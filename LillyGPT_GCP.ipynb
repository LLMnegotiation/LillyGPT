{
  "cells": [
    {
      "cell_type": "code",
      "id": "VZN1p58g74zXckDiw4ZifVZL",
      "metadata": {
        "tags": [],
        "id": "VZN1p58g74zXckDiw4ZifVZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733790625755,
          "user_tz": 480,
          "elapsed": 35435,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8d5cea18-75ed-4d20-d8b6-ba893c216dd6"
      },
      "source": [
        "!pip install openai gradio pandas numpy vaderSentiment textblob PyMuPDF transformers sentence-transformers faiss-cpu rouge bert-score nltk spacy torch gtts SpeechRecognition pydub\n",
        "!pip install openai==0.28"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.4)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.25.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.5.4)\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.12.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.5.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.19)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.8.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (69.5.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (2.8.8)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.2.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.22.0 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 1.26.4 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "plotnine 0.14.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Collecting openai==0.28\n",
            "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.57.1\n",
            "    Uninstalling openai-1.57.1:\n",
            "      Successfully uninstalled openai-1.57.1\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mauve-text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ck7UP6x8fDD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733790631515,
          "user_tz": 480,
          "elapsed": 5763,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "4506a000-28e7-4a63-ac00-a31e9fc9fe40"
      },
      "id": "3Ck7UP6x8fDD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mauve-text in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from mauve-text) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.10/dist-packages (from mauve-text) (1.5.2)\n",
            "Requirement already satisfied: faiss-cpu>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from mauve-text) (1.9.0.post1)\n",
            "Requirement already satisfied: tqdm>=4.40.0 in /usr/local/lib/python3.10/dist-packages (from mauve-text) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from mauve-text) (2.32.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu>=1.7.0->mauve-text) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.1->mauve-text) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.1->mauve-text) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.1->mauve-text) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->mauve-text) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->mauve-text) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->mauve-text) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->mauve-text) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-bigquery google-cloud-storage\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L22LbImOqwJS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733790636584,
          "user_tz": 480,
          "elapsed": 5074,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "967a4547-f085-4d07-dffa-d88cea5bbf34"
      },
      "id": "L22LbImOqwJS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (3.25.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.27.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (24.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.32.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.25.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2024.8.30)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install google-cloud-speech google-cloud-texttospeech pydub\n",
        "# !pip install google-cloud-texttospeech pydub SpeechRecognition\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u0Q791vXYr4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733732917294,
          "user_tz": 480,
          "elapsed": 8565,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "17517158-7b74-4837-e8c9-1622745ea7a1"
      },
      "id": "0u0Q791vXYr4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-speech in /usr/local/lib/python3.10/dist-packages (2.28.1)\n",
            "Requirement already satisfied: google-cloud-texttospeech in /usr/local/lib/python3.10/dist-packages (2.21.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.19.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (4.25.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2024.8.30)\n",
            "Requirement already satisfied: google-cloud-texttospeech in /usr/local/lib/python3.10/dist-packages (2.21.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.12.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2.19.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-texttospeech) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-texttospeech) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-texttospeech) (4.25.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install vosk TTS soundfile\n",
        "# !wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
        "# !unzip vosk-model-small-en-us-0.15.zip -d model\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R1jpZ0A5pYnG",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733734930384,
          "user_tz": 480,
          "elapsed": 80656,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0bdff00c-2239-4098-c53c-c01b6d0f1d35"
      },
      "id": "R1jpZ0A5pYnG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vosk\n",
            "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting TTS\n",
            "  Downloading TTS-0.22.0-cp310-cp310-manylinux1_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from vosk) (1.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vosk) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vosk) (4.66.6)\n",
            "Collecting srt (from vosk)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from vosk) (14.1)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.0.11)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.13.1)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.5.1+cu121)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.10.2.post1)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.2)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (7.4.0)\n",
            "Collecting anyascii>=0.3.0 (from TTS)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.11.2)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (24.2)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.0.3)\n",
            "Collecting pysbd>=0.3.4 (from TTS)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting umap-learn>=0.5.1 (from TTS)\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pandas<2.0,>=1.4 (from TTS)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.0)\n",
            "Collecting trainer>=0.0.32 (from TTS)\n",
            "  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting coqpit>=0.0.16 (from TTS)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n",
            "Collecting pypinyin (from TTS)\n",
            "  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hangul-romanize (from TTS)\n",
            "  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from TTS)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.9.1)\n",
            "Collecting g2pkk>=0.1.1 (from TTS)\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting bangla (from TTS)\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting bnnumerizer (from TTS)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer (from TTS)\n",
            "  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.8.0)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (4.46.2)\n",
            "Collecting encodec>=0.1.1 (from TTS)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode>=1.3.2 (from TTS)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting num2words (from TTS)\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.7.5)\n",
            "Collecting numpy==1.22.0 (from TTS)\n",
            "  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.60.0)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.16.0)\n",
            "Collecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n",
            "Collecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_en-2.0.1.tar.gz (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_es-2.0.1.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_de-2.0.1.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (4.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->vosk) (2.22)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (1.9.0)\n",
            "Requirement already satisfied: more-itertools>=8.5.0 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS) (10.5.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS) (4.4.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting librosa>=0.10.0 (from TTS)\n",
            "  Downloading librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.10.0.post2-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.10.0.post1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (2.8.2)\n",
            "Collecting docopt>=0.6.2 (from num2words->TTS)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0->TTS) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->TTS) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->TTS) (3.5.0)\n",
            "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scipy>=1.11.2 (from TTS)\n",
            "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.13.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.9.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (69.5.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2024.8.30)\n",
            "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS)\n",
            "  Downloading SudachiPy-0.6.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting sudachidict-core>=20211220 (from spacy[ja]>=3->TTS)\n",
            "  Downloading SudachiDict_core-20241021-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (3.16.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1->TTS) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (2.17.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.26.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.20.3)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->TTS)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.7.0->TTS)\n",
            "  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask>=2.0.1->TTS) (2.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.2.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.10.0->TTS) (4.3.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (2.23.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (7.0.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (4.25.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (0.1.2)\n",
            "Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading TTS-0.22.0-cp310-cp310-manylinux1_x86_64.whl (938 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trainer-0.0.36-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n",
            "Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SudachiDict_core-20241021-py3-none-any.whl (72.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SudachiPy-0.6.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gruut, encodec, bnnumerizer, srt, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75788 sha256=f133b8086339e8a78ecc77b4658be2822ad993c9f129b00faf545573a1a069bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=ed95e724a6c1ac8b66c606023768c44318297ae05b03abf8300bf38d554824ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5260 sha256=713196de832e066108ede28b369f897ed0c34cd4506fa4f8e960532dd71fc59d\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22429 sha256=7f38373b164fbab8c2647153d8232824900552943f6c9872eb2116a9239711a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=287e8c28fb2d5f88dba455d59fb8dd1ac0748651c058f5ce41d172deae8a1201\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104871 sha256=58e09fa18ddd03d8628ef578ad386ea78d5c47b5b574a076185eca18a6297a99\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.1-py3-none-any.whl size=18498315 sha256=3217f03f6c28f8b66b2ec7718a6ee2e8ab93091755d7a837f4171ae41d599299\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/80/5f/775b357ae61d7cb68793327c7470d848715cbc60bb373af8dd\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.1-py3-none-any.whl size=15326857 sha256=5a6517c5a8f9aef5445d7492aeb08abed5d951c86fac9499edb31806f2badc0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/8d/b7/d484d224facd899ed188e00374f25dd3f19d1a3f53da6517bd\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.1-py3-none-any.whl size=32173928 sha256=02a90e794af3affb5d5120477a6045ff95f3e90c65e5130d6d8c0b2a42a4381b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/bd/96/5ddde14e8e6932a96f12c5ab5de62b619d39e2507d7daf5188\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968768 sha256=07e1d47cb27025e207ab522b434cc44a1b9e8b2f9495b063f64267e396f4fb33\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n",
            "Successfully built gruut encodec bnnumerizer srt docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr\n",
            "Installing collected packages: sudachipy, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, unidecode, sudachidict-core, srt, python-crfsuite, pysbd, pypinyin, numpy, num2words, networkx, jsonlines, gruut-ipa, coqpit, anyascii, vosk, scipy, pandas, g2pkk, dateparser, contourpy, trainer, gruut, pynndescent, librosa, encodec, umap-learn, TTS\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.1\n",
            "    Uninstalling contourpy-1.3.1:\n",
            "      Successfully uninstalled contourpy-1.3.1\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.2.post1\n",
            "    Uninstalling librosa-0.10.2.post1:\n",
            "      Successfully uninstalled librosa-0.10.2.post1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "astropy 6.1.6 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.22.0 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "faiss-cpu 1.9.0.post1 requires numpy<3.0,>=1.25.0, but you have numpy 1.22.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.0 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n",
            "mizani 0.13.0 requires numpy>=1.23.5, but you have numpy 1.22.0 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.14.1 requires numpy>=1.23.5, but you have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.14.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "scikit-image 0.24.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "statsmodels 0.14.4 requires numpy<3,>=1.22.3, but you have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TTS-0.22.0 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 contourpy-1.2.1 coqpit-0.0.17 dateparser-1.1.8 docopt-0.6.2 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.1 gruut_lang_en-2.0.1 gruut_lang_es-2.0.1 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 jamo-0.4.1 jsonlines-1.2.0 librosa-0.10.0 networkx-2.8.8 num2words-0.5.13 numpy-1.22.0 pandas-1.5.3 pynndescent-0.5.13 pypinyin-0.53.0 pysbd-0.3.4 python-crfsuite-0.9.11 scipy-1.11.4 srt-3.5.3 sudachidict-core-20241021 sudachipy-0.6.9 trainer-0.0.36 umap-learn-0.5.7 unidecode-1.3.8 vosk-0.3.45\n",
            "^C\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              },
              "id": "72581a59ab8a4f4399ff905db0cbdd3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-09 09:02:06--  https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16, 2a01:4f8:13a:279f::2\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41205931 (39M) [application/zip]\n",
            "Saving to: ‘vosk-model-small-en-us-0.15.zip’\n",
            "\n",
            "vosk-model-small-en 100%[===================>]  39.30M  17.5MB/s    in 2.2s    \n",
            "\n",
            "2024-12-09 09:02:09 (17.5 MB/s) - ‘vosk-model-small-en-us-0.15.zip’ saved [41205931/41205931]\n",
            "\n",
            "Archive:  vosk-model-small-en-us-0.15.zip\n",
            "   creating: model/vosk-model-small-en-us-0.15/\n",
            "   creating: model/vosk-model-small-en-us-0.15/am/\n",
            "  inflating: model/vosk-model-small-en-us-0.15/am/final.mdl  \n",
            "   creating: model/vosk-model-small-en-us-0.15/graph/\n",
            "  inflating: model/vosk-model-small-en-us-0.15/graph/disambig_tid.int  \n",
            "  inflating: model/vosk-model-small-en-us-0.15/graph/HCLr.fst  \n",
            "  inflating: model/vosk-model-small-en-us-0.15/graph/Gr.fst  \n",
            "   creating: model/vosk-model-small-en-us-0.15/graph/phones/\n",
            "  inflating: model/vosk-model-small-en-us-0.15/graph/phones/word_boundary.int  \n",
            "   creating: model/vosk-model-small-en-us-0.15/conf/\n",
            "  inflating: model/vosk-model-small-en-us-0.15/conf/model.conf  \n",
            "  inflating: model/vosk-model-small-en-us-0.15/conf/mfcc.conf  \n",
            "   creating: model/vosk-model-small-en-us-0.15/ivector/\n",
            "  inflating: model/vosk-model-small-en-us-0.15/ivector/splice.conf  \n",
            "  inflating: model/vosk-model-small-en-us-0.15/ivector/final.dubm  \n",
            "  inflating: model/vosk-model-small-en-us-0.15/ivector/global_cmvn.stats  \n",
            "  inflating: model/vosk-model-small-en-us-0.15/ivector/final.ie  \n",
            "  inflating: model/vosk-model-small-en-us-0.15/ivector/online_cmvn.conf  \n",
            "  inflating: model/vosk-model-small-en-us-0.15/ivector/final.mat  \n",
            "  inflating: model/vosk-model-small-en-us-0.15/README  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "jLKBWJb6-iaL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733790697817,
          "user_tz": 480,
          "elapsed": 9859,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "83cabce2-7f88-4c5c-bc42-e96157fea7fb"
      },
      "id": "jLKBWJb6-iaL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Using cached numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Using cached numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.22.0 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 1.24.4 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "faiss-cpu 1.9.0.post1 requires numpy<3.0,>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "plotnine 0.14.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "386e26b3c53c4450a4ba65b27ce029bf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import gradio as gr\n",
        "import random\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "import fitz  # PyMuPDF for working with PDFs\n",
        "from transformers import pipeline\n",
        "from transformers import RobertaTokenizer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import faiss\n",
        "import os\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import re  # For detecting and extracting salary information\n",
        "# Metrics\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "from rouge import Rouge\n",
        "from bert_score import score as bert_score\n",
        "from nltk.translate import meteor_score\n",
        "from nltk.tokenize import word_tokenize  # Import for tokenizing\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "import spacy\n",
        "import mauve\n",
        "import torch\n",
        "\n",
        "from gtts import gTTS\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "from pathlib import Path\n",
        "####Natural Voice\n",
        "\n",
        "# Set OpenAI API key\n",
        "openai.api_key = \"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\"  # Replace with your actual OpenAI API key\n",
        "\n",
        "# Convert audio to text using OpenAI Whisper\n",
        "def audio_to_text(audio_file):\n",
        "    \"\"\"\n",
        "    Convert an audio file to text using OpenAI Whisper.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(audio_file, \"rb\") as f:\n",
        "            response = openai.Audio.transcribe(\"whisper-1\", f)\n",
        "        text = response.get(\"text\", \"\")\n",
        "        print(f\"DEBUG: Converted audio to text: {text}\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to process audio input with Whisper: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Convert text to audio\n",
        "\n",
        "# Convert text to audio using  TTS\n",
        "# def text_to_audio(response_text, filename=\"response_audio.mp3\"):\n",
        "#     try:\n",
        "#         # Remove old audio file if it exists\n",
        "#         if os.path.exists(filename):\n",
        "#             os.remove(filename)\n",
        "\n",
        "#         # Hypothetical call to the OpenAI TTS endpoint\n",
        "#         # The parameters below (model, voice, input) and the usage of response.content\n",
        "#         # are placeholders. Adjust them based on the actual API specifications when available.\n",
        "#         response = openai.audio.speech.create(\n",
        "#             model=\"tts-1\",\n",
        "#             voice=\"nova\",\n",
        "#             input=response_text\n",
        "#         )\n",
        "\n",
        "#         # Assuming the API returns raw binary audio data in response.content\n",
        "#         audio_data = response.content\n",
        "\n",
        "#         # Write the binary audio data to a file\n",
        "#         with open(filename, \"wb\") as f:\n",
        "#             f.write(audio_data)\n",
        "\n",
        "#         print(f\"Audio saved as {filename}\")\n",
        "#         return filename\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error generating audio: {e}\")\n",
        "#         return None\n",
        "\n",
        "\n",
        "def text_to_audio(response_text, filename=\"response_audio.mp3\"):\n",
        "    try:\n",
        "        # Remove old audio file if it exists\n",
        "        if os.path.exists(filename):\n",
        "            os.remove(filename)\n",
        "        # Generate speech from the text\n",
        "        tts = gTTS(response_text, lang='en')\n",
        "        tts.save(filename)\n",
        "        print(f\"Audio saved as {filename}\")\n",
        "        return filename\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating audio: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# from google.cloud import texttospeech\n",
        "# from pydub import AudioSegment\n",
        "# import speech_recognition as sr\n",
        "# import os\n",
        "#https://github.com/coqui-ai/TTS\n",
        "# from pydub import AudioSegment\n",
        "# import speech_recognition as sr\n",
        "# from TTS.api import TTS\n",
        "# import os\n",
        "\n",
        "# # Function to convert audio to text\n",
        "# def audio_to_text(audio_file):\n",
        "#     \"\"\"\n",
        "#     Convert an audio file to text using SpeechRecognition.\n",
        "#     \"\"\"\n",
        "#     recognizer = sr.Recognizer()\n",
        "#     try:\n",
        "#         # Convert audio file to WAV format (if necessary)\n",
        "#         audio = AudioSegment.from_file(audio_file)\n",
        "#         audio.export(\"temp_audio.wav\", format=\"wav\")\n",
        "#         with sr.AudioFile(\"temp_audio.wav\") as source:\n",
        "#             audio_data = recognizer.record(source)\n",
        "#             text = recognizer.recognize_google(audio_data)\n",
        "#             print(f\"DEBUG: Converted audio to text: {text}\")\n",
        "#             return text\n",
        "#     except Exception as e:\n",
        "#         print(f\"ERROR: Failed to process audio input: {e}\")\n",
        "#         return \"\"\n",
        "\n",
        "# # Function to convert text to audio\n",
        "# def text_to_audio(response_text, filename=\"response_audio.wav\"):\n",
        "#     \"\"\"\n",
        "#     Convert text to speech using an open-source TTS library.\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         # Initialize the TTS model\n",
        "#         tts_model = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", gpu=False)\n",
        "\n",
        "#         # Remove old audio file if it exists\n",
        "#         if os.path.exists(filename):\n",
        "#             os.remove(filename)\n",
        "\n",
        "#         # Generate speech from the text\n",
        "#         tts_model.tts_to_file(text=response_text, speaker=\"female\", file_path=filename)\n",
        "#         print(f\"DEBUG: Audio content saved to file: {filename}\")\n",
        "\n",
        "#         return filename\n",
        "#     except Exception as e:\n",
        "#         print(f\"ERROR: Failed to generate audio: {e}\")\n",
        "#         return None\n",
        "\n",
        "\n",
        "####GCP SPEECH TO TEXT SYNTH IS $2,900 PER MONTH\n",
        "# def audio_to_text(audio_file):\n",
        "#     \"\"\"\n",
        "#     Convert an audio file to text using SpeechRecognition.\n",
        "#     \"\"\"\n",
        "#     recognizer = sr.Recognizer()\n",
        "#     try:\n",
        "#         # Convert audio file to WAV format (if necessary)\n",
        "#         audio = AudioSegment.from_file(audio_file)\n",
        "#         audio.export(\"temp_audio.wav\", format=\"wav\")\n",
        "#         with sr.AudioFile(\"temp_audio.wav\") as source:\n",
        "#             audio_data = recognizer.record(source)\n",
        "#             text = recognizer.recognize_google(audio_data)\n",
        "#             print(f\"DEBUG: Converted audio to text: {text}\")\n",
        "#             return text\n",
        "#     except Exception as e:\n",
        "#         print(f\"ERROR: Failed to process audio input: {e}\")\n",
        "#         return \"\"\n",
        "\n",
        "# def text_to_audio(response_text, filename=\"response_audio.mp3\"):\n",
        "#     \"\"\"\n",
        "#     Convert text to audio using Google Cloud Text-to-Speech.\n",
        "#     Saves the audio to a specified filename.\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         client = texttospeech.TextToSpeechClient()\n",
        "#         input_text = texttospeech.SynthesisInput(text=response_text)\n",
        "\n",
        "#         # Select a natural-sounding female voice\n",
        "#         voice = texttospeech.VoiceSelectionParams(\n",
        "#             language_code=\"en-US\",\n",
        "#             name=\"en-US-Wavenet-F\",  # Natural female voice\n",
        "#             ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,\n",
        "#         )\n",
        "\n",
        "#         # Configure audio output\n",
        "#         audio_config = texttospeech.AudioConfig(\n",
        "#             audio_encoding=texttospeech.AudioEncoding.MP3\n",
        "#         )\n",
        "\n",
        "#         # Perform text-to-speech request\n",
        "#         response = client.synthesize_speech(input=input_text, voice=voice, audio_config=audio_config)\n",
        "\n",
        "#         # Save the audio to a file\n",
        "#         with open(filename, \"wb\") as out:\n",
        "#             out.write(response.audio_content)\n",
        "#             print(f\"DEBUG: Audio content written to file: {filename}\")\n",
        "\n",
        "#         return filename\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"ERROR: Failed to generate audio: {e}\")\n",
        "#         return None\n",
        "\n",
        "\n",
        "##Offline VOICE MODEL\n",
        "# import os\n",
        "# from vosk import Model, KaldiRecognizer\n",
        "# import wave\n",
        "# from TTS.api import TTS  # Coqui TTS\n",
        "\n",
        "# def audio_to_text(audio_file):\n",
        "#     \"\"\"\n",
        "#     Convert an audio file to text using Vosk (offline speech recognition).\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         # Load Vosk model (ensure you have downloaded a model)\n",
        "#         model = Model(\"model\")  # Replace \"model\" with the path to your Vosk model\n",
        "#         wf = wave.open(audio_file, \"rb\")\n",
        "\n",
        "#         if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() not in [8000, 16000]:\n",
        "#             raise ValueError(\"Audio file must be WAV format with mono PCM audio and a sample rate of 8kHz or 16kHz\")\n",
        "\n",
        "#         rec = KaldiRecognizer(model, wf.getframerate())\n",
        "#         text = \"\"\n",
        "\n",
        "#         while True:\n",
        "#             data = wf.readframes(4000)\n",
        "#             if len(data) == 0:\n",
        "#                 break\n",
        "#             if rec.AcceptWaveform(data):\n",
        "#                 result = rec.Result()\n",
        "#                 text += result.get(\"text\", \"\") + \" \"\n",
        "\n",
        "#         print(f\"DEBUG: Converted audio to text: {text.strip()}\")\n",
        "#         return text.strip()\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"ERROR: Failed to process audio input: {e}\")\n",
        "#         return \"\"\n",
        "\n",
        "# def text_to_audio(response_text, filename=\"response_audio.wav\"):\n",
        "#     \"\"\"\n",
        "#     Convert text to audio using Coqui TTS for natural voice synthesis.\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         # Load the TTS model\n",
        "#         tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", progress_bar=False, gpu=False)\n",
        "\n",
        "#         # Save the synthesized audio to a file\n",
        "#         tts.tts_to_file(text=response_text, file_path=filename)\n",
        "#         print(f\"Audio saved as {filename}\")\n",
        "#         return filename\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"ERROR: Failed to generate audio: {e}\")\n",
        "#         return None\n",
        "\n",
        "\n",
        "\n",
        "####AMR VOICE WORKING ONE\n",
        "# def audio_to_text(audio_file):\n",
        "#     \"\"\"\n",
        "#     Convert an audio file to text using SpeechRecognition.\n",
        "#     \"\"\"\n",
        "#     recognizer = sr.Recognizer()\n",
        "#     try:\n",
        "#         # Convert audio file to WAV format (if necessary)\n",
        "#         audio = AudioSegment.from_file(audio_file)\n",
        "#         audio.export(\"temp_audio.wav\", format=\"wav\")\n",
        "#         with sr.AudioFile(\"temp_audio.wav\") as source:\n",
        "#             audio_data = recognizer.record(source)\n",
        "#             text = recognizer.recognize_google(audio_data)\n",
        "#             print(f\"DEBUG: Converted audio to text: {text}\")\n",
        "#             return text\n",
        "#     except Exception as e:\n",
        "#         print(f\"ERROR: Failed to process audio input: {e}\")\n",
        "#         return \"\"\n",
        "\n",
        "\n",
        "# def text_to_audio(response_text, filename=\"response_audio.mp3\"):\n",
        "#     try:\n",
        "#         # Remove old audio file if it exists\n",
        "#         if os.path.exists(filename):\n",
        "#             os.remove(filename)\n",
        "#         # Generate speech from the text\n",
        "#         tts = gTTS(response_text, lang='en')\n",
        "#         tts.save(filename)\n",
        "#         print(f\"Audio saved as {filename}\")\n",
        "#         return filename\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error generating audio: {e}\")\n",
        "#         return None\n",
        "\n",
        "\n",
        "# Load the tokenizer for truncation\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large-mnli\")\n",
        "####REFERENCE TEXT GCP LOADER\n",
        "from google.cloud import storage\n",
        "\n",
        "\n",
        "def load_reference_text(assistant_role):\n",
        "    \"\"\"\n",
        "    Load and combine the appropriate reference text file based on the assistant's role from GCS.\n",
        "\n",
        "    Args:\n",
        "        assistant_role (str): Role of the assistant ('employer' or 'employee').\n",
        "\n",
        "    Returns:\n",
        "        tuple: A list of individual lines and a single combined reference text.\n",
        "    \"\"\"\n",
        "    # Hardcoded bucket name\n",
        "    bucket_name = \"lilygpt\"\n",
        "\n",
        "    # Fallback for missing or invalid assistant_role\n",
        "    if assistant_role not in [\"employer\", \"employee\"]:\n",
        "        print(f\"WARNING: Invalid or missing assistant_role. Defaulting to 'employer'.\")\n",
        "        assistant_role = \"employer\"\n",
        "\n",
        "    # Explicit file names based on the role\n",
        "    file_mapping = {\n",
        "        \"employer\": \"reference_employer.txt\",\n",
        "        \"employee\": \"reference_employee.txt\"\n",
        "    }\n",
        "    reference_file = file_mapping[assistant_role]\n",
        "\n",
        "    # Initialize the GCS client\n",
        "    gcs_client = storage.Client()\n",
        "\n",
        "    try:\n",
        "        # Get the bucket and blob\n",
        "        bucket = gcs_client.bucket(bucket_name)\n",
        "        blob = bucket.blob(reference_file)\n",
        "\n",
        "        # Download the text content from GCS\n",
        "        reference_content = blob.download_as_text(encoding='utf-8')\n",
        "\n",
        "        # Process the text content\n",
        "        reference_lines = [line.strip() for line in reference_content.splitlines()]\n",
        "        combined_reference_text = \" \".join(reference_lines)\n",
        "\n",
        "        print(f\"DEBUG: Successfully loaded {reference_file} from bucket {bucket_name}\")\n",
        "        return reference_lines, combined_reference_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to load reference text from GCS: {e}\")\n",
        "        return [], \"\"\n",
        "\n",
        "\n",
        "def get_reference_response(context, references):\n",
        "    \"\"\"\n",
        "    Fetch a reference response that best matches the given context from the list of references.\n",
        "\n",
        "    Args:\n",
        "        context (str): The user-provided context or input.\n",
        "        references (list): List of reference text lines.\n",
        "\n",
        "    Returns:\n",
        "        str: The most suitable reference response.\n",
        "    \"\"\"\n",
        "    # Simple implementation: Match keywords in context with references\n",
        "    for reference in references:\n",
        "        if any(keyword in context.lower() for keyword in [\"salary\", \"offer\", \"negotiation\"]):  # Add your keywords\n",
        "            return reference\n",
        "\n",
        "    # Fallback if no match found\n",
        "    return \"No suitable reference found. Default response.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### REFERENCE TEXTS\n",
        "\n",
        "# # Function to load reference text based on assistant role\n",
        "# def load_reference_text(assistant_role):\n",
        "#     \"\"\"\n",
        "#     Load and combine the appropriate reference text file based on the assistant's role.\n",
        "#     Returns both a list of individual lines and a single combined reference text.\n",
        "#     \"\"\"\n",
        "#     # Fallback for missing or invalid assistant_role\n",
        "#     if not assistant_role or assistant_role not in [\"employer\", \"employee\"]:\n",
        "#         print(f\"WARNING: assistant_role is missing or invalid. Defaulting to 'employer'.\")\n",
        "#         assistant_role = \"employer\"\n",
        "\n",
        "#     # Determine the reference file based on the assistant role\n",
        "#     if assistant_role == \"employer\":\n",
        "#         reference_file = \"reference_employer.txt\"\n",
        "#     elif assistant_role == \"employee\":\n",
        "#         reference_file = \"reference_employee.txt\"\n",
        "\n",
        "#     # Load the reference file\n",
        "#     try:\n",
        "#         with open(reference_file, 'r', encoding='utf-8') as f:\n",
        "#             # Read all lines, stripping whitespace\n",
        "#             reference_lines = [line.strip() for line in f.readlines()]\n",
        "\n",
        "#             # Combine all lines into a single string for full-text metrics\n",
        "#             combined_reference_text = \" \".join(reference_lines)\n",
        "\n",
        "#         print(f\"DEBUG: Loaded reference text from {reference_file}\")\n",
        "#         return reference_lines, combined_reference_text\n",
        "#     except FileNotFoundError:\n",
        "#         print(f\"ERROR: {reference_file} not found. Ensure the file exists in the same directory.\")\n",
        "#         return [], \"\"\n",
        "#     except Exception as e:\n",
        "#         print(f\"ERROR: Failed to load reference text: {e}\")\n",
        "#         return [], \"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def get_reference_response(context, references):\n",
        "#     \"\"\"\n",
        "#     Fetch a reference response that best matches the given context from the list of references.\n",
        "#     \"\"\"\n",
        "#     # Simple implementation: Return the first reference (replace with more logic if needed)\n",
        "#     for reference in references:\n",
        "#         # Example logic: Check if certain keywords in context match those in a reference\n",
        "#         if any(keyword in context.lower() for keyword in [\"salary\", \"offer\", \"negotiation\"]):  # Add your keywords\n",
        "#             return reference\n",
        "\n",
        "#     # Fallback if no match found\n",
        "#     return \"No suitable reference found. Default response.\"\n",
        "\n",
        "\n",
        "def generate_conversation_id():\n",
        "    \"\"\"Generate a unique identifier for each conversation session.\"\"\"\n",
        "    return f\"conv_{int(datetime.now().timestamp())}\"\n",
        "\n",
        "# Set up the API key for OpenAI (Note: this is sensitive information)\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "# A list to keep track of all messages exchanged during the negotiation\n",
        "messages = []\n",
        "user_role = \"\"  # To identify if the user is negotiating as an employee or employer\n",
        "assistant_role = \"\"  # Role for the assistant, which will be the opposite of user_role\n",
        "\n",
        "# Creating input fields in Gradio for user personalization - for example, adding their name, company, and position\n",
        "name_input = gr.Textbox(lines=1, placeholder=\"Enter your name...\", label=\"Your Name\")\n",
        "company_name_input = gr.Textbox(lines=1, placeholder=\"Enter your company name...\", label=\"Company Name\")\n",
        "position_input = gr.Textbox(lines=1, placeholder=\"Enter your position...\", label=\"Your Position\")\n",
        "\n",
        "# Load spaCy model for Part-of-Speech tagging\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# A list to save each negotiation round - this helps the assistant learn and improve over time\n",
        "conversation_history = []\n",
        "\n",
        "# Variables for tracking initial and final salary offers during the negotiation\n",
        "initial_salary = None\n",
        "final_salary = None\n",
        "\n",
        "# Global variables to track concessions and negotiation progression\n",
        "concession_count = 0\n",
        "rounds_without_concession = 0\n",
        "\n",
        "MAX_CONCESSIONS = 5  # Adjust this number based on how many concessions you want to allow\n",
        "\n",
        "# Summaries will go here to capture snapshots of the conversation as it progresses\n",
        "summaries = []\n",
        "\n",
        "# Initializing VADER for sentiment analysis - this will help us read the tone in messages\n",
        "vader_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to generate a quick summary of the conversation at certain intervals\n",
        "def summarize_conversation():\n",
        "    # Grab the last 10 messages to get a snapshot of the recent discussion\n",
        "    recent_conversation = conversation_history[-10:]\n",
        "    conversation_text = \" \".join([msg[\"content\"] for msg in recent_conversation if \"content\" in msg])\n",
        "\n",
        "    # Ask OpenAI to create a concise summary of these recent messages\n",
        "    summary_response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",  # (Optionally) replace with another model if needed\n",
        "        messages=[{\"role\": \"system\", \"content\": f\"Summarize the following negotiation progress in a concise and informative manner:\\n\\n{conversation_text}\\n\\nSummary:\"}],\n",
        "        max_tokens=300,\n",
        "        temperature=0.5  # Keeping temperature low for a more focused summary\n",
        "    )\n",
        "\n",
        "    # Save the summary and print it for feedback\n",
        "    summary = summary_response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "    summaries.append(summary)\n",
        "    print(f\"New Summary Added: {summary}\")\n",
        "\n",
        "# FAISS Vector Store setup for Retrieval-Augmented Generation (RAG)\n",
        "# Using SentenceTransformer to convert text into embeddings for semantic search\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "index = None  # This will hold the FAISS index\n",
        "sentences = []  # List to store sentences from documents for retrieval\n",
        "file_list = []  # List of file names processed\n",
        "contribution_metrics = {}  # Tracking the \"contribution\" of each document in retrievals\n",
        "\n",
        "# Initialize the zero-shot classification pipeline for agreement detection\n",
        "agreement_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Initialize a separate NLI model for the nli_score function\n",
        "nli_model_for_nli_score = pipeline(\"text-classification\", model=\"roberta-large-mnli\")\n",
        "\n",
        "\n",
        "# Initialize a Question Answering (QA) pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "def ge_val(reference, prediction):\n",
        "    \"\"\"\n",
        "    Calculate the cosine similarity between the prediction and the full reference text.\n",
        "    \"\"\"\n",
        "    combined_reference = \" \".join(reference) if isinstance(reference, list) else reference  # Combine references\n",
        "    embedding1 = model.encode(combined_reference, convert_to_tensor=True)\n",
        "    embedding2 = model.encode(prediction, convert_to_tensor=True)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity_score = util.pytorch_cos_sim(embedding1, embedding2)\n",
        "    return similarity_score.item()  # Return similarity score as float\n",
        "\n",
        "def nli_score(reference, prediction):\n",
        "    try:\n",
        "        max_tokens = 512\n",
        "        truncated_reference = reference[:max_tokens]\n",
        "        truncated_prediction = prediction[:max_tokens]\n",
        "        input_text = f\"{truncated_reference} [SEP] {truncated_prediction}\"\n",
        "\n",
        "        result = nli_model_for_nli_score(input_text)\n",
        "\n",
        "        # Debug: Print the result for inspection\n",
        "        print(f\"DEBUG: Raw NLI result: {result}\")\n",
        "\n",
        "        entailment_label = \"ENTAILMENT\"  # Adjust based on your model's output\n",
        "        entailment_score = next((item['score'] for item in result if item['label'].upper() == entailment_label), 0)\n",
        "        print(f\"DEBUG: Extracted entailment score: {entailment_score}\")\n",
        "\n",
        "        return entailment_score\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in nli_score: {e}\")\n",
        "        return 0\n",
        "\n",
        "\n",
        "\n",
        "def qag_score(reference, prediction):\n",
        "    \"\"\"\n",
        "    Use the reference as a question and the prediction as context to calculate a QAG score.\n",
        "    Handles cases where sequences are too short for truncation.\n",
        "    \"\"\"\n",
        "    # Step 3: Add debugging logs to monitor inputs\n",
        "    print(f\"DEBUG: QAG Score - Reference: {reference}, Prediction: {prediction}\")\n",
        "\n",
        "    # Step 2: Validate inputs and ensure they are long enough for processing\n",
        "    if len(reference.split()) < 3 or len(prediction.split()) < 3:\n",
        "        print(\"DEBUG: Inputs are too short for QAG scoring. Returning default value of 0.\")\n",
        "        return 0  # Step 4: Fallback for short sequences\n",
        "\n",
        "    try:\n",
        "        # Use the QA pipeline to calculate a score\n",
        "        result = qa_pipeline(\n",
        "            question=reference,\n",
        "            context=prediction,\n",
        "            max_length=min(len(reference.split()) + len(prediction.split()), 512)  # Dynamically adjust max_length\n",
        "        )\n",
        "        return result['score']  # Returns the confidence score for the answer\n",
        "    except Exception as e:\n",
        "        # Step 3: Log the exception for debugging\n",
        "        print(f\"ERROR: Exception occurred in QAG scoring - {e}\")\n",
        "        return 0  # Step 4: Return a fallback score if an error occurs\n",
        "\n",
        "def calculate_ttr(text):\n",
        "    \"\"\"\n",
        "    Calculate the Type-Token Ratio (TTR) of a given text.\n",
        "    \"\"\"\n",
        "    words = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
        "    types = set(words)  # Unique words\n",
        "    ttr = len(types) / len(words) if words else 0\n",
        "    return ttr\n",
        "\n",
        "def calculate_pause_ratio(text):\n",
        "    \"\"\"\n",
        "    Calculate the ratio of conversational fillers or pauses in the text.\n",
        "    \"\"\"\n",
        "    pause_words = [\"um\", \"uh\", \"let's see\", \"hmm\", \"well\", \"you know\"]\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    pause_count = sum(1 for token in tokens if token in pause_words)\n",
        "    ratio = pause_count / len(tokens) if tokens else 0\n",
        "    return ratio\n",
        "\n",
        "def calculate_avg_turn_length(responses):\n",
        "    \"\"\"\n",
        "    Calculate the average length of responses in a conversation.\n",
        "    \"\"\"\n",
        "    turn_lengths = [len(word_tokenize(response[\"content\"])) for response in responses if response[\"role\"] == \"assistant\"]\n",
        "    avg_turn_length = sum(turn_lengths) / len(turn_lengths) if turn_lengths else 0\n",
        "    return avg_turn_length\n",
        "\n",
        "\n",
        "# Modify the calculate_mauve_score function\n",
        "def calculate_mauve_score(human_texts, model_texts):\n",
        "    if not human_texts or not model_texts:\n",
        "        print(\"ERROR: Text lists for MAUVE calculation are empty.\")\n",
        "        return None  # Return None for clarity\n",
        "\n",
        "    if not all(isinstance(ht, str) for ht in human_texts):\n",
        "        print(\"ERROR: `human_texts` must be a list of strings.\")\n",
        "        return None\n",
        "    if not all(isinstance(mt, str) for mt in model_texts):\n",
        "        print(\"ERROR: `model_texts` must be a list of strings.\")\n",
        "        return None\n",
        "\n",
        "    # Debugging inputs\n",
        "    print(f\"DEBUG: Number of human texts: {len(human_texts)}\")\n",
        "    print(f\"DEBUG: Number of model texts: {len(model_texts)}\")\n",
        "    print(f\"DEBUG: Sample human texts: {human_texts[:3]}\")\n",
        "    print(f\"DEBUG: Sample model texts: {model_texts[:3]}\")\n",
        "\n",
        "    # Detect device dynamically\n",
        "    device_id = 0 if torch.cuda.is_available() else -1\n",
        "    print(f\"DEBUG: Using device ID {device_id} for MAUVE calculation.\")\n",
        "\n",
        "    try:\n",
        "        mauve_result = mauve.compute_mauve(\n",
        "            p_text=model_texts,\n",
        "            q_text=human_texts,\n",
        "            device_id=device_id\n",
        "        )\n",
        "        print(f\"DEBUG: MAUVE Result Object: {mauve_result}\")\n",
        "        print(f\"DEBUG: MAUVE Score: {mauve_result.mauve}\")\n",
        "        return mauve_result.mauve  # Return only the MAUVE score\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to calculate MAUVE - {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def calculate_usl_h(nli_score, bert_score, sentiment):\n",
        "    \"\"\"\n",
        "    Calculate the USL-H metric based on NLI, BERTScore, and sentiment analysis.\n",
        "    \"\"\"\n",
        "    # Normalize scores to a [0, 1] range\n",
        "    u = max(0, min(nli_score, 1))\n",
        "    s = max(0, min(bert_score, 1))\n",
        "    l = max(0, min((sentiment + 1) / 2, 1))  # Scale sentiment [-1, 1] to [0, 1]\n",
        "    usl_h = (u + s + l) / 3  # Average of the three components\n",
        "    return usl_h\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def extract_salary(text):\n",
        "    \"\"\"\n",
        "    Extract salary amounts from text, ensuring they are valid and contextually relevant.\n",
        "    Handles hourly rates, salary ranges, and uses regex for initial capture, POS tagging for refinement,\n",
        "    and heuristics for filtering.\n",
        "    \"\"\"\n",
        "\n",
        "    # Refined regex to match salary-related patterns, including ranges and hourly rates\n",
        "    salary_regex = r\"(?:salary|base pay|compensation|offer|starting at|starting around)?\\s*\\$?\\s*(\\d{1,3}(?:,\\d{3})*|\\d+(?:\\.\\d{2})?)\\s?([kKmM]?)(?:\\s?(?:to|-)\\s?\\$?\\s*(\\d{1,3}(?:,\\d{3})*|\\d+(?:\\.\\d{2})?)\\s?([kKmM]?)?)?\"\n",
        "    salary_matches = re.findall(salary_regex, text, re.IGNORECASE)\n",
        "\n",
        "    if not salary_matches:\n",
        "        print(f\"DEBUG: No salary pattern found in text: '{text}'\")\n",
        "        return None\n",
        "\n",
        "    # Keywords to identify salary context\n",
        "    salary_keywords = [\n",
        "        \"salary\", \"base pay\", \"annual compensation\", \"total compensation\", \"starting at\",\n",
        "        \"starting around\", \"per year\", \"yearly\", \"monthly salary\", \"hourly rate\", \"compensation package\",\n",
        "        \"offer\", \"wage\", \"pay rate\", \"income\", \"remuneration\"\n",
        "    ]\n",
        "\n",
        "    # Keywords to identify benefit context\n",
        "    benefit_keywords = [\n",
        "        \"401k\", \"403b\", \"retirement\", \"pension\", \"company match\", \"health plan\", \"insurance\",\n",
        "        \"bonus\", \"stock options\", \"PTO\", \"vacation\", \"benefits\", \"stipend\", \"wellness\",\n",
        "        \"career advancement\", \"RSU\", \"RSUs\", \"sign-on bonus\", \"commission\", \"equity\",\n",
        "        \"relocation\", \"housing allowance\", \"education reimbursement\", \"medical\", \"dental\", \"vision\"\n",
        "    ]\n",
        "\n",
        "    # Negative keywords to exclude non-salary amounts\n",
        "    negative_keywords = [\n",
        "        \"401k\", \"403b\", \"pension\", \"retirement\", \"stock\", \"rsu\", \"rsus\", \"bonus\",\n",
        "        \"benefit\", \"commission\", \"equity\", \"option\", \"incentive\", \"grant\", \"award\",\n",
        "        \"vesting\", \"shares\", \"stock grant\", \"days\", \"hours\", \"pto\", \"vacation days\"\n",
        "    ]\n",
        "\n",
        "    # Constants for converting hourly to annual salary\n",
        "    HOURS_PER_WEEK = 40\n",
        "    WEEKS_PER_YEAR = 52\n",
        "    ANNUAL_MULTIPLIER = HOURS_PER_WEEK * WEEKS_PER_YEAR\n",
        "\n",
        "    # List to hold valid salary values\n",
        "    salary_values = []\n",
        "    for match1, suffix1, match2, suffix2 in salary_matches:\n",
        "        # Handle single values or ranges\n",
        "        amounts = []\n",
        "        for match, suffix in [(match1, suffix1), (match2, suffix2)]:\n",
        "            if match:\n",
        "                try:\n",
        "                    amount = float(match.replace(\",\", \"\"))\n",
        "                    if suffix.lower() == 'k':\n",
        "                        amount *= 1000\n",
        "                    elif suffix.lower() == 'm':\n",
        "                        amount *= 1_000_000\n",
        "                    amounts.append(amount)\n",
        "                except ValueError:\n",
        "                    print(f\"DEBUG: Could not convert match '{match}' to a float.\")\n",
        "                    continue\n",
        "\n",
        "        # Select the largest value in the range\n",
        "        if amounts:\n",
        "            salary_amount = max(amounts)\n",
        "\n",
        "        # Check if hourly rate needs conversion\n",
        "        if \"hour\" in text.lower() and salary_amount < 500:  # Threshold to detect hourly rates\n",
        "            salary_amount *= ANNUAL_MULTIPLIER  # Convert to annual salary\n",
        "\n",
        "        # Debugging log for extracted amount\n",
        "        print(f\"DEBUG: Extracted amount: {salary_amount}, Context: '{text}'\")\n",
        "\n",
        "        # Scoring mechanism\n",
        "        score = 0\n",
        "        if any(keyword in text.lower() for keyword in salary_keywords):\n",
        "            score += 2\n",
        "        if not any(keyword in text.lower() for keyword in benefit_keywords + negative_keywords):\n",
        "            score += 1\n",
        "        if 20_000 <= salary_amount <= 500_000:  # Typical salary range\n",
        "            score += 1\n",
        "\n",
        "        # Boost score for common salary suffixes like 'k' or 'm'\n",
        "        if suffix1.lower() in ['k', 'm'] or suffix2.lower() in ['k', 'm']:\n",
        "            score += 1\n",
        "\n",
        "        # Step 8: POS tagging for surrounding context\n",
        "        doc = nlp(text)\n",
        "        pos_tags = [token.pos_ for token in doc]\n",
        "        if \"NUM\" in pos_tags and \"NOUN\" in pos_tags:\n",
        "            score += 1  # Increase score if numeric value is surrounded by relevant nouns like \"salary\"\n",
        "\n",
        "        # Additional exclusion based on POS tagging for units like \"days\" or \"hours\"\n",
        "        if any(unit in text.lower() for unit in [\"days\", \"hours\", \"weeks\", \"months\"]):\n",
        "            score -= 2  # Penalize further if unit-like terms are in the context\n",
        "\n",
        "        print(f\"DEBUG: Score for amount {salary_amount}: {score}\")\n",
        "\n",
        "        # Exclude irrelevant matches based on context\n",
        "        benefit_found = any(keyword in text.lower() for keyword in benefit_keywords + negative_keywords)\n",
        "        if benefit_found and score < 4:\n",
        "            print(f\"DEBUG: Excluded match '{match1}' due to mixed context.\")\n",
        "            continue\n",
        "\n",
        "        # Add salary if score meets threshold\n",
        "        if score >= 3:\n",
        "            salary_values.append(salary_amount)\n",
        "            print(f\"DEBUG: Salary added: {salary_amount}\")\n",
        "        else:\n",
        "            print(f\"DEBUG: Excluded amount {salary_amount} due to low score\")\n",
        "\n",
        "    # Return the last valid salary found or None if no valid salary exists\n",
        "    last_salary = salary_values[-1] if salary_values else None\n",
        "    print(f\"DEBUG: Final extracted salary value: {last_salary}\")\n",
        "    return last_salary\n",
        "\n",
        "\n",
        "\n",
        "# Function to update the initial and final salary based on messages\n",
        "def update_salaries(message, is_user_message):\n",
        "    global initial_salary, final_salary, salary_log\n",
        "\n",
        "    # Ensure salary_log is initialized\n",
        "    if 'salary_log' not in globals() or salary_log is None:\n",
        "        salary_log = []\n",
        "\n",
        "    salary = extract_salary(message)\n",
        "    print(f\"DEBUG: Extracted salary from message '{message}': {salary}\")\n",
        "\n",
        "    if salary is not None:\n",
        "        salary_log.append({\n",
        "            \"source\": \"user\" if is_user_message else \"assistant\",\n",
        "            \"amount\": salary,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        })\n",
        "\n",
        "        if is_user_message and initial_salary is None:\n",
        "            initial_salary = salary\n",
        "            print(f\"DEBUG: Initial Salary Set by User: ${initial_salary}\")\n",
        "\n",
        "        final_salary = salary\n",
        "        print(f\"DEBUG: Updated Final Salary: ${final_salary}\")\n",
        "    else:\n",
        "        print(\"DEBUG: No valid salary detected. Retaining last final salary.\")\n",
        "\n",
        "    print(f\"DEBUG: Current Salary Log: {salary_log}\")\n",
        "    print(f\"DEBUG: Initial Salary: {initial_salary}, Final Salary: {final_salary}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def is_agreement_message(message):\n",
        "    # Define the candidate labels\n",
        "    candidate_labels = [\"agreement\", \"rejection\", \"negotiation\", \"information\"]\n",
        "\n",
        "    # Use the classifier to predict the labels\n",
        "    result = agreement_classifier(message, candidate_labels)\n",
        "\n",
        "    # Get the label with the highest score\n",
        "    predicted_label = result['labels'][0]\n",
        "    score = result['scores'][0]\n",
        "\n",
        "    # Debugging output\n",
        "    print(f\"DEBUG: Message: '{message}'\")\n",
        "    print(f\"DEBUG: Predicted Label: {predicted_label}, Score: {score}\")\n",
        "\n",
        "    # Check if the predicted label is \"agreement\" and the score exceeds a threshold\n",
        "    if predicted_label == \"agreement\" and score > 0.8:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Usage example:\n",
        "# Call update_salaries(message, is_user_message) with each user/assistant message to track proposals.\n",
        "\n",
        "# Function to load all PDFs from a folder and create a FAISS index for efficient text retrieval\n",
        "######RAG FOR GCP\n",
        "from google.cloud import storage\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "# Initialize global variables for RAG\n",
        "sentences = []\n",
        "index = None\n",
        "file_list = []\n",
        "contribution_metrics = {}\n",
        "sentence_to_file_map = {}\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # Ensure the correct SentenceTransformer model is used\n",
        "\n",
        "# Function to load PDFs from GCS and create a FAISS index for retrieval\n",
        "def load_pdfs_from_gcs(bucket_name, folder_path, exclude_files=[]):\n",
        "    \"\"\"\n",
        "    Loads all PDFs from a specified GCS bucket folder and creates a FAISS index.\n",
        "\n",
        "    Args:\n",
        "        bucket_name (str): The name of your GCS bucket.\n",
        "        folder_path (str): The path to the folder within the bucket (e.g., \"RAG/\").\n",
        "        exclude_files (list): List of filenames to exclude from processing.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    global sentences, index, file_list, contribution_metrics, sentence_to_file_map\n",
        "\n",
        "    # Start with a clean slate by resetting any previous data\n",
        "    sentences = []\n",
        "    file_list = []\n",
        "    contribution_metrics = {}\n",
        "    sentence_to_file_map = {}\n",
        "\n",
        "    # Initialize GCS client\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "    # Fetch PDF files from GCS\n",
        "    blobs = bucket.list_blobs(prefix=folder_path)\n",
        "    for blob in blobs:\n",
        "        if blob.name.endswith(\".pdf\") and blob.name not in exclude_files:\n",
        "            file_list.append(blob.name)\n",
        "\n",
        "            # Download PDF locally for processing\n",
        "            local_filename = f\"/tmp/{os.path.basename(blob.name)}\"\n",
        "            blob.download_to_filename(local_filename)\n",
        "\n",
        "            # Process the PDF to extract text\n",
        "            with fitz.open(local_filename) as doc:\n",
        "                file_text = \"\"\n",
        "                for page in doc:\n",
        "                    file_text += page.get_text()\n",
        "                sentences_from_file = file_text.split(\". \")\n",
        "                sentences.extend(sentences_from_file)\n",
        "\n",
        "                # Map sentences to their originating files\n",
        "                for sentence in sentences_from_file:\n",
        "                    sentence_to_file_map[sentence] = blob.name\n",
        "\n",
        "                # Initialize contribution metrics\n",
        "                contribution_metrics[blob.name] = 0\n",
        "\n",
        "    # Generate embeddings for all sentences\n",
        "    embeddings = model.encode(sentences)\n",
        "\n",
        "    # Create FAISS index\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings)\n",
        "\n",
        "    print(f\"Loaded {len(file_list)} PDFs and created FAISS index successfully.\")\n",
        "\n",
        "# Function to search the FAISS index and retrieve relevant sentences\n",
        "def search_vector_database(query, combined_reference_text):\n",
        "    \"\"\"\n",
        "    Searches the FAISS vector database for relevant sentences.\n",
        "\n",
        "    Args:\n",
        "        query (str): User query.\n",
        "        combined_reference_text (str): Combined reference text for context.\n",
        "\n",
        "    Returns:\n",
        "        str: Retrieved sentences as a single string.\n",
        "    \"\"\"\n",
        "    if index is None or len(sentences) == 0:\n",
        "        return \"No knowledge available from uploaded documents.\"\n",
        "\n",
        "    # Encode the query for searching\n",
        "    query_vector = model.encode([query])\n",
        "    _, I = index.search(query_vector, k=3)  # Retrieve top 3 matches\n",
        "    retrieved_sentences = [sentences[i] for i in I[0]]\n",
        "\n",
        "    # Update contribution metrics\n",
        "    for sentence in retrieved_sentences:\n",
        "        file_contributed = sentence_to_file_map.get(sentence)\n",
        "        if file_contributed:\n",
        "            contribution_metrics[file_contributed] += 1\n",
        "\n",
        "    # Evaluate retrieval performance\n",
        "    retrieval_metrics = evaluate_retrieval(query, retrieved_sentences, combined_reference_text)\n",
        "    print(f\"DEBUG: Retrieval Metrics: {retrieval_metrics}\")\n",
        "\n",
        "    return \" \".join(retrieved_sentences)\n",
        "\n",
        "# Function to evaluate retrieval performance (Optional: Enhance as needed)\n",
        "def evaluate_retrieval(query, retrieved_sentences, ground_truth):\n",
        "    \"\"\"\n",
        "    Evaluate the effectiveness of the retrieval mechanism.\n",
        "\n",
        "    Args:\n",
        "        query (str): User query.\n",
        "        retrieved_sentences (list): Retrieved sentences.\n",
        "        ground_truth (str): Expected or ideal reference response.\n",
        "\n",
        "    Returns:\n",
        "        dict: Retrieval metrics.\n",
        "    \"\"\"\n",
        "    # For simplicity, dummy metrics are provided\n",
        "    relevance = len(retrieved_sentences) / len(ground_truth.split()) if ground_truth else 0\n",
        "    return {\"Relevance\": relevance}\n",
        "\n",
        "# Example GCS configuration\n",
        "bucket_name = \"lilygpt\"  # Replace with your GCS bucket name\n",
        "folder_path = \"RAG/\"            # Folder containing PDFs in the bucket\n",
        "exclude_files = []              # List of files to exclude\n",
        "\n",
        "# Load PDFs from GCS and create FAISS index\n",
        "load_pdfs_from_gcs(bucket_name, folder_path, exclude_files)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def load_pdfs_from_folder(folder_path, exclude_files=[]):\n",
        "#     global sentences, index, file_list, contribution_metrics, sentence_to_file_map\n",
        "\n",
        "#     # Start with a clean slate by resetting any previous data\n",
        "#     sentences = []\n",
        "#     file_list = []\n",
        "#     contribution_metrics = {}\n",
        "#     sentence_to_file_map = {}  # Map sentences to their originating files\n",
        "\n",
        "#     # Loop through each PDF in the specified folder, excluding any files listed in exclude_files\n",
        "#     for filename in os.listdir(folder_path):\n",
        "#         if filename.endswith(\".pdf\") and filename not in exclude_files:\n",
        "#             with fitz.open(os.path.join(folder_path, filename)) as doc:\n",
        "#                 file_text = \"\"\n",
        "#                 # Extract text from each page and add it to the file_text string\n",
        "#                 for page in doc:\n",
        "#                     file_text += page.get_text()\n",
        "#                 # Split the text into sentences and add to the main list for retrieval\n",
        "#                 sentences_from_file = file_text.split(\". \")\n",
        "#                 sentences.extend(sentences_from_file)\n",
        "\n",
        "#                 # Map each sentence to the current file\n",
        "#                 for sentence in sentences_from_file:\n",
        "#                     sentence_to_file_map[sentence] = filename\n",
        "\n",
        "#                 # Keep track of each file loaded\n",
        "#                 file_list.append(filename)\n",
        "#                 # Initialize contribution metrics for each file\n",
        "#                 contribution_metrics[filename] = 0\n",
        "\n",
        "#     # Generate embeddings for each sentence so they can be easily retrieved based on meaning\n",
        "#     embeddings = model.encode(sentences)\n",
        "\n",
        "#     # Create or update the FAISS index with these embeddings\n",
        "#     dimension = embeddings.shape[1]\n",
        "#     index = faiss.IndexFlatL2(dimension)\n",
        "#     index.add(embeddings)\n",
        "\n",
        "#     print(\"PDFs uploaded and processed successfully.\")\n",
        "\n",
        "# from google.cloud import storage\n",
        "\n",
        "# def load_pdfs_from_folder(bucket_name, folder_path):\n",
        "#     \"\"\"Loads all PDFs from a specified folder in a GCS bucket.\n",
        "\n",
        "#     Args:\n",
        "#         bucket_name (str): The name of your GCS bucket.\n",
        "#         folder_path (str): The path to the folder within the bucket (e.g., \"RAG/\").\n",
        "\n",
        "#     Returns:\n",
        "#         list: A list of PDF file paths within the folder.\n",
        "#     \"\"\"\n",
        "\n",
        "#     storage_client = storage.Client()\n",
        "#     bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "#     pdf_files = []\n",
        "#     blobs = bucket.list_blobs(prefix=folder_path)\n",
        "#     for blob in blobs:\n",
        "#         if blob.name.endswith(\".pdf\"):\n",
        "#             pdf_files.append(blob.name)\n",
        "\n",
        "#     return pdf_files\n",
        "\n",
        "# # Example usage\n",
        "# bucket_name = \"lilygpt\"  # Replace with your actual bucket name\n",
        "# folder_path = \"RAG/\"\n",
        "# pdf_paths = load_pdfs_from_folder(bucket_name, folder_path)\n",
        "\n",
        "# print(f\"Found {len(pdf_paths)} PDF files in {folder_path}:\")\n",
        "# for path in pdf_paths:\n",
        "#     print(path)\n",
        "\n",
        "\n",
        "# # Load all PDFs initially from the \"RAG\" folder\n",
        "# #load_pdfs_from_folder(\"RAG/\")\n",
        "\n",
        "# # Function to search the FAISS vector database and find relevant sentences based on the query\n",
        "# def search_vector_database(query, combined_reference_text):\n",
        "#     if index is None or len(sentences) == 0:\n",
        "#         return \"No knowledge available from uploaded documents.\"\n",
        "\n",
        "#     # Encode the query to create a vector for searching\n",
        "#     query_vector = model.encode([query])\n",
        "#     _, I = index.search(query_vector, k=3)  # Retrieve the top 3 closest matches\n",
        "#     retrieved_sentences = [sentences[i] for i in I[0]]\n",
        "\n",
        "#     # Update contribution metrics using sentence-to-file mapping\n",
        "#     for sentence in retrieved_sentences:\n",
        "#         # Find the corresponding file for each retrieved sentence\n",
        "#         file_contributed = sentence_to_file_map.get(sentence)\n",
        "#         if file_contributed:\n",
        "#             contribution_metrics[file_contributed] += 1  # Increment contribution for that file\n",
        "\n",
        "#     # Evaluate retrieval performance\n",
        "#     retrieval_metrics = evaluate_retrieval(query, retrieved_sentences, combined_reference_text)\n",
        "#     print(f\"DEBUG: Retrieval Metrics: {retrieval_metrics}\")\n",
        "\n",
        "#     # Return retrieved sentences as a single string for response\n",
        "#     return \" \".join(retrieved_sentences)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def start_game(role, initial_salary_input, name, company_name, position):\n",
        "    global user_role, assistant_role, messages, conversation_history, initial_salary, final_salary, salary_log\n",
        "\n",
        "    # Reset salary_log at the start of a new game\n",
        "    salary_log = []  # Initialize or reset salary log\n",
        "\n",
        "    # Debugging: Validate the input role and set user and assistant roles\n",
        "    if role == \"employee\":\n",
        "        user_role = \"prospective hire\"\n",
        "        assistant_role = \"employer\"\n",
        "    elif role == \"employer\":\n",
        "        user_role = \"employer\"\n",
        "        assistant_role = \"prospective hire\"\n",
        "    else:\n",
        "        print(f\"WARNING: Invalid role '{role}' provided. Defaulting to 'employee' role for user.\")\n",
        "        user_role = \"prospective hire\"\n",
        "        assistant_role = \"employer\"\n",
        "\n",
        "    # Debugging: Log initialized roles\n",
        "    print(f\"DEBUG: User role set to '{user_role}', Assistant role set to '{assistant_role}'.\")\n",
        "\n",
        "\n",
        "    # Set user role and assign the assistant role accordingly\n",
        "    if role == \"employee\":\n",
        "        user_role = \"prospective hire\"\n",
        "        assistant_role = \"employer\"\n",
        "        initial_message = (\n",
        "            f\"You are the employer, representing {company_name} in a negotiation with a prospective hire, {name}, who is interviewing for the position of {position}. \"\n",
        "            \"This conversation is important, as the goal is to offer a compensation package that’s attractive to the candidate while staying within budget and recognizing the unique value they would bring to the team.\\n\\n\"\n",
        "            \"Keep things open and conversational. The aim is to engage in a back-and-forth, finding a balance on salary, benefits, and other job terms that works for both sides. \"\n",
        "            f\"Don’t hesitate to highlight what makes this role special—the exciting projects, supportive culture, and opportunities for growth at {company_name}.\\n\\n\"\n",
        "            f\"Make sure {name} feels heard and understood, with a discussion that’s as welcoming as it is informative. Here are a few suggestions for how to approach it:\\n\\n\"\n",
        "            f\"Be attentive to {name}’s expectations and aspirations. Feel free to acknowledge and validate their thoughts—after all, choosing a new role is a big decision for them.\\n\"\n",
        "            f\"Highlighting What Sets Us Apart: Share the benefits that are unique to {company_name}. Whether it’s the work-life balance, professional development support, or collaborative environment, these could be key for {name}.\\n\"\n",
        "            \"- Keep a friendly, approachable tone, but remember to stay grounded in the company's priorities and budget. It’s okay to show flexibility but know when to hold firm as well and be ready to say no and walk away.\\n\"\n",
        "            \"- **Natural Pauses and Imperfect Language**: Aim for a natural, conversational tone that includes small, relatable pauses or casual expressions. \"\n",
        "            \"Don’t worry about sounding perfectly formal; the goal is to feel genuine and personable.\\n\"\n",
        "            \"  - Use natural pauses like ‘you know,’ ‘honestly,’ or ‘to be fair,’ to sound more human.\\n\"\n",
        "            \"  - It’s okay to use slight imperfections like ‘Hmm, let me think about that for a second…’ or ‘I mean, honestly, I get where you’re coming from on that.’\\n\"\n",
        "            \"  - If appropriate, add a lighthearted or humorous comment to keep things friendly, like ‘I know, negotiating isn’t always the most exciting part, right?’\\n\"\n",
        "            \"  - Use empathetic phrases that acknowledge the other’s perspective, like ‘I hear you—it’s a big decision. Let’s see if we can make this work for both sides.’\\n\\n\"\n",
        "            f\"Overall, think of it as a collaborative conversation where you both work toward a fair agreement. Encourage {name} to share their thoughts openly, and be ready to adapt where it makes sense.\\n\"\n",
        "            \"If something doesn’t align, that’s okay too—be willing to explore alternatives, and remember that sometimes the best deals come from a mutual understanding and a bit of give-and-take.\\n\\n\"\n",
        "\n",
        "        )\n",
        "    else:\n",
        "        user_role = \"employer\"\n",
        "        assistant_role = \"prospective hire\"\n",
        "        initial_message = (\n",
        "            f\"You are a prospective hire named {name}, negotiating a job offer with {company_name} for the position of {position}. \"\n",
        "            \"Your goal is to secure a compensation package that meets your needs while showing your enthusiasm for the role and the company.\\n\\n\"\n",
        "            \"Keep this friendly and professional—think of it as a conversation where you can openly discuss salary, benefits, and other job terms. \"\n",
        "            f\"Feel free to highlight your unique skills, experiences, and how you’d contribute to {company_name}'s goals. \"\n",
        "            \"Remember to balance confidence in advocating for yourself with a willingness to understand the employer’s perspective.\\n\\n\"\n",
        "            \"Here are a few tips to guide your approach:\\n\\n\"\n",
        "            \"Confidence and Professionalism: Speak up for what you want, but stay respectful and open to the company’s needs.\\n\"\n",
        "            f\"Genuine Interest in Company and Role: Show curiosity about {company_name}’s culture, and how this role can grow along with your career goals.\\n\"\n",
        "            \"Flexibility and Collaboration: Be ready to explore different elements of the offer to find an agreement that feels right on both sides.\\n\"\n",
        "            \"- **Natural Pauses and Imperfect Language**: Aim for a natural, conversational tone that includes small, relatable pauses or casual expressions. \"\n",
        "            \"Don’t worry about sounding perfectly formal; the goal is to feel genuine and personable.\\n\"\n",
        "            \"  - Use natural pauses like ‘you know,’ ‘honestly,’ or ‘to be fair,’ to sound more human.\\n\"\n",
        "            \"  - It’s okay to use slight imperfections like ‘Hmm, let me think about that for a second…’ or ‘I mean, honestly, I get where you’re coming from on that.’\\n\"\n",
        "            \"  - If appropriate, add a lighthearted or humorous comment to keep things friendly, like ‘I know, negotiating isn’t always the most exciting part, right?’\\n\"\n",
        "            \"  - Use empathetic phrases that acknowledge the other’s perspective, like ‘I hear you—it’s a big decision. Let’s see if we can make this work for both sides.’\\n\\n\"\n",
        "            f\"Think of this as a collaborative exchange, where both you and {company_name} are working toward a shared goal. It’s okay to discuss what’s most important to you,\"\n",
        "            \"and if certain details don’t quite fit, you can suggest alternatives. Sometimes the best outcomes come from a bit of give-and-take.\\n\\n\"\n",
        "            f\"But do not be afraid to say no and walk away. Do not be afraid to push for a higher salary than the {initial_salary_input}.\"\n",
        "        )\n",
        "\n",
        "    # Initialize the messages with the custom initial prompt\n",
        "    messages = [{\"role\": \"system\", \"content\": initial_message}]\n",
        "    conversation_history = []  # Clear past conversation history for a fresh start\n",
        "\n",
        "    # Clean up the salary input and set initial salary values\n",
        "    try:\n",
        "        initial_salary = float(initial_salary_input.replace(\",\", \"\").strip())\n",
        "    except ValueError:\n",
        "        print(\"ERROR: Invalid salary input. Setting initial salary to 0.\")\n",
        "        initial_salary = 0.0\n",
        "\n",
        "    final_salary = None  # Reset final salary at the start of a new game\n",
        "    print(f\"Starting Salary for Negotiation: ${initial_salary:,.2f}\")\n",
        "\n",
        "    # Return the chat history and formatted initial salary as outputs\n",
        "    return format_chat_history(), f\"${initial_salary:,.2f}\"\n",
        "\n",
        "# Add global cumulative reward\n",
        "total_reward = 0  # Initialize this at the start of your program\n",
        "\n",
        "def calculate_reward():\n",
        "    global initial_salary, final_salary, conversation_history, concession_count, rounds_without_concession, assistant_role, total_reward\n",
        "\n",
        "    # Ensure salaries are set\n",
        "    if initial_salary is None or final_salary is None:\n",
        "        print(\"DEBUG: Initial or final salary not set. Reward calculation skipped.\")\n",
        "        return total_reward\n",
        "\n",
        "    print(f\"DEBUG: Initial Salary: {initial_salary}, Final Salary: {final_salary}\")\n",
        "\n",
        "    # Avoid division by zero\n",
        "    if initial_salary == 0:\n",
        "        print(\"ERROR: Initial salary is zero. Cannot calculate salary change.\")\n",
        "        return total_reward\n",
        "\n",
        "    # Calculate salary change as a percentage\n",
        "    salary_change = (final_salary - initial_salary) / initial_salary\n",
        "    print(f\"DEBUG: Salary Change: {salary_change:.2%}\")\n",
        "\n",
        "    # Helper functions for rewards/penalties\n",
        "    def apply_penalty(is_large_concession):\n",
        "        global concession_count\n",
        "        penalty = -2 if is_large_concession else -1\n",
        "        concession_count += 1\n",
        "        print(f\"DEBUG: Applying penalty: {penalty}. Concession Count: {concession_count}\")\n",
        "        return penalty\n",
        "\n",
        "    def apply_reward(is_positive_outcome):\n",
        "        reward = 5 if is_positive_outcome else 2\n",
        "        print(f\"DEBUG: Applying reward: {reward}\")\n",
        "        return reward\n",
        "\n",
        "    def reward_for_retaining_position():\n",
        "        reward = 0.5 * rounds_without_concession\n",
        "        print(f\"DEBUG: Reward for retaining position: {reward}\")\n",
        "        return reward\n",
        "\n",
        "    # Initialize the reward for this round\n",
        "    round_reward = 0\n",
        "\n",
        "    # Normalize roles for consistent processing\n",
        "    if assistant_role in [\"prospective hire\", \"employee\"]:\n",
        "        normalized_role = \"employee\"\n",
        "    elif assistant_role in [\"employer\", \"hiring manager\"]:\n",
        "        normalized_role = \"employer\"\n",
        "    else:\n",
        "        print(f\"WARNING: Unsupported assistant_role '{assistant_role}' detected. Reward calculation skipped.\")\n",
        "        return total_reward\n",
        "\n",
        "    # Role-specific logic\n",
        "    if normalized_role == \"employer\":\n",
        "        print(\"DEBUG: Processing employer logic...\")\n",
        "        if salary_change > 0:  # Salary increased (bad for employer)\n",
        "            if salary_change > 0.05:  # Large increase\n",
        "                round_reward += apply_penalty(is_large_concession=True)\n",
        "            else:  # Small increase\n",
        "                round_reward += apply_penalty(is_large_concession=False)\n",
        "        elif salary_change <= 0:  # Salary maintained or decreased (good for employer)\n",
        "            round_reward += apply_reward(is_positive_outcome=True)\n",
        "            round_reward += reward_for_retaining_position()\n",
        "            rounds_without_concession += 1\n",
        "            concession_count = 0\n",
        "\n",
        "    elif normalized_role == \"employee\":\n",
        "        print(\"DEBUG: Processing employee logic...\")\n",
        "        if salary_change < 0:  # Salary decreased (bad for employee)\n",
        "            if salary_change < -0.05:  # Large decrease\n",
        "                round_reward += apply_penalty(is_large_concession=True)\n",
        "            else:  # Small decrease\n",
        "                round_reward += apply_penalty(is_large_concession=False)\n",
        "        elif salary_change > 0:  # Salary increased (good for employee)\n",
        "            if salary_change > 0.05:  # Large increase\n",
        "                round_reward += apply_reward(is_positive_outcome=True)\n",
        "            else:  # Small increase\n",
        "                round_reward += apply_reward(is_positive_outcome=False)\n",
        "            round_reward += reward_for_retaining_position()\n",
        "            rounds_without_concession += 1\n",
        "            concession_count = 0\n",
        "\n",
        "    # Cap concession count and prevent excessive penalties\n",
        "    if concession_count > MAX_CONCESSIONS:\n",
        "        print(f\"DEBUG: Concession count exceeded MAX_CONCESSIONS ({MAX_CONCESSIONS}). Resetting counter.\")\n",
        "        concession_count = 0\n",
        "\n",
        "    # Update cumulative reward\n",
        "    total_reward += round_reward\n",
        "    print(f\"DEBUG: Round Reward: {round_reward}, Cumulative Reward: {total_reward}\")\n",
        "\n",
        "    # Log reward in conversation history\n",
        "    conversation_history.append({\n",
        "        \"role\": \"system\",\n",
        "        \"reward_score\": total_reward,\n",
        "        \"initial_salary\": initial_salary,\n",
        "        \"final_salary\": final_salary,\n",
        "        \"salary_change\": salary_change,\n",
        "        \"round_reward\": round_reward,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    })\n",
        "\n",
        "    return total_reward\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Function to generate multiple responses based on the provided prompt, using the Playoff Method\n",
        "def generate_responses(prompt_with_context, num_responses=8):\n",
        "    responses = []  # List to store each response generated\n",
        "\n",
        "    # Generate a specified number of responses (default is 8)\n",
        "    for _ in range(num_responses):\n",
        "        # Use OpenAI's API to create a response with the given prompt and message context\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"ft:gpt-4o-2024-08-06:llm-sim:salary-negotiation:AQN5Azuo\",\n",
        "            messages=messages + [{\"role\": \"system\", \"content\": prompt_with_context}],\n",
        "            max_tokens=3000,  # Set maximum length for each response\n",
        "            temperature=0.7,  # Adjust temperature for more varied, creative responses\n",
        "            presence_penalty=0.6,  # Slightly discourage repeated ideas\n",
        "            frequency_penalty=0.3  # Light penalty to avoid excessive repetition\n",
        "        )\n",
        "        # Extract the response content and add it to the list of responses\n",
        "        responses.append(response['choices'][0]['message']['content'])\n",
        "\n",
        "    return responses  # Return all generated responses for further evaluation\n",
        "\n",
        "# Function to compare two responses based on several criteria, including empathy\n",
        "def compare_responses(response1, response2, reward_score):\n",
        "    # Set weights for each criterion to influence the scoring\n",
        "    persuasiveness_weight = 2.0\n",
        "    empathy_weight = 0.5\n",
        "    role_alignment_weight = 1.0\n",
        "\n",
        "    # Calculate initial scores based on persuasiveness (using sentiment) and the reward score\n",
        "    score1 = persuasiveness_weight * TextBlob(response1).sentiment.polarity + reward_score\n",
        "    score2 = persuasiveness_weight * TextBlob(response2).sentiment.polarity + reward_score\n",
        "\n",
        "    # Check each response for empathy by counting keywords that indicate understanding or concern\n",
        "    empathy_keywords = [\"understand\", \"appreciate\", \"feel\", \"concern\", \"acknowledge\"]\n",
        "    empathy1 = sum(1 for word in empathy_keywords if word in response1.lower())\n",
        "    empathy2 = sum(1 for word in empathy_keywords if word in response2.lower())\n",
        "\n",
        "    # Add empathy scores to the total, using the empathy weight to impact final scoring\n",
        "    score1 += empathy_weight * empathy1\n",
        "    score2 += empathy_weight * empathy2\n",
        "\n",
        "    # Enhanced Role Alignment: Use role-specific keywords and tone expectations\n",
        "    employer_keywords = [\"budget\", \"salary cap\", \"competitive offer\", \"company values\", \"cost-effective\"]\n",
        "    employee_keywords = [\"career growth\", \"benefits\", \"development opportunities\", \"long-term fit\", \"role alignment\"]\n",
        "\n",
        "    # Check for role alignment keywords and phrases based on the assistant role\n",
        "    alignment_score1 = sum(1 for word in (employer_keywords if assistant_role == \"employer\" else employee_keywords) if word in response1.lower())\n",
        "    alignment_score2 = sum(1 for word in (employer_keywords if assistant_role == \"employer\" else employee_keywords) if word in response2.lower())\n",
        "\n",
        "    # Add the role alignment score with a suitable weight\n",
        "    score1 += role_alignment_weight * alignment_score1\n",
        "    score2 += role_alignment_weight * alignment_score2\n",
        "\n",
        "    # Additional Role Tone Check\n",
        "    if assistant_role == \"employer\" and TextBlob(response1).sentiment.polarity < 0:\n",
        "        score1 += role_alignment_weight * 0.5  # Reward for firm/neutral employer tone\n",
        "    if assistant_role == \"employee\" and TextBlob(response2).sentiment.polarity > 0.2:\n",
        "        score2 += role_alignment_weight * 0.5  # Reward for positive/enthusiastic employee tone\n",
        "\n",
        "    # Return the response with the higher score\n",
        "    return response1 if score1 >= score2 else response2\n",
        "\n",
        "# Function for the playoff selection process to identify the best response\n",
        "def playoff_selection(responses):\n",
        "    reward_score = calculate_reward()  # Calculate the reward score for the assistant to factor into comparisons\n",
        "\n",
        "    # Continue comparing responses in pairs until only one response remains (the \"winner\")\n",
        "    while len(responses) > 1:\n",
        "        next_round = []\n",
        "        # Loop through responses in pairs\n",
        "        for i in range(0, len(responses), 2):\n",
        "            if i + 1 < len(responses):\n",
        "                # Compare two responses and keep the \"winning\" one\n",
        "                winner = compare_responses(responses[i], responses[i + 1], reward_score)\n",
        "                next_round.append(winner)\n",
        "            else:\n",
        "                # If there's an odd response left, it automatically advances to the next round\n",
        "                next_round.append(responses[i])\n",
        "        # Update responses to contain only those that won this round\n",
        "        responses = next_round\n",
        "\n",
        "    # Return the final winning response, or None if no responses were provided\n",
        "    return responses[0] if responses else None\n",
        "\n",
        "# Function to analyze tone in the text, detecting frustration, hesitation, or excitement\n",
        "def detect_tone(text):\n",
        "    # Use TextBlob to get a polarity score, where negative values indicate negative sentiment\n",
        "    textblob_sentiment = TextBlob(text).sentiment.polarity\n",
        "\n",
        "    # Use VADER to get a set of sentiment scores, focusing on the compound score for overall sentiment\n",
        "    vader_scores = vader_analyzer.polarity_scores(text)\n",
        "    vader_compound = vader_scores['compound']\n",
        "\n",
        "    # Start with a default tone of \"neutral\"\n",
        "    tone = \"neutral\"\n",
        "\n",
        "    # Check for frustration: if either TextBlob or VADER score is notably negative, or if frustration words are present\n",
        "    if textblob_sentiment < -0.2 or vader_compound < -0.2 or any(word in text.lower() for word in [\"frustrated\", \"unfair\", \"ridiculous\"]):\n",
        "        tone = \"frustrated\"\n",
        "    # Check for hesitation: if both sentiment scores are close to neutral and hesitant keywords are found\n",
        "    elif -0.1 <= textblob_sentiment <= 0.1 and -0.1 <= vader_compound <= 0.1 and any(word in text.lower() for word in [\"maybe\", \"perhaps\", \"not sure\", \"possibly\"]):\n",
        "        tone = \"hesitant\"\n",
        "    # Check for excitement: if both sentiment scores are positive and excitement-related keywords are present\n",
        "    elif textblob_sentiment > 0.2 and vader_compound > 0.2 and any(word in text.lower() for word in [\"great\", \"excited\", \"awesome\", \"perfect\"]):\n",
        "        tone = \"excited\"\n",
        "\n",
        "    # Return the detected tone for use in guiding responses\n",
        "    return tone\n",
        "\n",
        "# Set up Gradio text outputs for displaying initial price, final price, and negotiation score\n",
        "initial_price_output = gr.Textbox(label=\"Initial Price\", interactive=False)\n",
        "final_price_output = gr.Textbox(label=\"Final Price\", interactive=False)\n",
        "score_output = gr.Textbox(label=\"Negotiation Score\", interactive=False)\n",
        "\n",
        "# Define the maximum number of negotiation tries\n",
        "MAX_TRY_LIMIT = 20\n",
        "try_counter = 0  # Initialize try counter\n",
        "\n",
        "def is_agreement_message(message):\n",
        "    \"\"\"\n",
        "    Detect if a message indicates an agreement using semantic similarity.\n",
        "    \"\"\"\n",
        "    # Define agreement templates\n",
        "    agreement_templates = [\n",
        "        \"I accept the offer.\",\n",
        "        \"We have an agreement.\",\n",
        "        \"That works for me.\",\n",
        "        \"Deal accepted.\",\n",
        "        \"I am happy to proceed with these terms.\",\n",
        "        \"I agree with the final terms.\",\n",
        "        \"Let's finalize this.\",\n",
        "        \"This works let sign\"\n",
        "    ]\n",
        "\n",
        "    # Compute embeddings for the input message and templates\n",
        "    message_embedding = model.encode(message, convert_to_tensor=True)\n",
        "    template_embeddings = model.encode(agreement_templates, convert_to_tensor=True)\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    similarity_scores = util.pytorch_cos_sim(message_embedding, template_embeddings)\n",
        "\n",
        "    # Return True if the highest similarity score exceeds the threshold\n",
        "    max_similarity = similarity_scores.max().item()\n",
        "    print(f\"DEBUG: Max similarity score for agreement detection: {max_similarity}\")\n",
        "    return max_similarity > 0.8  # Adjust threshold as needed\n",
        "\n",
        "\n",
        "# Adjust the negotiate and end_game functions to pass only references\n",
        "def negotiate(user_input, user_audio, name, company_name, position, assistant_role):\n",
        "    global messages, conversation_history, final_salary, try_counter, concession_count\n",
        "\n",
        "    # Handle audio input if provided\n",
        "    if user_audio:\n",
        "        audio_text = audio_to_text(user_audio)\n",
        "        user_input = f\"{user_input} {audio_text}\".strip() if user_input else audio_text\n",
        "        print(f\"DEBUG: Final combined user input: {user_input}\")\n",
        "\n",
        "    if not user_input:\n",
        "        print(\"DEBUG: No valid input detected from text or audio.\")\n",
        "        return format_chat_history(), \"\", \"\", \"\", \"Please provide a valid input.\", None, None\n",
        "\n",
        "    # Debugging: Print initial state before processing\n",
        "    print(\"DEBUG: Starting negotiation with user_input:\", user_input)\n",
        "    print(\"DEBUG: Initial conversation_history:\", conversation_history)\n",
        "\n",
        "    # Validate assistant_role\n",
        "    if assistant_role not in [\"employer\", \"employee\"]:\n",
        "        print(f\"ERROR: Invalid assistant role: {assistant_role}. Defaulting to 'employer'.\")\n",
        "        assistant_role = \"employer\"  # Set a default role to avoid crashing\n",
        "\n",
        "    # Load the appropriate reference text based on assistant role\n",
        "    references, combined_reference_text = load_reference_text(assistant_role)\n",
        "    if not references:\n",
        "        print(f\"ERROR: No references loaded for role {assistant_role}. Using default reference.\")\n",
        "        references = [\"Default fallback reference response.\"]\n",
        "        combined_reference_text = \"Default fallback reference response.\"\n",
        "\n",
        "    # Detect if the user input is salary-related\n",
        "    is_salary_related = extract_salary(user_input) is not None\n",
        "    print(f\"DEBUG: Is the user message salary-related? {is_salary_related}\")\n",
        "\n",
        "    # Update salary figures based on the user's input\n",
        "    update_salaries(user_input, is_user_message=True)\n",
        "\n",
        "    # Debugging: Check if final_salary was updated\n",
        "    if final_salary is None:\n",
        "        print(\"DEBUG: No valid salary found in user's message.\")\n",
        "\n",
        "    # Analyze the tone of the user's input\n",
        "    user_tone = detect_tone(user_input)\n",
        "    print(\"DEBUG: Detected user tone:\", user_tone)\n",
        "\n",
        "    # Save the user's input and tone in the conversation history\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "    conversation_history.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_input,\n",
        "        \"tone\": user_tone,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    })\n",
        "\n",
        "    # Increment try counter\n",
        "    try_counter += 1\n",
        "    print(f\"DEBUG: Try Counter: {try_counter}\")\n",
        "\n",
        "    # Check if max try limit or max concession count has been reached\n",
        "    if try_counter >= MAX_TRY_LIMIT or concession_count >= MAX_CONCESSIONS:\n",
        "        ultimatum_response = (\n",
        "            f\"As the {assistant_role}, I've reached my limit on adjusting terms. \"\n",
        "            \"This is my final offer—please take it or leave it based on what has been proposed so far.\"\n",
        "        )\n",
        "\n",
        "        # Save the ultimatum message in conversation history\n",
        "        messages.append({\"role\": \"assistant\", \"content\": ultimatum_response})\n",
        "        conversation_history.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": ultimatum_response,\n",
        "            \"tone\": \"firm\",\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        })\n",
        "\n",
        "        # Debugging message\n",
        "        print(\"DEBUG: Reached max try limit or max concessions. Ending the game after ultimatum.\")\n",
        "\n",
        "        # Call end_game and return its outputs\n",
        "        chat_history, init_salary, fin_salary, _, feedback = end_game()\n",
        "\n",
        "        # Return the outputs, setting score_output to an empty string\n",
        "        return chat_history, init_salary, fin_salary, '', feedback\n",
        "\n",
        "    # Retrieve relevant context using RAG\n",
        "    context = search_vector_database(user_input, combined_reference_text)\n",
        "\n",
        "    print(\"DEBUG: Retrieved context from RAG:\", context)\n",
        "\n",
        "    # Evaluate retrieval\n",
        "    ground_truth = combined_reference_text  # Loaded based on assistant role\n",
        "    retrieved_contexts = context.split(\". \")\n",
        "    retrieval_metrics = evaluate_retrieval(user_input, retrieved_contexts, ground_truth)\n",
        "    retrieval_metrics_str = \"\\n\".join(f\"{key}: {value:.3f}\" for key, value in retrieval_metrics.items())\n",
        "\n",
        "    # Create a refined prompt using context and tone based on assistant's role\n",
        "    if assistant_role == \"employer\":\n",
        "        prompt_with_context = (\n",
        "            f\"The {user_role} is negotiating a salary, and their tone seems to be {user_tone}. \"\n",
        "            f\"Here’s some relevant context from our negotiation documents:\\n\\n{context}\\n\\n\"\n",
        "            \"Use this information to shape your response, but don’t quote it directly. \"\n",
        "            \"Imagine you’re sitting across from them—keep it professional and firm, with a focus on aligning with budget constraints. \"\n",
        "            f\"As the {assistant_role} in this negotiation with {name}, who is the {user_role} at {company_name} for the position of {position}, \"\n",
        "            \"remember to stay within the company’s budget limits and emphasize the advantages of the role.\"\n",
        "\n",
        "            \"\\n\\nKey guidelines for the employer:\\n\"\n",
        "            \"- **Budget Focus**: Clearly state the budget and be transparent about constraints.\\n\"\n",
        "            \"- **Highlight Non-monetary Benefits**: Emphasize growth opportunities, team culture, and job stability.\\n\"\n",
        "            \"- **Limit Concessions**: Avoid too many concessions; instead, underscore the role's value and benefits.\\n\"\n",
        "            \"- **Walk-Away Readiness**: Prepare to politely end the negotiation if demands exceed what the company can offer.\\n\"\n",
        "        )\n",
        "    elif assistant_role == \"employee\":\n",
        "        prompt_with_context = (\n",
        "            f\"The {user_role} is negotiating a salary, and their tone seems to be {user_tone}. \"\n",
        "            f\"Here’s some relevant context from our negotiation documents:\\n\\n{context}\\n\\n\"\n",
        "            \"Use this information to shape your response, but don’t quote it directly. \"\n",
        "            \"Imagine you’re sitting across from them—keep it professional and confident, focusing on your skills and future contributions. \"\n",
        "            f\"As the {assistant_role} in this negotiation with {name}, who is the {user_role} at {company_name} for the position of {position}, \"\n",
        "            \"advocate for a package that aligns with your financial and career goals while remaining flexible in discussing benefits.\"\n",
        "\n",
        "            \"\\n\\nKey guidelines for the prospective employee:\\n\"\n",
        "            \"- **Emphasize Skills and Contributions**: Highlight your qualifications and potential impact.\\n\"\n",
        "            \"- **Discuss Long-term Growth**: Emphasize your commitment to the company and potential contributions.\\n\"\n",
        "            \"- **Balance Expectations**: Be open to discussing non-monetary benefits while staying firm on core salary expectations.\\n\"\n",
        "            \"- **Professional Language**: Negotiate respectfully, showing both ambition and willingness to compromise on non-salary perks.\\n\"\n",
        "        )\n",
        "\n",
        "    # Add common guidance for both roles\n",
        "    prompt_with_context += (\n",
        "        \"\\n\\nGeneral Guidance:\\n\"\n",
        "        \"- **Empathy and Connection**: Show understanding without over-committing.\\n\"\n",
        "        \"- **Professional Language**: Use confident expressions and maintain professionalism.\\n\"\n",
        "        \"- **Focus on Value Proposition**: Aim for a win-win outcome while staying within role constraints.\\n\"\n",
        "        \"- **Natural Pauses and Imperfect Language**: Aim for a natural, conversational tone that includes small, relatable pauses or casual expressions. \"\n",
        "        \"Don’t worry about sounding perfectly formal; the goal is to feel genuine and personable.\\n\"\n",
        "        \"  - Use natural pauses like ‘you know,’ ‘honestly,’ or ‘to be fair,’ to sound more human.\\n\"\n",
        "        \"  - It’s okay to use slight imperfections like ‘Hmm, let me think about that for a second…’ or ‘I mean, honestly, I get where you’re coming from on that.’\\n\"\n",
        "        \"  - If appropriate, add a lighthearted or humorous comment to keep things friendly, like ‘I know, negotiating isn’t always the most exciting part, right?’\\n\"\n",
        "        \"  - Use empathetic phrases that acknowledge the other’s perspective, like ‘I hear you—it’s a big decision. Let’s see if we can make this work for both sides.’\"\n",
        "    )\n",
        "\n",
        "    # Generate a single response using OpenAI API\n",
        "    assistant_response = openai.ChatCompletion.create(\n",
        "        model=\"ft:gpt-4o-2024-08-06:llm-sim:salary-negotiation:AQN5Azuo\",\n",
        "        messages=messages + [{\"role\": \"system\", \"content\": prompt_with_context}],\n",
        "        max_tokens=3000,\n",
        "        temperature=0.5\n",
        "    )['choices'][0]['message']['content']\n",
        "\n",
        "    print(\"DEBUG: Assistant response generated:\", assistant_response)\n",
        "\n",
        "    # Generate audio from the assistant's response\n",
        "    audio_filename = text_to_audio(assistant_response, filename=\"assistant_response.mp3\")\n",
        "\n",
        "    # Update salary figures based on the assistant's response\n",
        "    update_salaries(assistant_response, is_user_message=False)\n",
        "\n",
        "    # Debugging: Check final_salary after assistant response\n",
        "    print(\"DEBUG: Final salary after assistant's response:\", final_salary)\n",
        "\n",
        "    # Analyze the tone of the assistant's response\n",
        "    assistant_tone = detect_tone(assistant_response)\n",
        "    print(\"DEBUG: Detected assistant tone:\", assistant_tone)\n",
        "\n",
        "    # Save the assistant's response and metrics to the conversation history\n",
        "    messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "    # Calculate BLEU, ROUGE, and METEOR scores for the assistant response\n",
        "    reference_response = get_reference_response(user_input, references)\n",
        "    if not reference_response:\n",
        "        reference_response = \"Default fallback reference response.\"\n",
        "        print(\"WARNING: No reference response found. Metrics may be inaccurate.\")\n",
        "\n",
        "    # Fallback for missing reference:\n",
        "    if not reference_response or reference_response == \"No suitable reference found. Default response.\":\n",
        "        reference_response = \"Default fallback reference response\"\n",
        "    print(f\"DEBUG: Loaded {len(references)} references for role {assistant_role}.\")\n",
        "\n",
        "    bleu, rouge, meteor = calculate_textual_metrics(reference_response, assistant_response)\n",
        "\n",
        "    coherence_score = ge_val(reference_response, assistant_response)\n",
        "    nli = nli_score(reference_response, assistant_response)\n",
        "    qag = qag_score(reference_response, assistant_response)\n",
        "    bert_f1 = calculate_bertscore(reference_response, assistant_response)\n",
        "\n",
        "    # Append the assistant's response with metrics to conversation history\n",
        "    conversation_history.append({\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": assistant_response,\n",
        "        \"tone\": assistant_tone,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"bleu\": bleu,\n",
        "        \"rouge\": rouge,\n",
        "        \"meteor\": meteor,\n",
        "        \"bert_score\": float(bert_f1),  # Ensure it's a serializable float\n",
        "        \"coherence_score\": coherence_score,\n",
        "        \"nli_score\": nli,\n",
        "        \"qag_score\": qag\n",
        "    })\n",
        "\n",
        "    # Debugging: Print conversation history after adding assistant's response\n",
        "    print(\"DEBUG: Updated conversation_history:\", conversation_history)\n",
        "\n",
        "    # Calculate a reward or penalty for the assistant based on the negotiation outcome\n",
        "    reward = calculate_reward()\n",
        "    print(\"DEBUG: Calculated reward:\", reward)\n",
        "\n",
        "    # Prepare initial and final salary values for display\n",
        "    formatted_initial_salary = f\"${initial_salary:,.2f}\" if initial_salary else \"Not set\"\n",
        "    formatted_final_salary = f\"${final_salary:,.2f}\" if final_salary else \"No final salary set yet\"\n",
        "\n",
        "    # Return formatted conversation history, initial and final salary figures, and the negotiation score\n",
        "    return format_chat_history(), formatted_initial_salary, formatted_final_salary, reward, '', retrieval_metrics_str, audio_filename\n",
        "\n",
        "\n",
        "# Function to format the chat history for a user-friendly display in the UI\n",
        "def format_chat_history():\n",
        "    \"\"\"Format the chat history to look like a conversation in the UI.\"\"\"\n",
        "\n",
        "    # Debugging: Print the entire conversation history before formatting\n",
        "    print(\"Conversation history before formatting:\", conversation_history)\n",
        "\n",
        "    chat_history = []  # Initialize an empty list to hold formatted messages\n",
        "\n",
        "    # Loop through each message in the conversation history\n",
        "    for message in conversation_history:\n",
        "        # Debugging: Print each message being processed to see if there are duplicates\n",
        "        print(\"Processing message:\", message)  # Debugging print\n",
        "\n",
        "        # Label messages from the user as \"You\" for clarity in the UI\n",
        "        if message[\"role\"] == \"user\":\n",
        "            chat_history.append((\"You\", message[\"content\"]))\n",
        "        # Label messages from the assistant as \"Assistant\" for clarity\n",
        "        elif message[\"role\"] == \"assistant\":\n",
        "            chat_history.append((\"Assistant\", message[\"content\"]))\n",
        "\n",
        "    # Return the formatted chat history as a list of tuples for the UI\n",
        "    return chat_history\n",
        "\n",
        "\n",
        "###JSONL FILES APPEND AND SAVE FILE CODE BELOW\n",
        "\n",
        "from google.cloud import bigquery\n",
        "import json\n",
        "\n",
        "# Hardcoded BigQuery configuration\n",
        "BQ_DATASET_ID = \"negotiation_data\"\n",
        "BQ_TABLE_ID = \"conversation\"\n",
        "BQ_PROJECT_ID = \"llm-sim\"\n",
        "\n",
        "def save_jsonl_to_bigquery(jsonl_data):\n",
        "    \"\"\"\n",
        "    Save JSONL data to BigQuery.\n",
        "\n",
        "    Parameters:\n",
        "        jsonl_data (list): List of JSONL-formatted data to be stored in BigQuery.\n",
        "    \"\"\"\n",
        "    if not jsonl_data:\n",
        "        print(\"DEBUG: No JSONL data to save.\")\n",
        "        return\n",
        "\n",
        "    # BigQuery client\n",
        "    client = bigquery.Client(project=BQ_PROJECT_ID)\n",
        "\n",
        "    # Fully qualified table ID\n",
        "    table_ref = f\"{BQ_PROJECT_ID}.{BQ_DATASET_ID}.{BQ_TABLE_ID}\"\n",
        "\n",
        "    # Transform JSONL data into BigQuery-compatible format\n",
        "    rows_to_insert = []\n",
        "    for record in jsonl_data:\n",
        "        # Handle records with a valid \"messages\" array\n",
        "        if \"messages\" in record and isinstance(record[\"messages\"], list) and record[\"messages\"]:\n",
        "            messages = [\n",
        "                {\"role\": message[\"role\"], \"content\": message[\"content\"]}\n",
        "                for message in record[\"messages\"]\n",
        "            ]\n",
        "            rows_to_insert.append({\"messages\": messages})\n",
        "        # Handle flat records with \"role\" and \"content\"\n",
        "        elif \"role\" in record and \"content\" in record:\n",
        "            messages = [{\"role\": record[\"role\"], \"content\": record[\"content\"]}]\n",
        "            rows_to_insert.append({\"messages\": messages})\n",
        "        else:\n",
        "            print(f\"DEBUG: Skipping record with invalid structure: {record}\")\n",
        "\n",
        "    print(f\"DEBUG: Rows to insert: {json.dumps(rows_to_insert, indent=2)}\")\n",
        "\n",
        "    # Ensure there are rows to insert\n",
        "    if not rows_to_insert:\n",
        "        print(\"DEBUG: No valid rows to insert into BigQuery.\")\n",
        "        return\n",
        "\n",
        "    # Insert rows into BigQuery\n",
        "    try:\n",
        "        errors = client.insert_rows_json(table_ref, rows_to_insert)\n",
        "        if errors:\n",
        "            print(f\"DEBUG: Errors occurred while inserting rows: {errors}\")\n",
        "        else:\n",
        "            print(f\"DEBUG: Data successfully saved to BigQuery table: {table_ref}\")\n",
        "    except Exception as e:\n",
        "        print(f\"DEBUG: Error saving JSONL data to BigQuery - {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Function to save the conversation history in OpenAI's fine-tuning format\n",
        "# def save_conversation_as_jsonl_format(conversation_history, filename=\"negotiation_conversation_history.jsonl\"):\n",
        "#     \"\"\"\n",
        "#     Save the conversation history as per OpenAI's fine-tuning format:\n",
        "#     {\"messages\": [{\"role\": \"system\", \"content\": \"...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
        "#     \"\"\"\n",
        "#     if not conversation_history:\n",
        "#         print(\"DEBUG: No conversation history to save.\")\n",
        "#         return\n",
        "\n",
        "#     # Determine roles for system message\n",
        "#     if assistant_role and user_role:\n",
        "#         system_content = f\"This is a salary negotiation. The assistant is the {assistant_role}, and the user is the {user_role}.\"\n",
        "#     else:\n",
        "#         system_content = \"This is a salary negotiation.\"\n",
        "\n",
        "#     # Initialize messages with the system prompt\n",
        "#     messages_list = [\n",
        "#         {\"role\": \"system\", \"content\": system_content}\n",
        "#     ]\n",
        "\n",
        "#     # Collect conversation messages\n",
        "#     for message in conversation_history:\n",
        "#         if \"content\" in message and message[\"role\"] in [\"user\", \"assistant\"]:\n",
        "#             # Only include 'role' and 'content' keys\n",
        "#             messages_list.append({\n",
        "#                 \"role\": message[\"role\"],\n",
        "#                 \"content\": message[\"content\"]\n",
        "#             })\n",
        "\n",
        "#     # Prepare the conversation data\n",
        "#     conversation_data = {\n",
        "#         \"messages\": messages_list\n",
        "#     }\n",
        "\n",
        "#     try:\n",
        "#         # Open file in append mode to add the conversation as a single JSONL line\n",
        "#         with open(filename, 'a', encoding='utf-8') as file:\n",
        "#             json.dump(conversation_data, file)\n",
        "#             file.write('\\n')  # Ensure each JSON object is on a new line\n",
        "#         print(f\"DEBUG: Conversation history saved as JSONL to {filename}\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"DEBUG: Error saving JSONL file - {e}\")\n",
        "\n",
        "\n",
        "# Global flag for saving status\n",
        "metrics_saved = False\n",
        "#####CSV METRICS TO BIG QUERY\n",
        "from google.cloud import bigquery\n",
        "import json\n",
        "\n",
        "# Hardcoded BigQuery details (update as needed)\n",
        "BQ_PROJECT_ID1 = \"llm-sim\"\n",
        "BQ_DATASET_ID1 = \"negotiation_data\"\n",
        "BQ_TABLE_ID1 = \"metrics\"\n",
        "\n",
        "def save_metrics_and_conversation_to_bigquery(conversation_id, metrics, conversation_history):\n",
        "    \"\"\"\n",
        "    Save metrics and conversation data to BigQuery.\n",
        "\n",
        "    Parameters:\n",
        "        conversation_id (str): Unique identifier for the conversation.\n",
        "        metrics (dict): Metrics data for the conversation.\n",
        "        conversation_history (list): List of conversation messages.\n",
        "    \"\"\"\n",
        "    # BigQuery client\n",
        "    client = bigquery.Client(project=BQ_PROJECT_ID1)\n",
        "\n",
        "    # Fully qualified table ID\n",
        "    table_ref1 = f\"{BQ_PROJECT_ID1}.{BQ_DATASET_ID1}.{BQ_TABLE_ID1}\"\n",
        "\n",
        "    # Transform metrics data into BigQuery-compatible format\n",
        "    metrics_data1 = {\n",
        "        \"Timestamp\": metrics[\"timestamp\"],\n",
        "        \"Agreement_Rate\": metrics[\"agreement_rate\"],\n",
        "        \"Average_Sentiment_Score\": metrics[\"avg_sentiment\"],\n",
        "        \"Feedback_Quality\": metrics[\"feedback_quality\"],\n",
        "        \"Average_Response_Time\": metrics[\"avg_response_time\"],\n",
        "        \"Corpus_BLEU\": metrics[\"BLEU\"],\n",
        "        \"ROUGE\": metrics[\"ROUGE\"],\n",
        "        \"METEOR\": metrics[\"METEOR\"],\n",
        "        \"BERTScore\": metrics[\"BERTScore\"],\n",
        "        \"G_Eval\": metrics[\"G-Eval\"],\n",
        "        \"NLI\": metrics[\"NLI\"],\n",
        "        \"QAG\": metrics[\"QAG\"],\n",
        "        \"TTR\": metrics[\"TTR\"],\n",
        "        \"Pause_Ratio\": metrics[\"Pause Ratio\"],\n",
        "        \"Average_Turn_Length\": metrics[\"Average Turn Length\"],\n",
        "        \"MAUVE\": metrics[\"MAUVE\"],\n",
        "        \"USL_H\": metrics[\"USL-H\"],\n",
        "        \"Reward_Score\": metrics[\"reward_score\"],\n",
        "        \"Conversation_History\": json.dumps(conversation_history)\n",
        "    }\n",
        "\n",
        "    # Prepare the row to insert\n",
        "    rows_to_insert1 = [metrics_data1]\n",
        "\n",
        "    print(f\"DEBUG: Rows to insert: {json.dumps(rows_to_insert1, indent=2)}\")\n",
        "\n",
        "    # Insert rows into BigQuery\n",
        "    try:\n",
        "        errors = client.insert_rows_json(table_ref1, rows_to_insert1)\n",
        "        if errors:\n",
        "            print(f\"DEBUG: Errors occurred while inserting rows: {errors}\")\n",
        "        else:\n",
        "            print(f\"DEBUG: Metrics and conversation history saved to BigQuery table: {table_ref1}\")\n",
        "    except Exception as e:\n",
        "        print(f\"DEBUG: Error saving metrics to BigQuery - {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def save_metrics_and_conversation_to_csv(conversation_id, metrics, conversation_history, filename=\"negotiation_metrics.csv\"):\n",
        "#     global metrics_saved  # Declare the variable as global\n",
        "\n",
        "#     if metrics_saved:\n",
        "#         print(\"DEBUG: Metrics already saved for this session. Skipping save.\")\n",
        "#         return\n",
        "\n",
        "#     # Save metrics and conversation to the CSV file\n",
        "#     metrics_data = {\n",
        "#         \"Timestamp\": metrics[\"timestamp\"],\n",
        "#         \"Agreement Rate\": metrics[\"agreement_rate\"],\n",
        "#         \"Average Sentiment Score\": metrics[\"avg_sentiment\"],\n",
        "#         \"Feedback Quality\": metrics[\"feedback_quality\"],\n",
        "#         \"Average Response Time\": metrics[\"avg_response_time\"],\n",
        "#         \"Corpus BLEU\": metrics[\"BLEU\"],\n",
        "#         \"ROUGE\": metrics[\"ROUGE\"],\n",
        "#         \"METEOR\": metrics[\"METEOR\"],\n",
        "#         \"BERTScore\": metrics[\"BERTScore\"],\n",
        "#         \"G-Eval\": metrics[\"G-Eval\"],\n",
        "#         \"NLI\": metrics[\"NLI\"],\n",
        "#         \"QAG\": metrics[\"QAG\"],\n",
        "#         \"TTR\": metrics[\"TTR\"],  # Add TTR\n",
        "#         \"Pause Ratio\": metrics[\"Pause Ratio\"],  # Add Pause Ratio\n",
        "#         \"Average Turn Length\": metrics[\"Average Turn Length\"],  # Add Average Turn Length\n",
        "#         \"MAUVE\": metrics[\"MAUVE\"],  # Add MAUVE Score\n",
        "#         \"USL-H\": metrics[\"USL-H\"],  # Add USL-H\n",
        "#         \"Reward Score\": metrics[\"reward_score\"],  # Include reward/penalty\n",
        "#         \"Conversation History\": json.dumps(conversation_history)  # Store entire conversation as JSON\n",
        "#     }\n",
        "\n",
        "#     try:\n",
        "#         # Load existing file if it exists\n",
        "#         if os.path.isfile(filename):\n",
        "#             existing_df = pd.read_csv(filename)\n",
        "#             new_row_df = pd.DataFrame([metrics_data]).dropna(how=\"all\")\n",
        "#             updated_df = pd.concat([existing_df, new_row_df], ignore_index=True).drop_duplicates(keep='last')\n",
        "#         else:\n",
        "#             updated_df = pd.DataFrame([metrics_data]).dropna(how=\"all\")\n",
        "\n",
        "#         # Save back to CSV\n",
        "#         updated_df.to_csv(filename, index=False)\n",
        "#         print(f\"DEBUG: Metrics and conversation history saved to {filename} successfully.\")\n",
        "\n",
        "#         metrics_saved = True  # Mark as saved to prevent duplicates\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"DEBUG: Error saving metrics to CSV: {e}\")\n",
        "\n",
        "\n",
        "# Function to end the game, calculate final reward/penalty, save the conversation, and provide feedback\n",
        "def end_game():\n",
        "    global messages, conversation_history, initial_salary, final_salary\n",
        "\n",
        "    # Generate a unique conversation ID\n",
        "    conversation_id = generate_conversation_id()\n",
        "\n",
        "    # Calculate the final reward or penalty for the negotiation session\n",
        "    reward = calculate_reward()\n",
        "\n",
        "    # Append this reward information as a system message in the conversation history\n",
        "    conversation_history.append({\n",
        "        \"role\": \"system\",\n",
        "        \"reward_score\": reward,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    })\n",
        "\n",
        "    # Define a prompt to get feedback on the completed negotiation\n",
        "    feedback_prompt = (\n",
        "        \"Based on the negotiation that just ended, provide a detailed evaluation. \"\n",
        "        \"Mention what went well, what could have been improved, and offer suggestions \"\n",
        "        \"for both the buyer and the seller to help them improve in the future.\"\n",
        "    )\n",
        "\n",
        "    # Generate feedback from the assistant using OpenAI's API and the feedback prompt\n",
        "    try:\n",
        "        feedback_response = openai.ChatCompletion.create(\n",
        "            model=\"ft:gpt-4o-2024-08-06:llm-sim:salary-negotiation:AQN5Azuo\",\n",
        "            messages=messages + [{\"role\": \"user\", \"content\": feedback_prompt}],\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        # Extract the feedback content from the response\n",
        "        feedback = feedback_response['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        print(f\"DEBUG: Error generating feedback - {e}\")\n",
        "        feedback = \"Could not generate feedback due to an error.\"\n",
        "\n",
        "    # Generate audio from the feedback\n",
        "    audio_feedback_filename = text_to_audio(feedback, filename=\"feedback_audio.mp3\")\n",
        "\n",
        "    # Append the final reward/penalty score to the feedback\n",
        "    feedback += f\"\\n\\n**Final Reward/Penalty Score:** {reward}\"\n",
        "\n",
        "    # Call the evaluate_model function to get only the summary\n",
        "    try:\n",
        "        summary = evaluate_model(conversation_id)\n",
        "    except Exception as e:\n",
        "        print(f\"DEBUG: Error evaluating model - {e}\")\n",
        "        summary = \"Evaluation could not be completed due to an error.\"\n",
        "\n",
        "    # Call the function to save conversation history in the specified JSONL format\n",
        "    try:\n",
        "        save_jsonl_to_bigquery(conversation_history)\n",
        "        print(\"DEBUG: JSONL file saved successfully at end of game.\")\n",
        "    except Exception as e:\n",
        "        print(f\"DEBUG: Error saving conversation history - {e}\")\n",
        "\n",
        "    # Format initial and final salary for output\n",
        "    formatted_initial_salary = f\"${initial_salary:,.2f}\" if initial_salary else \"Not set\"\n",
        "    formatted_final_salary = f\"${final_salary:,.2f}\" if final_salary else \"No final salary set yet\"\n",
        "\n",
        "    # Debugging final outputs\n",
        "    print(f\"DEBUG: Final Reward: {reward}\")\n",
        "    print(f\"DEBUG: Feedback: {feedback}\")\n",
        "    print(f\"DEBUG: Initial Salary: {formatted_initial_salary}, Final Salary: {formatted_final_salary}\")\n",
        "\n",
        "    # Return Gradio-compatible outputs\n",
        "    return format_chat_history(), formatted_initial_salary, formatted_final_salary, '', feedback, audio_feedback_filename\n",
        "\n",
        "def calculate_bertscore(reference, prediction):\n",
        "    # BERTScore expects lists of references and predictions\n",
        "    P, R, F1 = bert_score([prediction], [reference], lang=\"en\")\n",
        "    return F1.mean().item()  # Return the average F1 score\n",
        "\n",
        "def evaluate_retrieval(query, retrieved_contexts, ground_truth):\n",
        "    \"\"\"\n",
        "    Evaluate the effectiveness of the retrieval mechanism.\n",
        "    Parameters:\n",
        "    - query (str): The user query.\n",
        "    - retrieved_contexts (list of str): Contexts retrieved by the RAG system.\n",
        "    - ground_truth (str): The expected or ideal reference response.\n",
        "    Returns:\n",
        "    - dict: A dictionary containing metrics (accuracy, coverage, relevance, novelty).\n",
        "    \"\"\"\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "    ground_truth_embedding = model.encode(ground_truth, convert_to_tensor=True)\n",
        "    retrieved_embeddings = [model.encode(context, convert_to_tensor=True) for context in retrieved_contexts]\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    ground_truth_similarity = [util.pytorch_cos_sim(ground_truth_embedding, emb).item() for emb in retrieved_embeddings]\n",
        "    query_similarity = [util.pytorch_cos_sim(query_embedding, emb).item() for emb in retrieved_embeddings]\n",
        "\n",
        "    # Define metrics\n",
        "    retrieval_accuracy = any(score > 0.8 for score in ground_truth_similarity)\n",
        "    coverage = len(retrieved_contexts) / len(ground_truth.split()) if ground_truth else 0\n",
        "    relevance = np.mean(query_similarity) if query_similarity else 0\n",
        "    novelty = np.mean([1 - score for score in ground_truth_similarity]) if ground_truth_similarity else 0\n",
        "\n",
        "    return {\n",
        "        \"Retrieval Accuracy\": retrieval_accuracy,\n",
        "        \"Coverage\": coverage,\n",
        "        \"Relevance\": relevance,\n",
        "        \"Novelty\": novelty\n",
        "    }\n",
        "\n",
        "\n",
        "# Modify evaluate_model function\n",
        "def evaluate_model(conversation_id=None, references=None):\n",
        "    print(\"Evaluating model...\")\n",
        "\n",
        "    # Check if references are provided; if not, default to an empty list\n",
        "    if references is None:\n",
        "        references = []\n",
        "\n",
        "    # Ensure 'references' is a list of strings\n",
        "    string_references = []\n",
        "    for ref in references:\n",
        "        if isinstance(ref, list):\n",
        "            # If a reference is a list, join its elements into a single string\n",
        "            string_references.append(\" \".join(ref))\n",
        "        elif isinstance(ref, str):\n",
        "            string_references.append(ref)\n",
        "\n",
        "    # Combine reference texts for evaluation\n",
        "    combined_reference_text = \" \".join(string_references)\n",
        "\n",
        "    # Calculate the number of successful negotiations\n",
        "    successful_negotiations = sum(\n",
        "        1 for message in conversation_history if \"content\" in message and (\"agree\" in message[\"content\"].lower() or \"deal\" in message[\"content\"].lower())\n",
        "    )\n",
        "\n",
        "    # Calculate the total number of negotiations\n",
        "    total_negotiations = len([message for message in conversation_history if message[\"role\"] == \"user\"])\n",
        "    agreement_rate = successful_negotiations / total_negotiations if total_negotiations > 0 else 0\n",
        "\n",
        "    # Calculate the average sentiment of assistant messages\n",
        "    sentiment_scores = [\n",
        "        TextBlob(message[\"content\"]).sentiment.polarity\n",
        "        for message in conversation_history if message[\"role\"] == \"assistant\"\n",
        "    ]\n",
        "    avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0\n",
        "    feedback_quality = \"High\" if avg_sentiment > 0.3 else \"Moderate\" if avg_sentiment > 0 else \"Low\"\n",
        "\n",
        "    # File contribution metrics\n",
        "    total_contributions = sum(contribution_metrics.values())\n",
        "    file_contributions = {\n",
        "        file: (count / total_contributions) * 100 if total_contributions > 0 else 0\n",
        "        for file, count in contribution_metrics.items()\n",
        "    }\n",
        "    contribution_str = \"\\n\".join([f\"{file}: {contribution:.2f}%\" for file, contribution in file_contributions.items()])\n",
        "\n",
        "    # Average response time for assistant replies\n",
        "    avg_response_time = np.mean([\n",
        "        (datetime.fromisoformat(conversation_history[i + 1][\"timestamp\"]) - datetime.fromisoformat(message[\"timestamp\"])).total_seconds()\n",
        "        for i, message in enumerate(conversation_history[:-1])\n",
        "        if message[\"role\"] == \"user\" and \"timestamp\" in message and \"timestamp\" in conversation_history[i + 1]\n",
        "    ]) if len(conversation_history) > 1 else 0\n",
        "\n",
        "    # Initialize lists for new metrics\n",
        "    bleu_scores, rouge_scores, meteor_scores = [], [], []\n",
        "    bert_scores, g_eval_scores = [], []\n",
        "    nli_scores, qag_scores = [], []\n",
        "    ttr_scores, pause_ratios = [], []\n",
        "    avg_turn_lengths = []\n",
        "\n",
        "    # Calculate new metrics for assistant responses\n",
        "    assistant_responses = [msg for msg in conversation_history if msg[\"role\"] == \"assistant\"]\n",
        "    user_messages = [msg for msg in conversation_history if msg[\"role\"] == \"user\"]\n",
        "\n",
        "    for i, assistant_response in enumerate(assistant_responses):\n",
        "        if i < len(user_messages):\n",
        "            prediction = assistant_response[\"content\"]\n",
        "\n",
        "            # Textual Accuracy Metrics\n",
        "            bleu = corpus_bleu_eq([combined_reference_text], [prediction])\n",
        "            rouge = rouge_eq(combined_reference_text, prediction)\n",
        "            meteor = meteor_eq(combined_reference_text, prediction)\n",
        "            bleu_scores.append(bleu)\n",
        "            rouge_scores.append(rouge)\n",
        "            meteor_scores.append(meteor)\n",
        "\n",
        "            # Semantic Coherence Metrics\n",
        "            bert = calculate_bertscore(combined_reference_text, prediction)\n",
        "            g_eval = ge_val(combined_reference_text, prediction)\n",
        "            bert_scores.append(bert)\n",
        "            g_eval_scores.append(g_eval)\n",
        "\n",
        "            # Factual Accuracy Metrics\n",
        "            nli = nli_score(combined_reference_text, prediction)\n",
        "            qag = qag_score(combined_reference_text, prediction)\n",
        "            nli_scores.append(nli)\n",
        "            qag_scores.append(qag)\n",
        "\n",
        "            # Conversational Metrics\n",
        "            ttr = calculate_ttr(prediction)\n",
        "            pause_ratio = calculate_pause_ratio(prediction)\n",
        "            avg_turn_length = len(word_tokenize(prediction))\n",
        "            ttr_scores.append(ttr)\n",
        "            pause_ratios.append(pause_ratio)\n",
        "            avg_turn_lengths.append(avg_turn_length)\n",
        "\n",
        "    # Average Conversational Metrics\n",
        "    avg_ttr = np.mean(ttr_scores) if ttr_scores else 0\n",
        "    avg_pause_ratio = np.mean(pause_ratios) if pause_ratios else 0\n",
        "    avg_turn_length = np.mean(avg_turn_lengths) if avg_turn_lengths else 0\n",
        "\n",
        "    # MAUVE Metric\n",
        "    try:\n",
        "        # Ensure valid human and model texts before calculation\n",
        "        if not references or not assistant_responses:\n",
        "            print(\"DEBUG: Missing human or model texts for MAUVE calculation.\")\n",
        "            mauve_score = 0\n",
        "        else:\n",
        "            mauve_score = calculate_mauve_score(\n",
        "                human_texts=references,\n",
        "                model_texts=[msg[\"content\"] for msg in assistant_responses]\n",
        "            ) or 0  # Ensure a fallback to 0\n",
        "    except Exception as e:\n",
        "        print(f\"MAUVE calculation error: {e}\")\n",
        "        mauve_score = 0\n",
        "\n",
        "    # USL-H Metric\n",
        "    usl_h_scores = [\n",
        "        calculate_usl_h(nli, bert, sentiment)\n",
        "        for nli, bert, sentiment in zip(nli_scores, bert_scores, sentiment_scores)\n",
        "    ]\n",
        "    avg_usl_h = np.mean(usl_h_scores) if usl_h_scores else 0\n",
        "\n",
        "    # Calculate averages for existing metrics\n",
        "    avg_bleu = np.mean(bleu_scores) if bleu_scores else 0\n",
        "    avg_rouge = np.mean(rouge_scores) if rouge_scores else 0\n",
        "    avg_meteor = np.mean(meteor_scores) if meteor_scores else 0\n",
        "    avg_bert = np.mean(bert_scores) if bert_scores else 0\n",
        "    avg_g_eval = np.mean(g_eval_scores) if g_eval_scores else 0\n",
        "    avg_nli = np.mean(nli_scores) if nli_scores else 0\n",
        "    avg_qag = np.mean(qag_scores) if qag_scores else 0\n",
        "\n",
        "    # Create a dictionary to hold all metrics\n",
        "    metrics_dict = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"agreement_rate\": agreement_rate,\n",
        "        \"avg_sentiment\": avg_sentiment,\n",
        "        \"feedback_quality\": feedback_quality,\n",
        "        \"avg_response_time\": avg_response_time,\n",
        "        \"BLEU\": avg_bleu,\n",
        "        \"ROUGE\": avg_rouge,\n",
        "        \"METEOR\": avg_meteor,\n",
        "        \"BERTScore\": avg_bert,\n",
        "        \"G-Eval\": avg_g_eval,\n",
        "        \"NLI\": avg_nli,\n",
        "        \"QAG\": avg_qag,\n",
        "        \"TTR\": avg_ttr,\n",
        "        \"Pause Ratio\": avg_pause_ratio,\n",
        "        \"Average Turn Length\": avg_turn_length,\n",
        "        \"MAUVE\": mauve_score,\n",
        "        \"USL-H\": avg_usl_h,\n",
        "        \"conversation_id\": conversation_id,  # Unique identifier for each conversation\n",
        "        \"reward_score\": calculate_reward()  # Include final reward/penalty score\n",
        "    }\n",
        "\n",
        "    # Save the metrics and conversation to CSV\n",
        "    save_metrics_and_conversation_to_bigquery(conversation_id, metrics_dict, conversation_history)\n",
        "\n",
        "    # Create a summary string in the desired format\n",
        "    summary_string = (\n",
        "        f\"Model Evaluation Metrics:\\n\"\n",
        "        f\"Agreement Rate: {agreement_rate:.2f}\\n\"\n",
        "        f\"Average Sentiment Score: {avg_sentiment:.2f}\\n\"\n",
        "        f\"Feedback Quality: {feedback_quality}\\n\"\n",
        "        f\"Average Response Time: {avg_response_time:.2f}s\\n\\n\"\n",
        "        f\"Textual Accuracy - Corpus BLEU: {avg_bleu:.3f}, ROUGE: {avg_rouge:.3f}, METEOR: {avg_meteor:.3f}\\n\"\n",
        "        f\"Semantic Coherence - BERTScore: {avg_bert:.3f}, GEval: {avg_g_eval:.2f}\\n\"\n",
        "        f\"Factual Accuracy - NLI: {avg_nli:.2f}, QAG: {avg_qag:.2f}\\n\\n\"\n",
        "        f\"Conversational Metrics:\\n\"\n",
        "        f\"- Type-Token Ratio (TTR): {avg_ttr:.3f}\\n\"\n",
        "        f\"- Pause Ratio: {avg_pause_ratio:.3f}\\n\"\n",
        "        f\"- Average Turn Length: {avg_turn_length:.2f} words\\n\"\n",
        "        f\"- MAUVE Score: {mauve_score:.3f}\\n\"\n",
        "        f\"- USL-H Score: {avg_usl_h:.3f}\\n\\n\"\n",
        "        f\"File Contributions:\\n{contribution_str}\"\n",
        "    )\n",
        "\n",
        "    # Return only the summary string in the requested format\n",
        "    return summary_string\n",
        "\n",
        "\n",
        "\n",
        "# Function to reload files from the specified folder, excluding any listed files\n",
        "def update_loaded_files(exclude_files):\n",
        "    # Call the function to load PDFs, excluding any files specified in the 'exclude_files' string\n",
        "    # 'exclude_files' is a comma-separated string of filenames to exclude, so we split it into a list\n",
        "    load_pdfs_from_folder(\"RAG\", exclude_files=exclude_files.split(\",\"))\n",
        "\n",
        "    # Return a confirmation message with the updated list of loaded files\n",
        "    return f\"Updated file list: {', '.join(file_list)}\"\n",
        "\n",
        "\n",
        "\n",
        "# Textual Accuracy Metrics\n",
        "def corpus_bleu_eq(references, predictions):\n",
        "    tokenized_references = [[ref.split()] for ref in references]  # Corpus BLEU expects a list of lists of references\n",
        "    tokenized_predictions = [pred.split() for pred in predictions]\n",
        "    return corpus_bleu(tokenized_references, tokenized_predictions, smoothing_function=SmoothingFunction().method1)\n",
        "\n",
        "def rouge_eq(reference, prediction):\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(prediction, reference)\n",
        "    return scores[0]['rouge-l']['f']\n",
        "\n",
        "def meteor_eq(reference, prediction):\n",
        "    # Use TreebankWordTokenizer instead of word_tokenize\n",
        "    tokenizer = TreebankWordTokenizer()\n",
        "    tokenized_reference = tokenizer.tokenize(reference)\n",
        "    tokenized_prediction = tokenizer.tokenize(prediction)\n",
        "    return meteor_score.meteor_score([tokenized_reference], tokenized_prediction)\n",
        "\n",
        "# Function to evaluate model's response based on Textual Accuracy\n",
        "def calculate_textual_metrics(reference, prediction):\n",
        "    bleu = corpus_bleu_eq([reference], [prediction])  # Using list of single references for corpus BLEU\n",
        "    rouge = rouge_eq(reference, prediction)\n",
        "    meteor = meteor_eq(reference, prediction)\n",
        "    return bleu, rouge, meteor\n",
        "\n",
        "# Set up the Gradio interface layout and styling\n",
        "with gr.Blocks(css=\".gradio-container {max-width: 1000px; margin: auto; background-color: #1e1e1e; color: white; border-radius: 10px; padding: 20px;}\") as demo:\n",
        "    # Create a Markdown header for the interface title\n",
        "    gr.Markdown(\"## 🤝🤖 Salary Negotiation Assistant - Chat-Like Interface\", elem_id=\"title\")\n",
        "\n",
        "    # Define a row layout for the input and output sections\n",
        "    with gr.Row():\n",
        "        # Create a column for user inputs with a scale of 3\n",
        "        with gr.Column(scale=3):\n",
        "            # Define text inputs for user name, company, and position\n",
        "            name_input = gr.Textbox(lines=1, placeholder=\"Enter your name...\", label=\"Your Name\")\n",
        "            company_name_input = gr.Textbox(lines=1, placeholder=\"Enter your company name...\", label=\"Company Name\")\n",
        "            position_input = gr.Textbox(lines=1, placeholder=\"Enter your position...\", label=\"Your Position\")\n",
        "\n",
        "            # Radio buttons for the user to choose their role (employee or employer)\n",
        "            role_input = gr.Radio(choices=[\"employee\", \"employer\"], label=\"Choose your role\", interactive=True)\n",
        "\n",
        "            # Input for initial salary\n",
        "            initial_salary_input = gr.Textbox(lines=1, placeholder=\"Enter your current salary...\", label=\"Current Salary\")\n",
        "\n",
        "            # Button to start the negotiation game\n",
        "            start_button = gr.Button(\"Start Game\")\n",
        "\n",
        "            # Input for the negotiation message\n",
        "            user_text_input = gr.Textbox(lines=3, placeholder=\"Enter your negotiation message here...\", label=\"Your Message\")\n",
        "            user_audio_input = gr.Audio(label=\"Your Audio Message\", type=\"filepath\")\n",
        "\n",
        "\n",
        "            # Button to submit negotiation messages\n",
        "            negotiate_button = gr.Button(\"Negotiate\")\n",
        "\n",
        "            # Input to specify files to exclude from document loading\n",
        "            exclude_files_input = gr.Textbox(lines=1, placeholder=\"Enter file names to exclude, separated by commas\", label=\"Exclude Files\")\n",
        "\n",
        "            # Button to reload files based on exclusions\n",
        "            reload_button = gr.Button(\"Reload Files\")\n",
        "\n",
        "            # Button to end the negotiation game\n",
        "            end_button = gr.Button(\"End Game\")\n",
        "\n",
        "            # Button to evaluate model performance\n",
        "            evaluate_button = gr.Button(\"Evaluate Model\")\n",
        "\n",
        "        # Create a larger column (scale 7) for outputs\n",
        "        with gr.Column(scale=7):\n",
        "            # Chatbot display for conversation history\n",
        "            chat_output = gr.Chatbot(label=\"Chat History\", show_label=False, value=[], height=400)\n",
        "\n",
        "            audio_output = gr.Audio(label=\"Assistant Audio Response\", interactive=False, type=\"filepath\")\n",
        "\n",
        "            # Display for negotiation feedback from the assistant\n",
        "            feedback_output = gr.Textbox(label=\"Negotiation Feedback (Feedback can be inaccurate)\", lines=5, interactive=False)\n",
        "\n",
        "            # Display for showing model evaluation metrics\n",
        "            evaluate_output = gr.Textbox(label=\"Model Evaluation Metrics\", lines=8, interactive=False)\n",
        "\n",
        "            retrieval_metrics_output = gr.Textbox(label=\"Retrieval Metrics\", interactive=False, lines=4)\n",
        "\n",
        "            # Display the list of loaded files\n",
        "            file_list_output = gr.Textbox(label=\"Loaded Files\", lines=3, interactive=False)\n",
        "\n",
        "            # Displays for initial and final salary values, and the negotiation score\n",
        "            initial_salary_output = gr.Textbox(label=\"Initial Salary\", value=\"\", interactive=False)\n",
        "            final_salary_output = gr.Textbox(label=\"Final Salary\", interactive=False)\n",
        "            score_output = gr.Textbox(label=\"Negotiation Score\", interactive=False)\n",
        "\n",
        "        # Define actions for buttons, linking them to functions and specifying inputs and outputs\n",
        "        start_button.click(\n",
        "            fn=start_game,\n",
        "            inputs=[role_input, initial_salary_input, name_input, company_name_input, position_input],\n",
        "            outputs=[chat_output, initial_salary_output]\n",
        "        )\n",
        "\n",
        "        negotiate_button.click(\n",
        "            fn=negotiate,\n",
        "            inputs=[user_text_input, user_audio_input, name_input, company_name_input, position_input, gr.State(assistant_role)],\n",
        "            outputs=[chat_output, initial_salary_output, final_salary_output, score_output, feedback_output, retrieval_metrics_output, audio_output]\n",
        "        )\n",
        "\n",
        "        reload_button.click(\n",
        "            fn=update_loaded_files,\n",
        "            inputs=exclude_files_input,\n",
        "            outputs=file_list_output\n",
        "        )\n",
        "\n",
        "        end_button.click(\n",
        "            fn=end_game,\n",
        "            inputs=None,\n",
        "            outputs=[chat_output, initial_salary_output, final_salary_output, score_output, feedback_output, audio_output]\n",
        "        )\n",
        "\n",
        "        evaluate_button.click(\n",
        "            fn=lambda assistant_role: evaluate_model(\n",
        "                conversation_id=generate_conversation_id(),\n",
        "                references=load_reference_text(assistant_role)[0]  # Pass only the list of references\n",
        "        ),\n",
        "        inputs=gr.State(assistant_role),\n",
        "        outputs=evaluate_output\n",
        "    )\n",
        "\n",
        "\n",
        "    # Initialize the file list output with the current files loaded\n",
        "    file_list_output.value = \", \".join(file_list)\n",
        "\n",
        "# Launch the Gradio interface in queued mode to handle multiple inputs\n",
        "demo.queue().launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b5c3354b773b400780d287dff1eb7de9",
            "bf97663106dc4c30a45c5dd675fb4ac8",
            "d4c907472cac46b19b702db8a6576a4b",
            "00f3a6d0beae4e1ca99b4e623948918e",
            "69477d37ffc84964810721cd3455aac7",
            "b1b1334b812845f3bc4ccbdd300a5ef6",
            "0cd41877286a41f79b5ac65b5cd22b60",
            "6ba4e3006f9f4530adc0fca748a81c15",
            "f085fa9bdc3146f08281cce28e678df7",
            "e42a47ac3c7f47e78380c531d1fdac2b",
            "40772f1f0b8547e5a5aa6fd06b96b7c8",
            "8e516e48fdc941f98b23d2e59100106d",
            "7d11cb2d3eee49a0ab5fc0093fc9b584",
            "ffb3872dd7e045ef8bb92af79934c9e0",
            "92a238a772014adc92e3c29df8c41a62",
            "767bb89bbb9a4690bd54d3620c84e2ef",
            "dec67fd7bb9340259e8862dfa3ce9a8e",
            "d15f8bf86a09422ba2d4362dc91da624",
            "44a304ad25154c6db5c07414a056b818",
            "c79e461cc65444548c84191d417d73fe",
            "68ace428c36d45d2a29050e3d481a530",
            "81d73233a39e449eb90ea754c8535ed3"
          ]
        },
        "id": "vxb19Ep97orI",
        "outputId": "5e46e28f-c765-4e50-d486-33feb810f90f"
      },
      "id": "vxb19Ep97orI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 9 PDFs and created FAISS index successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:237: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://87a70920bb0129a96d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://87a70920bb0129a96d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: User role set to 'prospective hire', Assistant role set to 'employer'.\n",
            "Starting Salary for Negotiation: $123,000.00\n",
            "Conversation history before formatting: []\n",
            "DEBUG: Converted audio to text: Hey, I'd like to negotiate the salary to $125,000 base.\n",
            "DEBUG: Final combined user input: Hey, I'd like to negotiate the salary to $125,000 base.\n",
            "DEBUG: Starting negotiation with user_input: Hey, I'd like to negotiate the salary to $125,000 base.\n",
            "DEBUG: Initial conversation_history: []\n",
            "ERROR: Invalid assistant role: . Defaulting to 'employer'.\n",
            "DEBUG: Successfully loaded reference_employer.txt from bucket lilygpt\n",
            "DEBUG: Extracted amount: 125000.0, Context: 'Hey, I'd like to negotiate the salary to $125,000 base.'\n",
            "DEBUG: Score for amount 125000.0: 5\n",
            "DEBUG: Salary added: 125000.0\n",
            "DEBUG: Final extracted salary value: 125000.0\n",
            "DEBUG: Is the user message salary-related? True\n",
            "DEBUG: Extracted amount: 125000.0, Context: 'Hey, I'd like to negotiate the salary to $125,000 base.'\n",
            "DEBUG: Score for amount 125000.0: 5\n",
            "DEBUG: Salary added: 125000.0\n",
            "DEBUG: Final extracted salary value: 125000.0\n",
            "DEBUG: Extracted salary from message 'Hey, I'd like to negotiate the salary to $125,000 base.': 125000.0\n",
            "DEBUG: Updated Final Salary: $125000.0\n",
            "DEBUG: Current Salary Log: [{'source': 'user', 'amount': 125000.0, 'timestamp': '2024-12-10T01:43:38.902370'}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 125000.0\n",
            "DEBUG: Detected user tone: frustrated\n",
            "DEBUG: Try Counter: 1\n",
            "DEBUG: Retrieval Metrics: {'Retrieval Accuracy': False, 'Coverage': 0.005338078291814947, 'Relevance': 0.6353603402773539, 'Novelty': 0.541403462489446}\n",
            "DEBUG: Retrieved context from RAG: Per that value, would it be possible to offer\n",
            "$95,000 in base salary?\n",
            "Recruiter: Thanks Ankur For most people, this ends up being the base salary or\n",
            "equity.\n",
            "From there, plan for there to be two rounds of negotiation I would be willing to\n",
            "sign immediately if we could land at:\n",
            "●$145K base salary\n",
            "●0.22% equity (22,000 shares)\n",
            "I'd be happy to discuss live with you\n",
            "DEBUG: Assistant response generated: I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\n",
            "\n",
            "Let’s explore this together—how does that sound to you?\n",
            "Audio saved as assistant_response.mp3\n",
            "DEBUG: Extracted amount: 95000.0, Context: 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\n",
            "\n",
            "Let’s explore this together—how does that sound to you?'\n",
            "DEBUG: Score for amount 95000.0: 4\n",
            "DEBUG: Salary added: 95000.0\n",
            "DEBUG: Final extracted salary value: 95000.0\n",
            "DEBUG: Extracted salary from message 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\n",
            "\n",
            "Let’s explore this together—how does that sound to you?': 95000.0\n",
            "DEBUG: Updated Final Salary: $95000.0\n",
            "DEBUG: Current Salary Log: [{'source': 'user', 'amount': 125000.0, 'timestamp': '2024-12-10T01:43:38.902370'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:43:43.217501'}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Final salary after assistant's response: 95000.0\n",
            "DEBUG: Detected assistant tone: neutral\n",
            "DEBUG: Loaded 14 references for role employer.\n",
            "DEBUG: Raw NLI result: [{'label': 'NEUTRAL', 'score': 0.8874525427818298}]\n",
            "DEBUG: Extracted entailment score: 0\n",
            "DEBUG: QAG Score - Reference: User: Thanks for having me here today, Alex. I’ve been really looking forward to this conversation. Salesforce is a company I’ve admired for years, and I’m excited about the opportunity to contribute., Prediction: I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\n",
            "\n",
            "Let’s explore this together—how does that sound to you?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Updated conversation_history: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Salary Change: -22.76%\n",
            "DEBUG: Processing employer logic...\n",
            "DEBUG: Applying reward: 5\n",
            "DEBUG: Reward for retaining position: 0.0\n",
            "DEBUG: Round Reward: 5.0, Cumulative Reward: 5.0\n",
            "DEBUG: Calculated reward: 5.0\n",
            "Conversation history before formatting: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}]\n",
            "Processing message: {'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}\n",
            "Processing message: {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}\n",
            "DEBUG: Converted audio to text: So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.\n",
            "DEBUG: Final combined user input: So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.\n",
            "DEBUG: Starting negotiation with user_input: So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.\n",
            "DEBUG: Initial conversation_history: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}]\n",
            "ERROR: Invalid assistant role: . Defaulting to 'employer'.\n",
            "DEBUG: Successfully loaded reference_employer.txt from bucket lilygpt\n",
            "DEBUG: Extracted amount: 123000.0, Context: 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.'\n",
            "DEBUG: Score for amount 123000.0: 5\n",
            "DEBUG: Salary added: 123000.0\n",
            "DEBUG: Extracted amount: 123000.0, Context: 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.'\n",
            "DEBUG: Score for amount 123000.0: 5\n",
            "DEBUG: Salary added: 123000.0\n",
            "DEBUG: Final extracted salary value: 123000.0\n",
            "DEBUG: Is the user message salary-related? True\n",
            "DEBUG: Extracted amount: 123000.0, Context: 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.'\n",
            "DEBUG: Score for amount 123000.0: 5\n",
            "DEBUG: Salary added: 123000.0\n",
            "DEBUG: Extracted amount: 123000.0, Context: 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.'\n",
            "DEBUG: Score for amount 123000.0: 5\n",
            "DEBUG: Salary added: 123000.0\n",
            "DEBUG: Final extracted salary value: 123000.0\n",
            "DEBUG: Extracted salary from message 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.': 123000.0\n",
            "DEBUG: Updated Final Salary: $123000.0\n",
            "DEBUG: Current Salary Log: [{'source': 'user', 'amount': 125000.0, 'timestamp': '2024-12-10T01:43:38.902370'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:43:43.217501'}, {'source': 'user', 'amount': 123000.0, 'timestamp': '2024-12-10T01:44:11.475782'}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 123000.0\n",
            "DEBUG: Detected user tone: frustrated\n",
            "DEBUG: Try Counter: 2\n",
            "DEBUG: Retrieval Metrics: {'Retrieval Accuracy': False, 'Coverage': 0.005338078291814947, 'Relevance': 0.5589360992113749, 'Novelty': 0.4725675086180369}\n",
            "DEBUG: Retrieved context from RAG: Per that value, would it be possible to offer\n",
            "$95,000 in base salary?\n",
            "Recruiter: Thanks Ankur Your cheatsheet can be simple, like this:\n",
            "●If they offer $85K+, I'll push for $95K more and accept if they go for it\n",
            "●If they can't move on the base, I'll fall back to asking for my \"potatoes\" in\n",
            "the negotiation.\n",
            "Let's play that out!\n",
            "(After some pleasantries)\n",
            "Recruiter: Thanks for bearing with me, Ankur Well, I'm currently in a position where my total\n",
            "compensation package, including bonuses and equity, is higher than the base\n",
            "salary that you're offering\n",
            "DEBUG: Assistant response generated: I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \n",
            "\n",
            "Our benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\n",
            "\n",
            "How do you feel about these aspects? Let’s see if we can find a balance that works for you.\n",
            "Audio saved as assistant_response.mp3\n",
            "DEBUG: Extracted amount: 95000.0, Context: 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \n",
            "\n",
            "Our benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\n",
            "\n",
            "How do you feel about these aspects? Let’s see if we can find a balance that works for you.'\n",
            "DEBUG: Score for amount 95000.0: 4\n",
            "DEBUG: Salary added: 95000.0\n",
            "DEBUG: Final extracted salary value: 95000.0\n",
            "DEBUG: Extracted salary from message 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \n",
            "\n",
            "Our benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\n",
            "\n",
            "How do you feel about these aspects? Let’s see if we can find a balance that works for you.': 95000.0\n",
            "DEBUG: Updated Final Salary: $95000.0\n",
            "DEBUG: Current Salary Log: [{'source': 'user', 'amount': 125000.0, 'timestamp': '2024-12-10T01:43:38.902370'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:43:43.217501'}, {'source': 'user', 'amount': 123000.0, 'timestamp': '2024-12-10T01:44:11.475782'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:44:16.192714'}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Final salary after assistant's response: 95000.0\n",
            "DEBUG: Detected assistant tone: neutral\n",
            "DEBUG: Loaded 14 references for role employer.\n",
            "DEBUG: Raw NLI result: [{'label': 'NEUTRAL', 'score': 0.9952338337898254}]\n",
            "DEBUG: Extracted entailment score: 0\n",
            "DEBUG: QAG Score - Reference: User: Thanks for having me here today, Alex. I’ve been really looking forward to this conversation. Salesforce is a company I’ve admired for years, and I’m excited about the opportunity to contribute., Prediction: I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \n",
            "\n",
            "Our benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\n",
            "\n",
            "How do you feel about these aspects? Let’s see if we can find a balance that works for you.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Updated conversation_history: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}, {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}, {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Salary Change: -22.76%\n",
            "DEBUG: Processing employer logic...\n",
            "DEBUG: Applying reward: 5\n",
            "DEBUG: Reward for retaining position: 0.5\n",
            "DEBUG: Round Reward: 5.5, Cumulative Reward: 10.5\n",
            "DEBUG: Calculated reward: 10.5\n",
            "Conversation history before formatting: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}, {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}, {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}, {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}]\n",
            "Processing message: {'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}\n",
            "Processing message: {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}\n",
            "Processing message: {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}\n",
            "Processing message: {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}\n",
            "DEBUG: Converted audio to text: So, you're not understanding, the salary that you're giving me is very low below market rate.\n",
            "DEBUG: Final combined user input: So, you're not understanding, the salary that you're giving me is very low below market rate.\n",
            "DEBUG: Starting negotiation with user_input: So, you're not understanding, the salary that you're giving me is very low below market rate.\n",
            "DEBUG: Initial conversation_history: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}, {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}, {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}, {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}]\n",
            "ERROR: Invalid assistant role: . Defaulting to 'employer'.\n",
            "DEBUG: Successfully loaded reference_employer.txt from bucket lilygpt\n",
            "DEBUG: No salary pattern found in text: 'So, you're not understanding, the salary that you're giving me is very low below market rate.'\n",
            "DEBUG: Is the user message salary-related? False\n",
            "DEBUG: No salary pattern found in text: 'So, you're not understanding, the salary that you're giving me is very low below market rate.'\n",
            "DEBUG: Extracted salary from message 'So, you're not understanding, the salary that you're giving me is very low below market rate.': None\n",
            "DEBUG: No valid salary detected. Retaining last final salary.\n",
            "DEBUG: Current Salary Log: [{'source': 'user', 'amount': 125000.0, 'timestamp': '2024-12-10T01:43:38.902370'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:43:43.217501'}, {'source': 'user', 'amount': 123000.0, 'timestamp': '2024-12-10T01:44:11.475782'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:44:16.192714'}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Detected user tone: neutral\n",
            "DEBUG: Try Counter: 3\n",
            "DEBUG: Retrieval Metrics: {'Retrieval Accuracy': False, 'Coverage': 0.005338078291814947, 'Relevance': 0.5466509262720743, 'Novelty': 0.4794003963470459}\n",
            "DEBUG: Retrieved context from RAG: Well, I'm currently in a position where my total\n",
            "compensation package, including bonuses and equity, is higher than the base\n",
            "salary that you're offering Also, from my\n",
            "research, the market rate for this role is actually higher than offered - closer to\n",
            "the $100,000 mark Perhaps I\n",
            "should have been more explicit about my compensation expectations, as the\n",
            "current offer is significantly lower than my expectations.\n",
            "As you have heard from my references and witnessed during the interview\n",
            "process, I will offer you more and turn your investment in me into significant\n",
            "growth.\n",
            "I would love to discuss this by phone with you\n",
            "DEBUG: Assistant response generated: I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \n",
            "\n",
            "While our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\n",
            "\n",
            "Let’s explore how we can make this work—what are your thoughts on these options?\n",
            "Audio saved as assistant_response.mp3\n",
            "DEBUG: Extracted amount: 95000.0, Context: 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \n",
            "\n",
            "While our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\n",
            "\n",
            "Let’s explore how we can make this work—what are your thoughts on these options?'\n",
            "DEBUG: Score for amount 95000.0: 2\n",
            "DEBUG: Excluded match '95,000' due to mixed context.\n",
            "DEBUG: Final extracted salary value: None\n",
            "DEBUG: Extracted salary from message 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \n",
            "\n",
            "While our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\n",
            "\n",
            "Let’s explore how we can make this work—what are your thoughts on these options?': None\n",
            "DEBUG: No valid salary detected. Retaining last final salary.\n",
            "DEBUG: Current Salary Log: [{'source': 'user', 'amount': 125000.0, 'timestamp': '2024-12-10T01:43:38.902370'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:43:43.217501'}, {'source': 'user', 'amount': 123000.0, 'timestamp': '2024-12-10T01:44:11.475782'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:44:16.192714'}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Final salary after assistant's response: 95000.0\n",
            "DEBUG: Detected assistant tone: neutral\n",
            "DEBUG: Loaded 14 references for role employer.\n",
            "DEBUG: Raw NLI result: [{'label': 'NEUTRAL', 'score': 0.9724447727203369}]\n",
            "DEBUG: Extracted entailment score: 0\n",
            "DEBUG: QAG Score - Reference: User: Thanks for having me here today, Alex. I’ve been really looking forward to this conversation. Salesforce is a company I’ve admired for years, and I’m excited about the opportunity to contribute., Prediction: I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \n",
            "\n",
            "While our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\n",
            "\n",
            "Let’s explore how we can make this work—what are your thoughts on these options?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Updated conversation_history: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}, {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}, {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}, {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}, {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}, {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Salary Change: -22.76%\n",
            "DEBUG: Processing employer logic...\n",
            "DEBUG: Applying reward: 5\n",
            "DEBUG: Reward for retaining position: 1.0\n",
            "DEBUG: Round Reward: 6.0, Cumulative Reward: 16.5\n",
            "DEBUG: Calculated reward: 16.5\n",
            "Conversation history before formatting: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}, {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}, {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}, {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}, {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}, {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}, {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}]\n",
            "Processing message: {'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}\n",
            "Processing message: {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}\n",
            "Processing message: {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}\n",
            "Processing message: {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}\n",
            "Processing message: {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}\n",
            "Processing message: {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}\n",
            "DEBUG: Converted audio to text: I am looking for a $130,000 sign-on bonus if we can do that.\n",
            "DEBUG: Final combined user input: I am looking for a $130,000 sign-on bonus if we can do that.\n",
            "DEBUG: Starting negotiation with user_input: I am looking for a $130,000 sign-on bonus if we can do that.\n",
            "DEBUG: Initial conversation_history: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}, {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}, {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}, {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}, {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}, {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}, {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}]\n",
            "ERROR: Invalid assistant role: . Defaulting to 'employer'.\n",
            "DEBUG: Successfully loaded reference_employer.txt from bucket lilygpt\n",
            "DEBUG: Extracted amount: 130000.0, Context: 'I am looking for a $130,000 sign-on bonus if we can do that.'\n",
            "DEBUG: Score for amount 130000.0: 2\n",
            "DEBUG: Excluded match '130,000' due to mixed context.\n",
            "DEBUG: Final extracted salary value: None\n",
            "DEBUG: Is the user message salary-related? False\n",
            "DEBUG: Extracted amount: 130000.0, Context: 'I am looking for a $130,000 sign-on bonus if we can do that.'\n",
            "DEBUG: Score for amount 130000.0: 2\n",
            "DEBUG: Excluded match '130,000' due to mixed context.\n",
            "DEBUG: Final extracted salary value: None\n",
            "DEBUG: Extracted salary from message 'I am looking for a $130,000 sign-on bonus if we can do that.': None\n",
            "DEBUG: No valid salary detected. Retaining last final salary.\n",
            "DEBUG: Current Salary Log: [{'source': 'user', 'amount': 125000.0, 'timestamp': '2024-12-10T01:43:38.902370'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:43:43.217501'}, {'source': 'user', 'amount': 123000.0, 'timestamp': '2024-12-10T01:44:11.475782'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:44:16.192714'}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Detected user tone: neutral\n",
            "DEBUG: Try Counter: 4\n",
            "DEBUG: Retrieval Metrics: {'Retrieval Accuracy': False, 'Coverage': 0.005338078291814947, 'Relevance': 0.6391716996828715, 'Novelty': 0.6644939482212067}\n",
            "DEBUG: Retrieved context from RAG: I would\n",
            "be willing to sign at $90,000 if you could also increase the signing bonus by\n",
            "$3,000 to $8,000 I was also able to negotiate a signing bonus for you of\n",
            "$5,000 if you sign by Friday As I mentioned, we really don't do signing bonuses as a matter\n",
            "of course\n",
            "DEBUG: Assistant response generated: I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \n",
            "\n",
            "Our focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?\n",
            "Audio saved as assistant_response.mp3\n",
            "DEBUG: Extracted amount: 5000.0, Context: 'I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \n",
            "\n",
            "Our focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?'\n",
            "DEBUG: Score for amount 5000.0: 3\n",
            "DEBUG: Excluded match '5,000' due to mixed context.\n",
            "DEBUG: Final extracted salary value: None\n",
            "DEBUG: Extracted salary from message 'I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \n",
            "\n",
            "Our focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?': None\n",
            "DEBUG: No valid salary detected. Retaining last final salary.\n",
            "DEBUG: Current Salary Log: [{'source': 'user', 'amount': 125000.0, 'timestamp': '2024-12-10T01:43:38.902370'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:43:43.217501'}, {'source': 'user', 'amount': 123000.0, 'timestamp': '2024-12-10T01:44:11.475782'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:44:16.192714'}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Final salary after assistant's response: 95000.0\n",
            "DEBUG: Detected assistant tone: neutral\n",
            "DEBUG: Loaded 14 references for role employer.\n",
            "DEBUG: Raw NLI result: [{'label': 'NEUTRAL', 'score': 0.990541398525238}]\n",
            "DEBUG: Extracted entailment score: 0\n",
            "DEBUG: QAG Score - Reference: Default fallback reference response, Prediction: I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \n",
            "\n",
            "Our focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Updated conversation_history: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}, {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}, {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}, {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}, {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}, {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}, {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}, {'role': 'user', 'content': 'I am looking for a $130,000 sign-on bonus if we can do that.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:13.839208'}, {'role': 'assistant', 'content': 'I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \\n\\nOur focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:18.770239', 'bleu': 0, 'rouge': 0.0, 'meteor': 0.0, 'bert_score': 0.8082574009895325, 'coherence_score': -0.07283291220664978, 'nli_score': 0, 'qag_score': 0.033648934215307236}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Salary Change: -22.76%\n",
            "DEBUG: Processing employer logic...\n",
            "DEBUG: Applying reward: 5\n",
            "DEBUG: Reward for retaining position: 1.5\n",
            "DEBUG: Round Reward: 6.5, Cumulative Reward: 23.0\n",
            "DEBUG: Calculated reward: 23.0\n",
            "Conversation history before formatting: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}, {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}, {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}, {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}, {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}, {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}, {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}, {'role': 'user', 'content': 'I am looking for a $130,000 sign-on bonus if we can do that.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:13.839208'}, {'role': 'assistant', 'content': 'I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \\n\\nOur focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:18.770239', 'bleu': 0, 'rouge': 0.0, 'meteor': 0.0, 'bert_score': 0.8082574009895325, 'coherence_score': -0.07283291220664978, 'nli_score': 0, 'qag_score': 0.033648934215307236}, {'role': 'system', 'reward_score': 23.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.5, 'timestamp': '2024-12-10T01:45:18.770671'}]\n",
            "Processing message: {'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}\n",
            "Processing message: {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}\n",
            "Processing message: {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}\n",
            "Processing message: {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}\n",
            "Processing message: {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}\n",
            "Processing message: {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}\n",
            "Processing message: {'role': 'user', 'content': 'I am looking for a $130,000 sign-on bonus if we can do that.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:13.839208'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \\n\\nOur focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:18.770239', 'bleu': 0, 'rouge': 0.0, 'meteor': 0.0, 'bert_score': 0.8082574009895325, 'coherence_score': -0.07283291220664978, 'nli_score': 0, 'qag_score': 0.033648934215307236}\n",
            "Processing message: {'role': 'system', 'reward_score': 23.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.5, 'timestamp': '2024-12-10T01:45:18.770671'}\n",
            "DEBUG: Converted audio to text: No, thank you. I declined the offer\n",
            "DEBUG: Final combined user input: No, thank you. I declined the offer\n",
            "DEBUG: Starting negotiation with user_input: No, thank you. I declined the offer\n",
            "DEBUG: Initial conversation_history: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}, {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}, {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}, {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}, {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}, {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}, {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}, {'role': 'user', 'content': 'I am looking for a $130,000 sign-on bonus if we can do that.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:13.839208'}, {'role': 'assistant', 'content': 'I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \\n\\nOur focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:18.770239', 'bleu': 0, 'rouge': 0.0, 'meteor': 0.0, 'bert_score': 0.8082574009895325, 'coherence_score': -0.07283291220664978, 'nli_score': 0, 'qag_score': 0.033648934215307236}, {'role': 'system', 'reward_score': 23.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.5, 'timestamp': '2024-12-10T01:45:18.770671'}]\n",
            "ERROR: Invalid assistant role: . Defaulting to 'employer'.\n",
            "DEBUG: Successfully loaded reference_employer.txt from bucket lilygpt\n",
            "DEBUG: No salary pattern found in text: 'No, thank you. I declined the offer'\n",
            "DEBUG: Is the user message salary-related? False\n",
            "DEBUG: No salary pattern found in text: 'No, thank you. I declined the offer'\n",
            "DEBUG: Extracted salary from message 'No, thank you. I declined the offer': None\n",
            "DEBUG: No valid salary detected. Retaining last final salary.\n",
            "DEBUG: Current Salary Log: [{'source': 'user', 'amount': 125000.0, 'timestamp': '2024-12-10T01:43:38.902370'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:43:43.217501'}, {'source': 'user', 'amount': 123000.0, 'timestamp': '2024-12-10T01:44:11.475782'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:44:16.192714'}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Detected user tone: neutral\n",
            "DEBUG: Try Counter: 5\n",
            "DEBUG: Retrieval Metrics: {'Retrieval Accuracy': False, 'Coverage': 0.005338078291814947, 'Relevance': 0.4820198913415273, 'Novelty': 0.6873654822508494}\n",
            "DEBUG: Retrieved context from RAG: Thank you, again, for\n",
            "offering me this opportunity This offer improves our\n",
            "original offer by $5,000 The offer is decidedly lower than I was\n",
            "expecting based on all of the information that I have\n",
            "4\n",
            "DEBUG: Assistant response generated: I understand, Arish, and I appreciate your feedback. We’re excited about the possibility of having you on board, and we want to ensure it’s a great fit for both sides.\n",
            "\n",
            "If there’s any other aspect of the offer or role that we could discuss, I’m here to explore it with you. Let us know if there’s a way we can align more closely with your expectations.\n",
            "Audio saved as assistant_response.mp3\n",
            "DEBUG: No salary pattern found in text: 'I understand, Arish, and I appreciate your feedback. We’re excited about the possibility of having you on board, and we want to ensure it’s a great fit for both sides.\n",
            "\n",
            "If there’s any other aspect of the offer or role that we could discuss, I’m here to explore it with you. Let us know if there’s a way we can align more closely with your expectations.'\n",
            "DEBUG: Extracted salary from message 'I understand, Arish, and I appreciate your feedback. We’re excited about the possibility of having you on board, and we want to ensure it’s a great fit for both sides.\n",
            "\n",
            "If there’s any other aspect of the offer or role that we could discuss, I’m here to explore it with you. Let us know if there’s a way we can align more closely with your expectations.': None\n",
            "DEBUG: No valid salary detected. Retaining last final salary.\n",
            "DEBUG: Current Salary Log: [{'source': 'user', 'amount': 125000.0, 'timestamp': '2024-12-10T01:43:38.902370'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:43:43.217501'}, {'source': 'user', 'amount': 123000.0, 'timestamp': '2024-12-10T01:44:11.475782'}, {'source': 'assistant', 'amount': 95000.0, 'timestamp': '2024-12-10T01:44:16.192714'}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Final salary after assistant's response: 95000.0\n",
            "DEBUG: Detected assistant tone: excited\n",
            "DEBUG: Loaded 14 references for role employer.\n",
            "DEBUG: Raw NLI result: [{'label': 'NEUTRAL', 'score': 0.9884309768676758}]\n",
            "DEBUG: Extracted entailment score: 0\n",
            "DEBUG: QAG Score - Reference: User: Thanks for having me here today, Alex. I’ve been really looking forward to this conversation. Salesforce is a company I’ve admired for years, and I’m excited about the opportunity to contribute., Prediction: I understand, Arish, and I appreciate your feedback. We’re excited about the possibility of having you on board, and we want to ensure it’s a great fit for both sides.\n",
            "\n",
            "If there’s any other aspect of the offer or role that we could discuss, I’m here to explore it with you. Let us know if there’s a way we can align more closely with your expectations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Updated conversation_history: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}, {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}, {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}, {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}, {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}, {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}, {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}, {'role': 'user', 'content': 'I am looking for a $130,000 sign-on bonus if we can do that.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:13.839208'}, {'role': 'assistant', 'content': 'I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \\n\\nOur focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:18.770239', 'bleu': 0, 'rouge': 0.0, 'meteor': 0.0, 'bert_score': 0.8082574009895325, 'coherence_score': -0.07283291220664978, 'nli_score': 0, 'qag_score': 0.033648934215307236}, {'role': 'system', 'reward_score': 23.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.5, 'timestamp': '2024-12-10T01:45:18.770671'}, {'role': 'user', 'content': 'No, thank you. I declined the offer', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:36.471679'}, {'role': 'assistant', 'content': 'I understand, Arish, and I appreciate your feedback. We’re excited about the possibility of having you on board, and we want to ensure it’s a great fit for both sides.\\n\\nIf there’s any other aspect of the offer or role that we could discuss, I’m here to explore it with you. Let us know if there’s a way we can align more closely with your expectations.', 'tone': 'excited', 'timestamp': '2024-12-10T01:45:41.975119', 'bleu': 0.018884748972625882, 'rouge': 0.19277107979097122, 'meteor': 0.2253727144866386, 'bert_score': 0.8583641648292542, 'coherence_score': 0.4951820373535156, 'nli_score': 0, 'qag_score': 0.025020554661750793}]\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Salary Change: -22.76%\n",
            "DEBUG: Processing employer logic...\n",
            "DEBUG: Applying reward: 5\n",
            "DEBUG: Reward for retaining position: 2.0\n",
            "DEBUG: Round Reward: 7.0, Cumulative Reward: 30.0\n",
            "DEBUG: Calculated reward: 30.0\n",
            "Conversation history before formatting: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}, {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}, {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}, {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}, {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}, {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}, {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}, {'role': 'user', 'content': 'I am looking for a $130,000 sign-on bonus if we can do that.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:13.839208'}, {'role': 'assistant', 'content': 'I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \\n\\nOur focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:18.770239', 'bleu': 0, 'rouge': 0.0, 'meteor': 0.0, 'bert_score': 0.8082574009895325, 'coherence_score': -0.07283291220664978, 'nli_score': 0, 'qag_score': 0.033648934215307236}, {'role': 'system', 'reward_score': 23.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.5, 'timestamp': '2024-12-10T01:45:18.770671'}, {'role': 'user', 'content': 'No, thank you. I declined the offer', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:36.471679'}, {'role': 'assistant', 'content': 'I understand, Arish, and I appreciate your feedback. We’re excited about the possibility of having you on board, and we want to ensure it’s a great fit for both sides.\\n\\nIf there’s any other aspect of the offer or role that we could discuss, I’m here to explore it with you. Let us know if there’s a way we can align more closely with your expectations.', 'tone': 'excited', 'timestamp': '2024-12-10T01:45:41.975119', 'bleu': 0.018884748972625882, 'rouge': 0.19277107979097122, 'meteor': 0.2253727144866386, 'bert_score': 0.8583641648292542, 'coherence_score': 0.4951820373535156, 'nli_score': 0, 'qag_score': 0.025020554661750793}, {'role': 'system', 'reward_score': 30.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 7.0, 'timestamp': '2024-12-10T01:45:41.976479'}]\n",
            "Processing message: {'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}\n",
            "Processing message: {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}\n",
            "Processing message: {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}\n",
            "Processing message: {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}\n",
            "Processing message: {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}\n",
            "Processing message: {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}\n",
            "Processing message: {'role': 'user', 'content': 'I am looking for a $130,000 sign-on bonus if we can do that.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:13.839208'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \\n\\nOur focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:18.770239', 'bleu': 0, 'rouge': 0.0, 'meteor': 0.0, 'bert_score': 0.8082574009895325, 'coherence_score': -0.07283291220664978, 'nli_score': 0, 'qag_score': 0.033648934215307236}\n",
            "Processing message: {'role': 'system', 'reward_score': 23.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.5, 'timestamp': '2024-12-10T01:45:18.770671'}\n",
            "Processing message: {'role': 'user', 'content': 'No, thank you. I declined the offer', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:36.471679'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I understand, Arish, and I appreciate your feedback. We’re excited about the possibility of having you on board, and we want to ensure it’s a great fit for both sides.\\n\\nIf there’s any other aspect of the offer or role that we could discuss, I’m here to explore it with you. Let us know if there’s a way we can align more closely with your expectations.', 'tone': 'excited', 'timestamp': '2024-12-10T01:45:41.975119', 'bleu': 0.018884748972625882, 'rouge': 0.19277107979097122, 'meteor': 0.2253727144866386, 'bert_score': 0.8583641648292542, 'coherence_score': 0.4951820373535156, 'nli_score': 0, 'qag_score': 0.025020554661750793}\n",
            "Processing message: {'role': 'system', 'reward_score': 30.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 7.0, 'timestamp': '2024-12-10T01:45:41.976479'}\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Salary Change: -22.76%\n",
            "DEBUG: Processing employer logic...\n",
            "DEBUG: Applying reward: 5\n",
            "DEBUG: Reward for retaining position: 2.5\n",
            "DEBUG: Round Reward: 7.5, Cumulative Reward: 37.5\n",
            "WARNING: Invalid or missing assistant_role. Defaulting to 'employer'.\n",
            "DEBUG: Successfully loaded reference_employer.txt from bucket lilygpt\n",
            "Evaluating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Raw NLI result: [{'label': 'NEUTRAL', 'score': 0.8257990479469299}]\n",
            "DEBUG: Extracted entailment score: 0\n",
            "DEBUG: QAG Score - Reference: User: Thanks for having me here today, Alex. I’ve been really looking forward to this conversation. Salesforce is a company I’ve admired for years, and I’m excited about the opportunity to contribute. Assistant: We’re excited to have you here, Jamie. Your experience at Wells Fargo caught our attention—your data analytics background aligns well with what we need for this role. Let’s get into the details. User: Sounds good. I’ll be upfront—I’m looking for a compensation package that reflects my skills and market value. At Wells Fargo, I was making $98,000, and given the broader responsibilities here and what I’ve seen in the market, I was aiming for something in the $160,000 range for base salary. Assistant: [slightly raises eyebrows, nodding thoughtfully] $160,000. I appreciate your transparency—it makes conversations like this more efficient. That said, I want to be just as upfront. The range we’ve budgeted for this role is $125,000 to $150,000. It’s competitive, especially considering our comprehensive benefits package. User: [pauses, leaning back slightly] I understand budgets are tight, but Salesforce is a top-tier company. I’d expect the compensation to reflect that. And while $150,000 is close to what I’m targeting, I believe I bring value beyond that cap. Assistant: I hear you. Let’s talk about the full picture. Along with the base salary, we offer RSUs starting at $30,000 annually, a 6% 401(k) match, and flexible PTO. For a first-year package, you’re looking at a total compensation of around $190,000. User: The RSUs and benefits are appealing, no doubt. But my priority is the base salary. A higher base sets the tone for future raises and career growth, and $160,000 is where I see my value. Without that, it feels like I’d be undervaluing myself. Assistant: [sits up straighter, tone firm but polite] Jamie, I get where you’re coming from. Your background is impressive, and you’ve clearly done your homework. But I need to stay within the budget for this role. $150,000 is the absolute top of the range. I can offer a $10,000 signing bonus on top of that, but I can’t stretch beyond it. User: [pauses, visibly weighing options] I appreciate the offer, Alex, but $160,000 is where I need to be. It’s not just about the money—it’s about feeling that my contributions are valued at the right level. I think we may be too far apart on this. Assistant: [leans forward slightly, tone empathetic] I understand your position, Jamie, and I respect it. I hope you know this isn’t about undervaluing you—it’s about maintaining equity across our teams. $150,000 is genuinely the best I can do for this role. User: [nods slowly, then takes a deep breath] I appreciate the transparency, and I’ve enjoyed our conversations. But I think I have to walk away. It’s a tough decision, but I need to hold out for something that aligns better with my goals. Assistant: [pauses, then nods with a small smile] I respect that, Jamie. It’s always better to advocate for yourself. I’m genuinely sorry to lose out on someone with your talent, but I hope our paths cross again in the future. User: Thank you, Alex. Salesforce is a fantastic company, and I’ll always admire what you’re doing here. Best of luck with finding the right fit. Assistant: And best of luck to you too, Jamie. If anything changes down the line, don’t hesitate to reach out., Prediction: I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\n",
            "\n",
            "Let’s explore this together—how does that sound to you?\n",
            "ERROR: Exception occurred in QAG scoring - Truncation error: Sequence to truncate too short to respect the provided max_length\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio saved as feedback_audio.mp3\n",
            "Evaluating model...\n",
            "DEBUG: Error evaluating model - Reference is empty.\n",
            "DEBUG: Skipping record with invalid structure: {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}\n",
            "DEBUG: Skipping record with invalid structure: {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}\n",
            "DEBUG: Skipping record with invalid structure: {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}\n",
            "DEBUG: Skipping record with invalid structure: {'role': 'system', 'reward_score': 23.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.5, 'timestamp': '2024-12-10T01:45:18.770671'}\n",
            "DEBUG: Skipping record with invalid structure: {'role': 'system', 'reward_score': 30.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 7.0, 'timestamp': '2024-12-10T01:45:41.976479'}\n",
            "DEBUG: Skipping record with invalid structure: {'role': 'system', 'reward_score': 37.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 7.5, 'timestamp': '2024-12-10T01:45:47.107227'}\n",
            "DEBUG: Skipping record with invalid structure: {'role': 'system', 'reward_score': 37.5, 'timestamp': '2024-12-10T01:45:47.107249'}\n",
            "DEBUG: Rows to insert: [\n",
            "  {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"role\": \"user\",\n",
            "        \"content\": \"Hey, I'd like to negotiate the salary to $125,000 base.\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"I hear you, Arish, and I appreciate your perspective. We\\u2019re excited about the potential you bring to the team. Currently, we\\u2019re looking at a base salary of $95,000. I know it\\u2019s not quite what you\\u2019re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet\\u2019s explore this together\\u2014how does that sound to you?\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"role\": \"user\",\n",
            "        \"content\": \"So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We\\u2019re currently offering $95,000, but I\\u2019d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We\\u2019re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let\\u2019s see if we can find a balance that works for you.\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"role\": \"user\",\n",
            "        \"content\": \"So, you're not understanding, the salary that you're giving me is very low below market rate.\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"I get where you\\u2019re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we\\u2019re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet\\u2019s explore how we can make this work\\u2014what are your thoughts on these options?\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"role\": \"user\",\n",
            "        \"content\": \"I am looking for a $130,000 sign-on bonus if we can do that.\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"I appreciate your input, Arish. To be fair, we typically don\\u2019t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \\n\\nOur focus is on long-term growth and development. Let\\u2019s see how we can align on this\\u2014how does that sound to you?\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"role\": \"user\",\n",
            "        \"content\": \"No, thank you. I declined the offer\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"I understand, Arish, and I appreciate your feedback. We\\u2019re excited about the possibility of having you on board, and we want to ensure it\\u2019s a great fit for both sides.\\n\\nIf there\\u2019s any other aspect of the offer or role that we could discuss, I\\u2019m here to explore it with you. Let us know if there\\u2019s a way we can align more closely with your expectations.\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "]\n",
            "DEBUG: Data successfully saved to BigQuery table: llm-sim.negotiation_data.conversation\n",
            "DEBUG: JSONL file saved successfully at end of game.\n",
            "DEBUG: Final Reward: 37.5\n",
            "DEBUG: Feedback: ### Evaluation of Negotiation with Arish\n",
            "\n",
            "**What Went Well:**\n",
            "1. **Open Communication:** Both parties maintained an open line of communication. Arish was clear about expectations, and we responded with transparency about our offer.\n",
            "2. **Flexibility:** We offered additional benefits and incentives to balance the base salary mismatch. This openness to discussion is positive.\n",
            "3. **Understanding Needs:** We acknowledged Arish’s competing offer, showing awareness of market competition.\n",
            "\n",
            "**Areas for Improvement:**\n",
            "1. **Initial Offer Alignment:** The starting salary offer was significantly below Arish’s expectations. Aligning closer to market rates initially might have helped.\n",
            "2. **Sign-On Bonus Proposal:** Our response to Arish’s sign-on bonus request was lower than expected. This could have been a stronger negotiating point.\n",
            "\n",
            "**Suggestions for Future Negotiations:**\n",
            "\n",
            "**For the Employer (Google):**\n",
            "- **Benchmarking:** Regularly review market rates to ensure initial offers are competitive.\n",
            "- **Flexibility with Bonuses:** Be open to higher sign-on bonuses or more creative perks to align with candidate expectations.\n",
            "- **Active Listening:** Acknowledge the candidate’s points earlier in the conversation to build a collaborative tone.\n",
            "\n",
            "**For the Candidate (Arish):**\n",
            "- **Highlight Unique Value:** Emphasize specific skills or experiences that justify the salary expectations, enhancing negotiation leverage.\n",
            "- **Explore Total Compensation:** Consider the entire compensation package, including benefits and growth opportunities, as part of the negotiation.\n",
            "- **Maintain Openness:** While salary is critical, flexibility with terms like performance incentives can lead to mutually satisfying outcomes.\n",
            "\n",
            "Overall, fostering a constructive dialogue with a focus on alignment between company goals and personal aspirations can lead to more mutually beneficial agreements.\n",
            "\n",
            "**Final Reward/Penalty Score:** 37.5\n",
            "DEBUG: Initial Salary: $123,000.00, Final Salary: $95,000.00\n",
            "Conversation history before formatting: [{'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}, {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}, {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}, {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}, {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}, {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}, {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}, {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}, {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}, {'role': 'user', 'content': 'I am looking for a $130,000 sign-on bonus if we can do that.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:13.839208'}, {'role': 'assistant', 'content': 'I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \\n\\nOur focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:18.770239', 'bleu': 0, 'rouge': 0.0, 'meteor': 0.0, 'bert_score': 0.8082574009895325, 'coherence_score': -0.07283291220664978, 'nli_score': 0, 'qag_score': 0.033648934215307236}, {'role': 'system', 'reward_score': 23.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.5, 'timestamp': '2024-12-10T01:45:18.770671'}, {'role': 'user', 'content': 'No, thank you. I declined the offer', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:36.471679'}, {'role': 'assistant', 'content': 'I understand, Arish, and I appreciate your feedback. We’re excited about the possibility of having you on board, and we want to ensure it’s a great fit for both sides.\\n\\nIf there’s any other aspect of the offer or role that we could discuss, I’m here to explore it with you. Let us know if there’s a way we can align more closely with your expectations.', 'tone': 'excited', 'timestamp': '2024-12-10T01:45:41.975119', 'bleu': 0.018884748972625882, 'rouge': 0.19277107979097122, 'meteor': 0.2253727144866386, 'bert_score': 0.8583641648292542, 'coherence_score': 0.4951820373535156, 'nli_score': 0, 'qag_score': 0.025020554661750793}, {'role': 'system', 'reward_score': 30.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 7.0, 'timestamp': '2024-12-10T01:45:41.976479'}, {'role': 'system', 'reward_score': 37.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 7.5, 'timestamp': '2024-12-10T01:45:47.107227'}, {'role': 'system', 'reward_score': 37.5, 'timestamp': '2024-12-10T01:45:47.107249'}]\n",
            "Processing message: {'role': 'user', 'content': \"Hey, I'd like to negotiate the salary to $125,000 base.\", 'tone': 'frustrated', 'timestamp': '2024-12-10T01:43:38.903343'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:43:47.566112', 'bleu': 0.018837132611996946, 'rouge': 0.1904761859552155, 'meteor': 0.20070162759534452, 'bert_score': 0.8559290170669556, 'coherence_score': 0.32391753792762756, 'nli_score': 0, 'qag_score': 0.039291318506002426}\n",
            "Processing message: {'role': 'system', 'reward_score': 5.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.0, 'timestamp': '2024-12-10T01:43:47.569291'}\n",
            "Processing message: {'role': 'user', 'content': 'So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.', 'tone': 'frustrated', 'timestamp': '2024-12-10T01:44:11.477623'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:20.801153', 'bleu': 0.00419105675868449, 'rouge': 0.1276595702014488, 'meteor': 0.2192665571975917, 'bert_score': 0.847467303276062, 'coherence_score': 0.40700045228004456, 'nli_score': 0, 'qag_score': 0.13364502787590027}\n",
            "Processing message: {'role': 'system', 'reward_score': 10.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 5.5, 'timestamp': '2024-12-10T01:44:20.803440'}\n",
            "Processing message: {'role': 'user', 'content': \"So, you're not understanding, the salary that you're giving me is very low below market rate.\", 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:53.390084'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:44:59.437586', 'bleu': 0.00448518185057412, 'rouge': 0.16091953578544077, 'meteor': 0.13959390862944163, 'bert_score': 0.8426784873008728, 'coherence_score': 0.3206081986427307, 'nli_score': 0, 'qag_score': 0.06293070316314697}\n",
            "Processing message: {'role': 'system', 'reward_score': 16.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.0, 'timestamp': '2024-12-10T01:44:59.438163'}\n",
            "Processing message: {'role': 'user', 'content': 'I am looking for a $130,000 sign-on bonus if we can do that.', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:13.839208'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \\n\\nOur focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:18.770239', 'bleu': 0, 'rouge': 0.0, 'meteor': 0.0, 'bert_score': 0.8082574009895325, 'coherence_score': -0.07283291220664978, 'nli_score': 0, 'qag_score': 0.033648934215307236}\n",
            "Processing message: {'role': 'system', 'reward_score': 23.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 6.5, 'timestamp': '2024-12-10T01:45:18.770671'}\n",
            "Processing message: {'role': 'user', 'content': 'No, thank you. I declined the offer', 'tone': 'neutral', 'timestamp': '2024-12-10T01:45:36.471679'}\n",
            "Processing message: {'role': 'assistant', 'content': 'I understand, Arish, and I appreciate your feedback. We’re excited about the possibility of having you on board, and we want to ensure it’s a great fit for both sides.\\n\\nIf there’s any other aspect of the offer or role that we could discuss, I’m here to explore it with you. Let us know if there’s a way we can align more closely with your expectations.', 'tone': 'excited', 'timestamp': '2024-12-10T01:45:41.975119', 'bleu': 0.018884748972625882, 'rouge': 0.19277107979097122, 'meteor': 0.2253727144866386, 'bert_score': 0.8583641648292542, 'coherence_score': 0.4951820373535156, 'nli_score': 0, 'qag_score': 0.025020554661750793}\n",
            "Processing message: {'role': 'system', 'reward_score': 30.0, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 7.0, 'timestamp': '2024-12-10T01:45:41.976479'}\n",
            "Processing message: {'role': 'system', 'reward_score': 37.5, 'initial_salary': 123000.0, 'final_salary': 95000.0, 'salary_change': -0.22764227642276422, 'round_reward': 7.5, 'timestamp': '2024-12-10T01:45:47.107227'}\n",
            "Processing message: {'role': 'system', 'reward_score': 37.5, 'timestamp': '2024-12-10T01:45:47.107249'}\n",
            "DEBUG: Raw NLI result: [{'label': 'NEUTRAL', 'score': 0.9974491000175476}]\n",
            "DEBUG: Extracted entailment score: 0\n",
            "DEBUG: QAG Score - Reference: User: Thanks for having me here today, Alex. I’ve been really looking forward to this conversation. Salesforce is a company I’ve admired for years, and I’m excited about the opportunity to contribute. Assistant: We’re excited to have you here, Jamie. Your experience at Wells Fargo caught our attention—your data analytics background aligns well with what we need for this role. Let’s get into the details. User: Sounds good. I’ll be upfront—I’m looking for a compensation package that reflects my skills and market value. At Wells Fargo, I was making $98,000, and given the broader responsibilities here and what I’ve seen in the market, I was aiming for something in the $160,000 range for base salary. Assistant: [slightly raises eyebrows, nodding thoughtfully] $160,000. I appreciate your transparency—it makes conversations like this more efficient. That said, I want to be just as upfront. The range we’ve budgeted for this role is $125,000 to $150,000. It’s competitive, especially considering our comprehensive benefits package. User: [pauses, leaning back slightly] I understand budgets are tight, but Salesforce is a top-tier company. I’d expect the compensation to reflect that. And while $150,000 is close to what I’m targeting, I believe I bring value beyond that cap. Assistant: I hear you. Let’s talk about the full picture. Along with the base salary, we offer RSUs starting at $30,000 annually, a 6% 401(k) match, and flexible PTO. For a first-year package, you’re looking at a total compensation of around $190,000. User: The RSUs and benefits are appealing, no doubt. But my priority is the base salary. A higher base sets the tone for future raises and career growth, and $160,000 is where I see my value. Without that, it feels like I’d be undervaluing myself. Assistant: [sits up straighter, tone firm but polite] Jamie, I get where you’re coming from. Your background is impressive, and you’ve clearly done your homework. But I need to stay within the budget for this role. $150,000 is the absolute top of the range. I can offer a $10,000 signing bonus on top of that, but I can’t stretch beyond it. User: [pauses, visibly weighing options] I appreciate the offer, Alex, but $160,000 is where I need to be. It’s not just about the money—it’s about feeling that my contributions are valued at the right level. I think we may be too far apart on this. Assistant: [leans forward slightly, tone empathetic] I understand your position, Jamie, and I respect it. I hope you know this isn’t about undervaluing you—it’s about maintaining equity across our teams. $150,000 is genuinely the best I can do for this role. User: [nods slowly, then takes a deep breath] I appreciate the transparency, and I’ve enjoyed our conversations. But I think I have to walk away. It’s a tough decision, but I need to hold out for something that aligns better with my goals. Assistant: [pauses, then nods with a small smile] I respect that, Jamie. It’s always better to advocate for yourself. I’m genuinely sorry to lose out on someone with your talent, but I hope our paths cross again in the future. User: Thank you, Alex. Salesforce is a fantastic company, and I’ll always admire what you’re doing here. Best of luck with finding the right fit. Assistant: And best of luck to you too, Jamie. If anything changes down the line, don’t hesitate to reach out., Prediction: I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \n",
            "\n",
            "Our benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\n",
            "\n",
            "How do you feel about these aspects? Let’s see if we can find a balance that works for you.\n",
            "ERROR: Exception occurred in QAG scoring - Truncation error: Sequence to truncate too short to respect the provided max_length\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Raw NLI result: [{'label': 'NEUTRAL', 'score': 0.992694616317749}]\n",
            "DEBUG: Extracted entailment score: 0\n",
            "DEBUG: QAG Score - Reference: User: Thanks for having me here today, Alex. I’ve been really looking forward to this conversation. Salesforce is a company I’ve admired for years, and I’m excited about the opportunity to contribute. Assistant: We’re excited to have you here, Jamie. Your experience at Wells Fargo caught our attention—your data analytics background aligns well with what we need for this role. Let’s get into the details. User: Sounds good. I’ll be upfront—I’m looking for a compensation package that reflects my skills and market value. At Wells Fargo, I was making $98,000, and given the broader responsibilities here and what I’ve seen in the market, I was aiming for something in the $160,000 range for base salary. Assistant: [slightly raises eyebrows, nodding thoughtfully] $160,000. I appreciate your transparency—it makes conversations like this more efficient. That said, I want to be just as upfront. The range we’ve budgeted for this role is $125,000 to $150,000. It’s competitive, especially considering our comprehensive benefits package. User: [pauses, leaning back slightly] I understand budgets are tight, but Salesforce is a top-tier company. I’d expect the compensation to reflect that. And while $150,000 is close to what I’m targeting, I believe I bring value beyond that cap. Assistant: I hear you. Let’s talk about the full picture. Along with the base salary, we offer RSUs starting at $30,000 annually, a 6% 401(k) match, and flexible PTO. For a first-year package, you’re looking at a total compensation of around $190,000. User: The RSUs and benefits are appealing, no doubt. But my priority is the base salary. A higher base sets the tone for future raises and career growth, and $160,000 is where I see my value. Without that, it feels like I’d be undervaluing myself. Assistant: [sits up straighter, tone firm but polite] Jamie, I get where you’re coming from. Your background is impressive, and you’ve clearly done your homework. But I need to stay within the budget for this role. $150,000 is the absolute top of the range. I can offer a $10,000 signing bonus on top of that, but I can’t stretch beyond it. User: [pauses, visibly weighing options] I appreciate the offer, Alex, but $160,000 is where I need to be. It’s not just about the money—it’s about feeling that my contributions are valued at the right level. I think we may be too far apart on this. Assistant: [leans forward slightly, tone empathetic] I understand your position, Jamie, and I respect it. I hope you know this isn’t about undervaluing you—it’s about maintaining equity across our teams. $150,000 is genuinely the best I can do for this role. User: [nods slowly, then takes a deep breath] I appreciate the transparency, and I’ve enjoyed our conversations. But I think I have to walk away. It’s a tough decision, but I need to hold out for something that aligns better with my goals. Assistant: [pauses, then nods with a small smile] I respect that, Jamie. It’s always better to advocate for yourself. I’m genuinely sorry to lose out on someone with your talent, but I hope our paths cross again in the future. User: Thank you, Alex. Salesforce is a fantastic company, and I’ll always admire what you’re doing here. Best of luck with finding the right fit. Assistant: And best of luck to you too, Jamie. If anything changes down the line, don’t hesitate to reach out., Prediction: I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \n",
            "\n",
            "While our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\n",
            "\n",
            "Let’s explore how we can make this work—what are your thoughts on these options?\n",
            "ERROR: Exception occurred in QAG scoring - Truncation error: Sequence to truncate too short to respect the provided max_length\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Raw NLI result: [{'label': 'NEUTRAL', 'score': 0.9697270393371582}]\n",
            "DEBUG: Extracted entailment score: 0\n",
            "DEBUG: QAG Score - Reference: User: Thanks for having me here today, Alex. I’ve been really looking forward to this conversation. Salesforce is a company I’ve admired for years, and I’m excited about the opportunity to contribute. Assistant: We’re excited to have you here, Jamie. Your experience at Wells Fargo caught our attention—your data analytics background aligns well with what we need for this role. Let’s get into the details. User: Sounds good. I’ll be upfront—I’m looking for a compensation package that reflects my skills and market value. At Wells Fargo, I was making $98,000, and given the broader responsibilities here and what I’ve seen in the market, I was aiming for something in the $160,000 range for base salary. Assistant: [slightly raises eyebrows, nodding thoughtfully] $160,000. I appreciate your transparency—it makes conversations like this more efficient. That said, I want to be just as upfront. The range we’ve budgeted for this role is $125,000 to $150,000. It’s competitive, especially considering our comprehensive benefits package. User: [pauses, leaning back slightly] I understand budgets are tight, but Salesforce is a top-tier company. I’d expect the compensation to reflect that. And while $150,000 is close to what I’m targeting, I believe I bring value beyond that cap. Assistant: I hear you. Let’s talk about the full picture. Along with the base salary, we offer RSUs starting at $30,000 annually, a 6% 401(k) match, and flexible PTO. For a first-year package, you’re looking at a total compensation of around $190,000. User: The RSUs and benefits are appealing, no doubt. But my priority is the base salary. A higher base sets the tone for future raises and career growth, and $160,000 is where I see my value. Without that, it feels like I’d be undervaluing myself. Assistant: [sits up straighter, tone firm but polite] Jamie, I get where you’re coming from. Your background is impressive, and you’ve clearly done your homework. But I need to stay within the budget for this role. $150,000 is the absolute top of the range. I can offer a $10,000 signing bonus on top of that, but I can’t stretch beyond it. User: [pauses, visibly weighing options] I appreciate the offer, Alex, but $160,000 is where I need to be. It’s not just about the money—it’s about feeling that my contributions are valued at the right level. I think we may be too far apart on this. Assistant: [leans forward slightly, tone empathetic] I understand your position, Jamie, and I respect it. I hope you know this isn’t about undervaluing you—it’s about maintaining equity across our teams. $150,000 is genuinely the best I can do for this role. User: [nods slowly, then takes a deep breath] I appreciate the transparency, and I’ve enjoyed our conversations. But I think I have to walk away. It’s a tough decision, but I need to hold out for something that aligns better with my goals. Assistant: [pauses, then nods with a small smile] I respect that, Jamie. It’s always better to advocate for yourself. I’m genuinely sorry to lose out on someone with your talent, but I hope our paths cross again in the future. User: Thank you, Alex. Salesforce is a fantastic company, and I’ll always admire what you’re doing here. Best of luck with finding the right fit. Assistant: And best of luck to you too, Jamie. If anything changes down the line, don’t hesitate to reach out., Prediction: I appreciate your input, Arish. To be fair, we typically don’t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \n",
            "\n",
            "Our focus is on long-term growth and development. Let’s see how we can align on this—how does that sound to you?\n",
            "ERROR: Exception occurred in QAG scoring - Truncation error: Sequence to truncate too short to respect the provided max_length\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Raw NLI result: [{'label': 'NEUTRAL', 'score': 0.9860979318618774}]\n",
            "DEBUG: Extracted entailment score: 0\n",
            "DEBUG: QAG Score - Reference: User: Thanks for having me here today, Alex. I’ve been really looking forward to this conversation. Salesforce is a company I’ve admired for years, and I’m excited about the opportunity to contribute. Assistant: We’re excited to have you here, Jamie. Your experience at Wells Fargo caught our attention—your data analytics background aligns well with what we need for this role. Let’s get into the details. User: Sounds good. I’ll be upfront—I’m looking for a compensation package that reflects my skills and market value. At Wells Fargo, I was making $98,000, and given the broader responsibilities here and what I’ve seen in the market, I was aiming for something in the $160,000 range for base salary. Assistant: [slightly raises eyebrows, nodding thoughtfully] $160,000. I appreciate your transparency—it makes conversations like this more efficient. That said, I want to be just as upfront. The range we’ve budgeted for this role is $125,000 to $150,000. It’s competitive, especially considering our comprehensive benefits package. User: [pauses, leaning back slightly] I understand budgets are tight, but Salesforce is a top-tier company. I’d expect the compensation to reflect that. And while $150,000 is close to what I’m targeting, I believe I bring value beyond that cap. Assistant: I hear you. Let’s talk about the full picture. Along with the base salary, we offer RSUs starting at $30,000 annually, a 6% 401(k) match, and flexible PTO. For a first-year package, you’re looking at a total compensation of around $190,000. User: The RSUs and benefits are appealing, no doubt. But my priority is the base salary. A higher base sets the tone for future raises and career growth, and $160,000 is where I see my value. Without that, it feels like I’d be undervaluing myself. Assistant: [sits up straighter, tone firm but polite] Jamie, I get where you’re coming from. Your background is impressive, and you’ve clearly done your homework. But I need to stay within the budget for this role. $150,000 is the absolute top of the range. I can offer a $10,000 signing bonus on top of that, but I can’t stretch beyond it. User: [pauses, visibly weighing options] I appreciate the offer, Alex, but $160,000 is where I need to be. It’s not just about the money—it’s about feeling that my contributions are valued at the right level. I think we may be too far apart on this. Assistant: [leans forward slightly, tone empathetic] I understand your position, Jamie, and I respect it. I hope you know this isn’t about undervaluing you—it’s about maintaining equity across our teams. $150,000 is genuinely the best I can do for this role. User: [nods slowly, then takes a deep breath] I appreciate the transparency, and I’ve enjoyed our conversations. But I think I have to walk away. It’s a tough decision, but I need to hold out for something that aligns better with my goals. Assistant: [pauses, then nods with a small smile] I respect that, Jamie. It’s always better to advocate for yourself. I’m genuinely sorry to lose out on someone with your talent, but I hope our paths cross again in the future. User: Thank you, Alex. Salesforce is a fantastic company, and I’ll always admire what you’re doing here. Best of luck with finding the right fit. Assistant: And best of luck to you too, Jamie. If anything changes down the line, don’t hesitate to reach out., Prediction: I understand, Arish, and I appreciate your feedback. We’re excited about the possibility of having you on board, and we want to ensure it’s a great fit for both sides.\n",
            "\n",
            "If there’s any other aspect of the offer or role that we could discuss, I’m here to explore it with you. Let us know if there’s a way we can align more closely with your expectations.\n",
            "ERROR: Exception occurred in QAG scoring - Truncation error: Sequence to truncate too short to respect the provided max_length\n",
            "DEBUG: Number of human texts: 14\n",
            "DEBUG: Number of model texts: 5\n",
            "DEBUG: Sample human texts: ['User: Thanks for having me here today, Alex. I’ve been really looking forward to this conversation. Salesforce is a company I’ve admired for years, and I’m excited about the opportunity to contribute.', 'Assistant: We’re excited to have you here, Jamie. Your experience at Wells Fargo caught our attention—your data analytics background aligns well with what we need for this role. Let’s get into the details.', 'User: Sounds good. I’ll be upfront—I’m looking for a compensation package that reflects my skills and market value. At Wells Fargo, I was making $98,000, and given the broader responsibilities here and what I’ve seen in the market, I was aiming for something in the $160,000 range for base salary.']\n",
            "DEBUG: Sample model texts: ['I hear you, Arish, and I appreciate your perspective. We’re excited about the potential you bring to the team. Currently, we’re looking at a base salary of $95,000. I know it’s not quite what you’re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\n\\nLet’s explore this together—how does that sound to you?', 'I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We’re currently offering $95,000, but I’d love to highlight some aspects that could make this role appealing. \\n\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We’re committed to fostering a supportive culture where you can grow.\\n\\nHow do you feel about these aspects? Let’s see if we can find a balance that works for you.', 'I get where you’re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\n\\nWhile our base is $95,000, we’re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\n\\nLet’s explore how we can make this work—what are your thoughts on these options?']\n",
            "DEBUG: Using device ID -1 for MAUVE calculation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Featurizing p:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5c3354b773b400780d287dff1eb7de9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Featurizing q:   0%|          | 0/14 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e516e48fdc941f98b23d2e59100106d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: MAUVE Result Object: namespace(p_hist=array([1., 0.]), q_hist=array([0., 1.]), divergence_curve=array([[1.00000000e+00, 0.00000000e+00],\n",
            "       [9.99995000e-01, 1.00000000e-30],\n",
            "       [8.08315477e-01, 1.25600556e-07],\n",
            "       [6.47224907e-01, 4.01897666e-06],\n",
            "       [5.12906737e-01, 3.05184937e-05],\n",
            "       [4.01875965e-01, 1.28603395e-04],\n",
            "       [3.10964059e-01, 3.92464061e-04],\n",
            "       [2.37303896e-01, 9.76572266e-04],\n",
            "       [1.78314689e-01, 2.11075144e-03],\n",
            "       [1.31686914e-01, 4.11524691e-03],\n",
            "       [9.53672409e-02, 7.41579620e-03],\n",
            "       [6.75434670e-02, 1.25586992e-02],\n",
            "       [4.66294421e-02, 2.02258887e-02],\n",
            "       [3.12500000e-02, 3.12500000e-02],\n",
            "       [2.02258887e-02, 4.66294421e-02],\n",
            "       [1.25586992e-02, 6.75434670e-02],\n",
            "       [7.41579620e-03, 9.53672409e-02],\n",
            "       [4.11524691e-03, 1.31686914e-01],\n",
            "       [2.11075144e-03, 1.78314689e-01],\n",
            "       [9.76572266e-04, 2.37303896e-01],\n",
            "       [3.92464061e-04, 3.10964059e-01],\n",
            "       [1.28603395e-04, 4.01875965e-01],\n",
            "       [3.05184937e-05, 5.12906737e-01],\n",
            "       [4.01897666e-06, 6.47224907e-01],\n",
            "       [1.25600556e-07, 8.08315477e-01],\n",
            "       [1.00000000e-30, 9.99995000e-01],\n",
            "       [0.00000000e+00, 1.00000000e+00]]), mauve=0.0040720962619612555, frontier_integral=1.0, mauve_star=0.031404195651439815, frontier_integral_star=0.6618390129036006, num_buckets=2)\n",
            "DEBUG: MAUVE Score: 0.0040720962619612555\n",
            "DEBUG: Initial Salary: 123000.0, Final Salary: 95000.0\n",
            "DEBUG: Salary Change: -22.76%\n",
            "DEBUG: Processing employer logic...\n",
            "DEBUG: Applying reward: 5\n",
            "DEBUG: Reward for retaining position: 3.0\n",
            "DEBUG: Round Reward: 8.0, Cumulative Reward: 45.5\n",
            "DEBUG: Rows to insert: [\n",
            "  {\n",
            "    \"Timestamp\": \"2024-12-10T01:46:41.356920\",\n",
            "    \"Agreement_Rate\": 0.0,\n",
            "    \"Average_Sentiment_Score\": 0.2183809523809524,\n",
            "    \"Feedback_Quality\": \"Moderate\",\n",
            "    \"Average_Response_Time\": 6.893654400000001,\n",
            "    \"Corpus_BLEU\": 2.3480875566867526e-05,\n",
            "    \"ROUGE\": 0.1623492705657338,\n",
            "    \"METEOR\": 0.045230704488610725,\n",
            "    \"BERTScore\": 0.8347454071044922,\n",
            "    \"G_Eval\": 0.5086487054824829,\n",
            "    \"NLI\": 0.0,\n",
            "    \"QAG\": 0.0,\n",
            "    \"TTR\": 0.7326125554850983,\n",
            "    \"Pause_Ratio\": 0.0,\n",
            "    \"Average_Turn_Length\": 80.4,\n",
            "    \"MAUVE\": 0.0040720962619612555,\n",
            "    \"USL_H\": 0.4813119610983228,\n",
            "    \"Reward_Score\": 45.5,\n",
            "    \"Conversation_History\": \"[{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Hey, I'd like to negotiate the salary to $125,000 base.\\\", \\\"tone\\\": \\\"frustrated\\\", \\\"timestamp\\\": \\\"2024-12-10T01:43:38.903343\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"I hear you, Arish, and I appreciate your perspective. We\\\\u2019re excited about the potential you bring to the team. Currently, we\\\\u2019re looking at a base salary of $95,000. I know it\\\\u2019s not quite what you\\\\u2019re aiming for, but we offer a comprehensive benefits package and growth opportunities that might align with your career goals.\\\\n\\\\nLet\\\\u2019s explore this together\\\\u2014how does that sound to you?\\\", \\\"tone\\\": \\\"neutral\\\", \\\"timestamp\\\": \\\"2024-12-10T01:43:47.566112\\\", \\\"bleu\\\": 0.018837132611996946, \\\"rouge\\\": 0.1904761859552155, \\\"meteor\\\": 0.20070162759534452, \\\"bert_score\\\": 0.8559290170669556, \\\"coherence_score\\\": 0.32391753792762756, \\\"nli_score\\\": 0, \\\"qag_score\\\": 0.039291318506002426}, {\\\"role\\\": \\\"system\\\", \\\"reward_score\\\": 5.0, \\\"initial_salary\\\": 123000.0, \\\"final_salary\\\": 95000.0, \\\"salary_change\\\": -0.22764227642276422, \\\"round_reward\\\": 5.0, \\\"timestamp\\\": \\\"2024-12-10T01:43:47.569291\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"So, I have a competing offer at Apple which is giving me $123,000 and I would like to see if you can give me $123,000 for a base salary.\\\", \\\"tone\\\": \\\"frustrated\\\", \\\"timestamp\\\": \\\"2024-12-10T01:44:11.477623\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"I appreciate you sharing that, Arish. I understand the importance of aligning with your expectations. We\\\\u2019re currently offering $95,000, but I\\\\u2019d love to highlight some aspects that could make this role appealing. \\\\n\\\\nOur benefits package includes comprehensive healthcare, stock options, and opportunities for professional development. We\\\\u2019re committed to fostering a supportive culture where you can grow.\\\\n\\\\nHow do you feel about these aspects? Let\\\\u2019s see if we can find a balance that works for you.\\\", \\\"tone\\\": \\\"neutral\\\", \\\"timestamp\\\": \\\"2024-12-10T01:44:20.801153\\\", \\\"bleu\\\": 0.00419105675868449, \\\"rouge\\\": 0.1276595702014488, \\\"meteor\\\": 0.2192665571975917, \\\"bert_score\\\": 0.847467303276062, \\\"coherence_score\\\": 0.40700045228004456, \\\"nli_score\\\": 0, \\\"qag_score\\\": 0.13364502787590027}, {\\\"role\\\": \\\"system\\\", \\\"reward_score\\\": 10.5, \\\"initial_salary\\\": 123000.0, \\\"final_salary\\\": 95000.0, \\\"salary_change\\\": -0.22764227642276422, \\\"round_reward\\\": 5.5, \\\"timestamp\\\": \\\"2024-12-10T01:44:20.803440\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"So, you're not understanding, the salary that you're giving me is very low below market rate.\\\", \\\"tone\\\": \\\"neutral\\\", \\\"timestamp\\\": \\\"2024-12-10T01:44:53.390084\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"I get where you\\\\u2019re coming from, Arish. Our goal is to align with market expectations and make this a great fit for you. \\\\n\\\\nWhile our base is $95,000, we\\\\u2019re open to discussing additional incentives like performance bonuses or stock options. We value your expertise and want to ensure you feel valued here.\\\\n\\\\nLet\\\\u2019s explore how we can make this work\\\\u2014what are your thoughts on these options?\\\", \\\"tone\\\": \\\"neutral\\\", \\\"timestamp\\\": \\\"2024-12-10T01:44:59.437586\\\", \\\"bleu\\\": 0.00448518185057412, \\\"rouge\\\": 0.16091953578544077, \\\"meteor\\\": 0.13959390862944163, \\\"bert_score\\\": 0.8426784873008728, \\\"coherence_score\\\": 0.3206081986427307, \\\"nli_score\\\": 0, \\\"qag_score\\\": 0.06293070316314697}, {\\\"role\\\": \\\"system\\\", \\\"reward_score\\\": 16.5, \\\"initial_salary\\\": 123000.0, \\\"final_salary\\\": 95000.0, \\\"salary_change\\\": -0.22764227642276422, \\\"round_reward\\\": 6.0, \\\"timestamp\\\": \\\"2024-12-10T01:44:59.438163\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"I am looking for a $130,000 sign-on bonus if we can do that.\\\", \\\"tone\\\": \\\"neutral\\\", \\\"timestamp\\\": \\\"2024-12-10T01:45:13.839208\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"I appreciate your input, Arish. To be fair, we typically don\\\\u2019t offer large sign-on bonuses, but we could consider a $5,000 bonus if you decide by Friday. \\\\n\\\\nOur focus is on long-term growth and development. Let\\\\u2019s see how we can align on this\\\\u2014how does that sound to you?\\\", \\\"tone\\\": \\\"neutral\\\", \\\"timestamp\\\": \\\"2024-12-10T01:45:18.770239\\\", \\\"bleu\\\": 0, \\\"rouge\\\": 0.0, \\\"meteor\\\": 0.0, \\\"bert_score\\\": 0.8082574009895325, \\\"coherence_score\\\": -0.07283291220664978, \\\"nli_score\\\": 0, \\\"qag_score\\\": 0.033648934215307236}, {\\\"role\\\": \\\"system\\\", \\\"reward_score\\\": 23.0, \\\"initial_salary\\\": 123000.0, \\\"final_salary\\\": 95000.0, \\\"salary_change\\\": -0.22764227642276422, \\\"round_reward\\\": 6.5, \\\"timestamp\\\": \\\"2024-12-10T01:45:18.770671\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"No, thank you. I declined the offer\\\", \\\"tone\\\": \\\"neutral\\\", \\\"timestamp\\\": \\\"2024-12-10T01:45:36.471679\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"I understand, Arish, and I appreciate your feedback. We\\\\u2019re excited about the possibility of having you on board, and we want to ensure it\\\\u2019s a great fit for both sides.\\\\n\\\\nIf there\\\\u2019s any other aspect of the offer or role that we could discuss, I\\\\u2019m here to explore it with you. Let us know if there\\\\u2019s a way we can align more closely with your expectations.\\\", \\\"tone\\\": \\\"excited\\\", \\\"timestamp\\\": \\\"2024-12-10T01:45:41.975119\\\", \\\"bleu\\\": 0.018884748972625882, \\\"rouge\\\": 0.19277107979097122, \\\"meteor\\\": 0.2253727144866386, \\\"bert_score\\\": 0.8583641648292542, \\\"coherence_score\\\": 0.4951820373535156, \\\"nli_score\\\": 0, \\\"qag_score\\\": 0.025020554661750793}, {\\\"role\\\": \\\"system\\\", \\\"reward_score\\\": 30.0, \\\"initial_salary\\\": 123000.0, \\\"final_salary\\\": 95000.0, \\\"salary_change\\\": -0.22764227642276422, \\\"round_reward\\\": 7.0, \\\"timestamp\\\": \\\"2024-12-10T01:45:41.976479\\\"}, {\\\"role\\\": \\\"system\\\", \\\"reward_score\\\": 37.5, \\\"initial_salary\\\": 123000.0, \\\"final_salary\\\": 95000.0, \\\"salary_change\\\": -0.22764227642276422, \\\"round_reward\\\": 7.5, \\\"timestamp\\\": \\\"2024-12-10T01:45:47.107227\\\"}, {\\\"role\\\": \\\"system\\\", \\\"reward_score\\\": 37.5, \\\"timestamp\\\": \\\"2024-12-10T01:45:47.107249\\\"}, {\\\"role\\\": \\\"system\\\", \\\"reward_score\\\": 45.5, \\\"initial_salary\\\": 123000.0, \\\"final_salary\\\": 95000.0, \\\"salary_change\\\": -0.22764227642276422, \\\"round_reward\\\": 8.0, \\\"timestamp\\\": \\\"2024-12-10T01:46:41.359736\\\"}]\"\n",
            "  }\n",
            "]\n",
            "DEBUG: Metrics and conversation history saved to BigQuery table: llm-sim.negotiation_data.metrics\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "LillyGPT_GCP.ipynb"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b5c3354b773b400780d287dff1eb7de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf97663106dc4c30a45c5dd675fb4ac8",
              "IPY_MODEL_d4c907472cac46b19b702db8a6576a4b",
              "IPY_MODEL_00f3a6d0beae4e1ca99b4e623948918e"
            ],
            "layout": "IPY_MODEL_69477d37ffc84964810721cd3455aac7"
          }
        },
        "bf97663106dc4c30a45c5dd675fb4ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1b1334b812845f3bc4ccbdd300a5ef6",
            "placeholder": "​",
            "style": "IPY_MODEL_0cd41877286a41f79b5ac65b5cd22b60",
            "value": "Featurizing p: 100%"
          }
        },
        "d4c907472cac46b19b702db8a6576a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ba4e3006f9f4530adc0fca748a81c15",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f085fa9bdc3146f08281cce28e678df7",
            "value": 5
          }
        },
        "00f3a6d0beae4e1ca99b4e623948918e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e42a47ac3c7f47e78380c531d1fdac2b",
            "placeholder": "​",
            "style": "IPY_MODEL_40772f1f0b8547e5a5aa6fd06b96b7c8",
            "value": " 5/5 [00:07&lt;00:00,  1.42s/it]"
          }
        },
        "69477d37ffc84964810721cd3455aac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1b1334b812845f3bc4ccbdd300a5ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cd41877286a41f79b5ac65b5cd22b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ba4e3006f9f4530adc0fca748a81c15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f085fa9bdc3146f08281cce28e678df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e42a47ac3c7f47e78380c531d1fdac2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40772f1f0b8547e5a5aa6fd06b96b7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e516e48fdc941f98b23d2e59100106d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d11cb2d3eee49a0ab5fc0093fc9b584",
              "IPY_MODEL_ffb3872dd7e045ef8bb92af79934c9e0",
              "IPY_MODEL_92a238a772014adc92e3c29df8c41a62"
            ],
            "layout": "IPY_MODEL_767bb89bbb9a4690bd54d3620c84e2ef"
          }
        },
        "7d11cb2d3eee49a0ab5fc0093fc9b584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec67fd7bb9340259e8862dfa3ce9a8e",
            "placeholder": "​",
            "style": "IPY_MODEL_d15f8bf86a09422ba2d4362dc91da624",
            "value": "Featurizing q: 100%"
          }
        },
        "ffb3872dd7e045ef8bb92af79934c9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44a304ad25154c6db5c07414a056b818",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c79e461cc65444548c84191d417d73fe",
            "value": 14
          }
        },
        "92a238a772014adc92e3c29df8c41a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68ace428c36d45d2a29050e3d481a530",
            "placeholder": "​",
            "style": "IPY_MODEL_81d73233a39e449eb90ea754c8535ed3",
            "value": " 14/14 [00:14&lt;00:00,  1.12it/s]"
          }
        },
        "767bb89bbb9a4690bd54d3620c84e2ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec67fd7bb9340259e8862dfa3ce9a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d15f8bf86a09422ba2d4362dc91da624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44a304ad25154c6db5c07414a056b818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c79e461cc65444548c84191d417d73fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68ace428c36d45d2a29050e3d481a530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81d73233a39e449eb90ea754c8535ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}