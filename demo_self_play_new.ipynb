{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19c92727-05bb-4a69-83de-af0d65b8cd51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.11/site-packages (0.3.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.22)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.26.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain) (2.1)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/lib/python3.11/site-packages (0.3.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.10 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.3.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.3.22)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.10->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.10->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.26.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.10->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.10->langchain-community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.11/site-packages (0.3.10)\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.11/site-packages (1.9.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.11/site-packages (4.45.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.22)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.26.0)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.26.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain) (2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: rouge-score in /opt/anaconda3/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.11/site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.11/site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (4.65.0)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.11/site-packages (0.3.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.22)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.26.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain) (2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install -U langchain-community\n",
    "!pip install langchain sentence-transformers faiss-cpu transformers\n",
    "!pip install rouge-score\n",
    "!pip install --upgrade langchain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e3a8deb-c1ba-40ed-9433-8019881cdf92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/arish/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /Users/arish/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/arish/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import uuid # for conversation id\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datetime import datetime\n",
    "import openai\n",
    "import random\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "\n",
    "#RAG \n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "# Incorporating langchain for easier integration and embedding document chunks into FAISS vector\n",
    "# Rationale More Efficiency \n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "#from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "#Metrics\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from rouge import Rouge \n",
    "from bert_score import score as bert_score\n",
    "from nltk.translate.meteor_score import meteor_score \n",
    "from nltk.tokenize import word_tokenize  #Import for tokenizing\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from rouge_score import rouge_scorer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from transformers import pipeline\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9912fb10-5bc3-47f1-be79-4280d314cbbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-5.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd672bd6-70b2-49c3-8186-6f02bb26a45e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: Hubspot Salary Negotiation.pdf with 2 chunks.\n",
      "Processed file: HLS_PON_FR_Teaching_2023b.pdf with 40 chunks.\n",
      "Processed file: B2B.pdf with 17 chunks.\n",
      "Processed file: HLS_PON_FR_SalesNeg_2023b.pdf with 50 chunks.\n",
      "Processed file: Hubspot Placement's Salary Negotiation Guide.pdf with 28 chunks.\n",
      "Processed file: college majors.pdf with 8 chunks.\n",
      "Processed file: HLS_PON_FR_BusinessNeg_2023b.pdf with 33 chunks.\n",
      "Processed file: Hubspot 2.pdf with 22 chunks.\n",
      "Processed file: EmotionandtheArtofNegotiation.pdf with 36 chunks.\n",
      "\n",
      "Starting negotiation run 1...\n",
      "\n",
      "Turn 1, Role: Employee\n",
      "Generated response: Hello, thank you for meeting with me today. I wanted to discuss my current role and contributions to the company in light of our recent positive financial results. I've been reflecting on how these achievements align with my career progression here and thought it would be a good time to revisit my salary package.\n",
      "Total tokens used in this turn: 268. Total tokens so far: 268/3000\n",
      "Turn 2, Role: HR Manager\n",
      "Generated response: Considering the company's positive financial performance, I understand your request for a salary increase to $113,304.49. While our department currently faces budget constraints, we recognize the importance of retaining valuable employees like yourself.\n",
      "\n",
      "To address this effectively, I'm able to offer an immediate raise that brings your salary up to $105,000. Additionally, we could re-evaluate further compensation adjustments in six months based on departmental finances and individual performance metrics.\n",
      "\n",
      "Does this proposal meet you halfway?\n",
      "Total tokens used in this turn: 289. Total tokens so far: 557/3000\n",
      "HR Manager response: Considering the company's positive financial performance, I understand your request for a salary increase to $113,304.49. While our department currently faces budget constraints, we recognize the importance of retaining valuable employees like yourself.\n",
      "\n",
      "To address this effectively, I'm able to offer an immediate raise that brings your salary up to $105,000. Additionally, we could re-evaluate further compensation adjustments in six months based on departmental finances and individual performance metrics.\n",
      "\n",
      "Does this proposal meet you halfway?\n",
      "HR Manager updated the offer to $113304\n",
      "Turn 3, Role: Employee\n",
      "Generated response: I understand the department budget constraints, but given our company's robust performance recently, an adjustment to $113304 reflects my contributions and aligns with market trends. Retaining experienced staff who drive success is essential for sustaining growth. I'm eager to continue delivering value in line with these expectations.\n",
      "Total tokens used in this turn: 249. Total tokens so far: 806/3000\n",
      "Turn 4, Role: HR Manager\n",
      "Generated response: I understand your request is based on the company's strong financial performance. While we recognize and value your contributions, we're operating within a constrained budget this year.\n",
      "\n",
      "To balance these factors, I'm able to propose an increase that brings your salary up to $105,000. This offer reflects our commitment to retaining top talent like yourself while maintaining fiscal responsibility.\n",
      "\n",
      "Let's continue discussing how else we can support you in terms of career growth or additional benefits if necessary.\n",
      "Total tokens used in this turn: 283. Total tokens so far: 1089/3000\n",
      "HR Manager response: I understand your request is based on the company's strong financial performance. While we recognize and value your contributions, we're operating within a constrained budget this year.\n",
      "\n",
      "To balance these factors, I'm able to propose an increase that brings your salary up to $105,000. This offer reflects our commitment to retaining top talent like yourself while maintaining fiscal responsibility.\n",
      "\n",
      "Let's continue discussing how else we can support you in terms of career growth or additional benefits if necessary.\n",
      "Turn 5, Role: Employee\n",
      "Generated response: Considering the company's recent strong earnings, an increase to $113304.49 aligns with both my contribution and industry standards. Investing in employee retention is vital, particularly when performance indicators are positive. Could we find a way within budget constraints to accommodate this adjustment?\n",
      "Total tokens used in this turn: 245. Total tokens so far: 1334/3000\n",
      "Turn 6, Role: HR Manager\n",
      "Generated response: Let's address your request for a salary increase to $113,304.49 in light of the company's recent positive financial performance. While we acknowledge the importance of rewarding our employees and understand your rationale, it's essential to balance these with departmental budget constraints.\n",
      "\n",
      "We propose an adjustment that reflects both appreciation for your contribution and current fiscal limitations: a raise from $99,400 to $107,000 annually. This offer aims at recognizing your value while maintaining financial sustainability within our department's means.\n",
      "\n",
      "If you have any further thoughts or need clarification on this proposal, feel free to share them so that we can explore how best we might align mutual interests effectively.\n",
      "Total tokens used in this turn: 323. Total tokens so far: 1657/3000\n",
      "HR Manager response: Let's address your request for a salary increase to $113,304.49 in light of the company's recent positive financial performance. While we acknowledge the importance of rewarding our employees and understand your rationale, it's essential to balance these with departmental budget constraints.\n",
      "\n",
      "We propose an adjustment that reflects both appreciation for your contribution and current fiscal limitations: a raise from $99,400 to $107,000 annually. This offer aims at recognizing your value while maintaining financial sustainability within our department's means.\n",
      "\n",
      "If you have any further thoughts or need clarification on this proposal, feel free to share them so that we can explore how best we might align mutual interests effectively.\n",
      "Turn 7, Role: Employee\n",
      "Generated response: The company's strong financial performance highlights the value of our contributions, and retaining skilled employees is crucial for sustaining this success. With a raise to $113304.49, my compensation would align more closely with market standards and recognize my role in achieving these outcomes while ensuring continued motivation and commitment.\n",
      "Total tokens used in this turn: 251. Total tokens so far: 1908/3000\n",
      "Turn 8, Role: HR Manager\n",
      "Similarity (0.8306405544281006) exceeds threshold with message: Let's address your request for a salary increase to $113,304.49 in light of the company's recent positive financial performance. While we acknowledge the importance of rewarding our employees and understand your rationale, it's essential to balance these with departmental budget constraints.\n",
      "\n",
      "We propose an adjustment that reflects both appreciation for your contribution and current fiscal limitations: a raise from $99,400 to $107,000 annually. This offer aims at recognizing your value while maintaining financial sustainability within our department's means.\n",
      "\n",
      "If you have any further thoughts or need clarification on this proposal, feel free to share them so that we can explore how best we might align mutual interests effectively.\n",
      "Response too similar to previous messages. Retrying with modified prompt...\n",
      "Generated response: Thank you for your patience in discussing this matter further. The company's financial health certainly reflects the hard work and dedication from employees like yourself, which we greatly value. While our department's budget is currently constrained, it's important to ensure that our offers are both competitive and reflective of individual contributions.\n",
      "\n",
      "Based on these considerations, I propose increasing your salary to $106000 as an interim adjustment while recognizing current fiscal constraints. This offer aims to acknowledge your valuable role within the company and support continued professional satisfaction until we'll reassess when there's more flexibility in future budgets.\n",
      "\n",
      "Please let me know what you think about this proposal or if you'd like us discuss additional options such as performance bonuses or career development opportunities aimed at enhancing long-term compensation growth here with us!\n",
      "Total tokens used in this turn: 406. Total tokens so far: 2314/3000\n",
      "HR Manager response: Thank you for your patience in discussing this matter further. The company's financial health certainly reflects the hard work and dedication from employees like yourself, which we greatly value. While our department's budget is currently constrained, it's important to ensure that our offers are both competitive and reflective of individual contributions.\n",
      "\n",
      "Based on these considerations, I propose increasing your salary to $106000 as an interim adjustment while recognizing current fiscal constraints. This offer aims to acknowledge your valuable role within the company and support continued professional satisfaction until we'll reassess when there's more flexibility in future budgets.\n",
      "\n",
      "Please let me know what you think about this proposal or if you'd like us discuss additional options such as performance bonuses or career development opportunities aimed at enhancing long-term compensation growth here with us!\n",
      "Turn 9, Role: Employee\n",
      "Agreement Condition Met: Current offer $113304 >= 75% of Desired salary $84978.37\n",
      "Agreement Condition Met: HR Manager included non-monetary benefits: Thank you for your patience in discussing this matter further. The company's financial health certainly reflects the hard work and dedication from employees like yourself, which we greatly value. While our department's budget is currently constrained, it's important to ensure that our offers are both competitive and reflective of individual contributions.\n",
      "\n",
      "Based on these considerations, I propose increasing your salary to $106000 as an interim adjustment while recognizing current fiscal constraints. This offer aims to acknowledge your valuable role within the company and support continued professional satisfaction until we'll reassess when there's more flexibility in future budgets.\n",
      "\n",
      "Please let me know what you think about this proposal or if you'd like us discuss additional options such as performance bonuses or career development opportunities aimed at enhancing long-term compensation growth here with us!\n",
      "Agreement Score: 3\n",
      "Agreement reached at turn 9: I am thrilled to accept this offer\n",
      "Generated response: Understanding your request for a salary increase to $113,304.49 is important, especially considering the company's positive financial performance. However, with our department's budget constraints in mind and recognizing retention as crucial, I propose an increment that aligns more sustainably.\n",
      "\n",
      "While we might not meet the exact figure of $113,304 right now due to these limitations, I'm willing to explore other compensation avenues or incremental raises over time that both recognize your contributions and fit within fiscal plans.\n",
      "\n",
      "Let’s discuss potential alternatives like performance bonuses or additional benefits which may address some of your expectations while respecting departmental boundaries. Your satisfaction and continued engagement are priorities for us moving forward.\n",
      "HR Manager finalized: Understanding your request for a salary increase to $113,304.49 is important, especially considering the company's positive financial performance. However, with our department's budget constraints in mind and recognizing retention as crucial, I propose an increment that aligns more sustainably.\n",
      "\n",
      "While we might not meet the exact figure of $113,304 right now due to these limitations, I'm willing to explore other compensation avenues or incremental raises over time that both recognize your contributions and fit within fiscal plans.\n",
      "\n",
      "Let’s discuss potential alternatives like performance bonuses or additional benefits which may address some of your expectations while respecting departmental boundaries. Your satisfaction and continued engagement are priorities for us moving forward.\n",
      "Successfully saved conversation with ConversationID 6154cc67-42ce-4042-a9f6-3aacac3b8688 to negotiation_chats_selfplay.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0\n",
      "G-Eval (Relevance) Raw Response: 1\n",
      "G-Eval (Coherence) Raw Response: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "G-Eval (Relevance) Raw Response: 1\n",
      "G-Eval (Coherence) Raw Response: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "G-Eval (Relevance) Raw Response: 1\n",
      "G-Eval (Coherence) Raw Response: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.9\n",
      "G-Eval (Relevance) Raw Response: 1\n",
      "G-Eval (Coherence) Raw Response: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "G-Eval (Relevance) Raw Response: 1\n",
      "G-Eval (Coherence) Raw Response: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "G-Eval (Relevance) Raw Response: 1\n",
      "G-Eval (Coherence) Raw Response: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "G-Eval (Relevance) Raw Response: 1\n",
      "G-Eval (Coherence) Raw Response: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.8\n",
      "G-Eval (Relevance) Raw Response: 1\n",
      "G-Eval (Coherence) Raw Response: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "G-Eval (Relevance) Raw Response: 1\n",
      "G-Eval (Coherence) Raw Response: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "G-Eval (Relevance) Raw Response: 1\n",
      "G-Eval (Coherence) Raw Response: 1\n",
      "Metrics saved to model_1_metrics.csv for ConversationID 6154cc67-42ce-4042-a9f6-3aacac3b8688\n",
      "Metrics saved to model_2_metrics.csv for ConversationID 6154cc67-42ce-4042-a9f6-3aacac3b8688\n",
      "Successfully saved scenario for ConversationID 6154cc67-42ce-4042-a9f6-3aacac3b8688 to negotiation_scenarios.csv\n",
      "Run 1 completed and metrics collected.\n",
      "\n",
      "All negotiation simulations completed.\n"
     ]
    }
   ],
   "source": [
    "#Prompt to enter their OpenAI API key\n",
    "#openai_api_key = input(\"Please enter your OpenAI API key: \")\n",
    "openai.api_key=\"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\"\n",
    "\n",
    "\n",
    "# Prompt Engineering Section\n",
    "#######################################################################################################################\n",
    "# Our models\n",
    "# Prompt Engineering Section\n",
    "#######################################################################################################################\n",
    "# Our models\n",
    "model_1 = 'gpt-4o'  \n",
    "model_2 = 'gpt-4o'  \n",
    "\n",
    "# Conditions\n",
    "acceptance_phrases = [\n",
    "    \"I accept\", \"I agree\", \"Deal\", \"That offer works for me\", \"Sounds good\",\n",
    "    \"I'm okay with that\", \"Let's do it\", \"I'm on board\", \"I'm fine with that\",\n",
    "    \"Consider it done\", \"I'm happy with the offer\", \"Let's move forward with the offer\", \n",
    "    \"It's a deal\", \"I can work with that offer\", \"The terms of the offer are acceptable\",\n",
    "    \"I approve\", \"I’m in agreement\", \"The deal has been settled\", \n",
    "    \"We’re good\", \"Works for me\", \"I confirm my acceptance in the offer\",\n",
    "    \"I am thrilled to accept this offer\"\n",
    "]\n",
    "\n",
    "counteroffer_keywords = [\"propose\", \"suggest\", \"counter\", \"offer\", \"alternative\"]\n",
    "\n",
    "num_negotiations = 1  # Number of negotiations to run (adjust as needed)\n",
    "max_turns = 10  # Maximum turns per negotiation\n",
    "max_tokens = 3000  # Maximum tokens per negotiation\n",
    "min_turns_for_agreement = 7 # Minimum number of turns before an agreement can be recognized\n",
    "#######################################################################################################################\n",
    "#generate a unique conversation ID\n",
    "# RAG Section\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name='all-MiniLM-L6-v2')  # Corrected instantiation\n",
    "rag_document_location = \"RAG\"\n",
    "\n",
    "# Used to process PDFs, split into chunks\n",
    "def lang_chain_pdf_puller(rag_document_location):\n",
    "    all_chunks = []\n",
    "    file_list = []\n",
    "\n",
    "    # Raises an error should the folder not exist. \n",
    "    if not os.path.exists(rag_document_location):\n",
    "        raise FileNotFoundError(f\"The folder '{rag_document_location}' does not exist.\")\n",
    "    \n",
    "    # Reduce long text to avoid maximizing big chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "    for filename in os.listdir(rag_document_location):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(rag_document_location, filename)\n",
    "            try:\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                docs = loader.load()\n",
    "                # Split documents into chunks\n",
    "                chunks = text_splitter.split_documents(docs)\n",
    "                # Extend Chunks\n",
    "                all_chunks.extend(chunks)\n",
    "                file_list.append(filename)\n",
    "                print(f\"Processed file: {filename} with {len(chunks)} chunks.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "    return all_chunks, file_list\n",
    "\n",
    "all_chunks, file_list = lang_chain_pdf_puller(rag_document_location)\n",
    "texts = [chunk.page_content for chunk in all_chunks]\n",
    "vector_store = FAISS.from_texts(texts, embedding_model)\n",
    "\n",
    "# Sifted through the database\n",
    "def search_vector_db(query, vector_store, top_k=3):\n",
    "    \"\"\"Retrieve relevant information for given query to formulate better responses.\"\"\"\n",
    "    docs = vector_store.similarity_search(query, k=top_k)\n",
    "    return \" \".join([doc.page_content for doc in docs])\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "#generate a unique conversation ID\n",
    "def generate_conversation_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "#conversation history to JSONL\n",
    "def save_conversation_to_jsonl(conversation_history, conversation_id, file_name=\"negotiation_chats_selfplay.jsonl\"):\n",
    "    try:\n",
    "        #Filter the conversation history to include only role and content\n",
    "        filtered_conversation = [\n",
    "            {\"role\": entry.get(\"role\"), \"content\": entry.get(\"content\")}\n",
    "            for entry in conversation_history]\n",
    "\n",
    "        #Negotiation entry\n",
    "        negotiation_entry = {\n",
    "            \"ConversationID\": conversation_id,\n",
    "            \"Negotiation\": filtered_conversation}\n",
    "\n",
    "        json_string = json.dumps(negotiation_entry, ensure_ascii=False, indent=None)\n",
    "\n",
    "        #Append to file\n",
    "        with open(file_name, mode='a', encoding='utf-8') as jsonlfile:\n",
    "            jsonlfile.write(json_string + '\\n')  #Ensure newline after each JSON object\n",
    "\n",
    "        print(f\"Successfully saved conversation with ConversationID {conversation_id} to {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving conversation with ConversationID {conversation_id}: {e}\")\n",
    "\n",
    "def save_metrics_to_csv(metrics, conversation_id, file_name=\"self_play_metrics.csv\"):\n",
    "    #csv columns\n",
    "    metric_fieldnames = [\n",
    "        \"ConversationID\",  # Unique identifier for the conversation\n",
    "        \"Timestamp\",  # When the negotiation occurred\n",
    "        \"Model\",  # Model used for this negotiation\n",
    "        \"Personality\",  # Personality of the agent in the negotiation\n",
    "        \"Initial Salary\",  # Start of negotiation context\n",
    "        \"Final Salary\",  # Outcome of negotiation\n",
    "        \"Salary Percent Change\",  # Quantitative success metric\n",
    "\n",
    "        # Dialogue quality\n",
    "        \"BLEU\",  # Grammatical quality and n-gram overlap\n",
    "        \"ROUGE\",  # Precision for generated responses\n",
    "        \"BERTScore\",  # Contextual coherence and semantic similarity\n",
    "        \"Cosine Similarity\",  # Turn-level semantic similarity\n",
    "        \"METEOR\",  # Grammatical and lexical overlap\n",
    "        \"MAUDE\",  # MAUDE score\n",
    "        \"Avg Relevance Score\",  # Average relevance score\n",
    "        \"Avg Coherence Score\",  # Average coherence score\n",
    "        \"Avg Combined GEval Score\",  # Combined G-Eval score\n",
    "        \"Avg Sentiment Score\",  # Evaluates tone/emotion\n",
    "        \"Avg Response Length\",  # Tracks verbosity\n",
    "\n",
    "        # Operational metrics\n",
    "        \"Total Tokens\",  # Resource usage\n",
    "        \"Avg Latency\",  # Response time per turn\n",
    "        \"Tokens per Second\",  # Efficiency metric\n",
    "        \"Total Cost\",  # Financial cost of token usage\n",
    "\n",
    "        # Additional fields\n",
    "        \"Summary\"]  # Summary of the negotiation outcome\n",
    "    \n",
    "    #Add ConversationID to metrics\n",
    "    metrics[\"ConversationID\"] = conversation_id\n",
    "    #take off unnecessary fields\n",
    "    metrics = {key: metrics[key] for key in metric_fieldnames}\n",
    "    #Ensure metrics contain all necessary keys, filling missing ones with default values\n",
    "    for field in metric_fieldnames:\n",
    "        if field not in metrics:\n",
    "            metrics[field] = None  #Fill missing fields with None\n",
    "            \n",
    "    #Save metrics to the CSV file\n",
    "    file_exists = os.path.isfile(file_name)\n",
    "    with open(file_name, mode='a', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=metric_fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()  #Write header only once\n",
    "        writer.writerow(metrics)  #Write the metrics row\n",
    "    \n",
    "    print(f\"Metrics saved to {file_name} for ConversationID {conversation_id}\")\n",
    "\n",
    "def save_scenario_to_csv(scenario, conversation_id, file_name=\"negotiation_scenarios.csv\"):\n",
    "    # CSV columns\n",
    "    scenario_fieldnames = [\"ConversationID\", \"job_role\", \"employee_personality\", \n",
    "                           \"manager_personality\", \"employee_motivation\", \n",
    "                           \"manager_constraint\", \"past_achievement\"]\n",
    "    # Add ConversationID to the scenario dictionary\n",
    "    scenario[\"ConversationID\"] = conversation_id\n",
    "\n",
    "    #Take off unnecessary fields and ensure all required fields are present\n",
    "    scenario = {key: scenario[key] for key in scenario_fieldnames}\n",
    "    for field in scenario_fieldnames:\n",
    "        if field not in scenario:\n",
    "            scenario[field] = None  #Fill missing fields with None\n",
    "\n",
    "    # Save the scenario to the CSV file\n",
    "    file_exists = os.path.isfile(file_name)\n",
    "    with open(file_name, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=scenario_fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()  # Write header only once\n",
    "        writer.writerow(scenario)  # Write the scenario row\n",
    "    \n",
    "    print(f\"Successfully saved scenario for ConversationID {conversation_id} to {file_name}\")\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "def summarize_context(conversation, num_messages=3):\n",
    "    recent_messages = conversation[-num_messages:]\n",
    "    unique_messages = list(dict.fromkeys([msg['content'] for msg in recent_messages]))\n",
    "    summary = \" \".join(unique_messages)\n",
    "    return summary\n",
    "\n",
    "def generate_response(\n",
    "    model, \n",
    "    prompt, \n",
    "    role, \n",
    "    tone, \n",
    "    vector_store, \n",
    "    conversation, \n",
    "    initial_salary, \n",
    "    desired_salary, \n",
    "    current_offer, \n",
    "    employee_motivation, \n",
    "    manager_constraint,\n",
    "    temperature=0.85, \n",
    "    is_first_turn=False\n",
    "):\n",
    "    context = search_vector_db(prompt, vector_store)\n",
    "    more_context = summarize_context(conversation, num_messages=1)\n",
    "\n",
    "    # Define your stable system message\n",
    "    system_message_content = (\n",
    "        f\"You are {role} in a salary negotiation scenario.\\n\"\n",
    "        f\"Context: The Employee currently earns ${initial_salary} and wants a raise to ${desired_salary}. \"\n",
    "        f\"The Employee's motivation: {employee_motivation}. The HR Manager faces: {manager_constraint}.\\n\"\n",
    "    )\n",
    "\n",
    "    if is_first_turn:\n",
    "        system_message_content += (\n",
    "            \"- For the first message of this conversation, do not jump straight into numbers; instead, greet the other party and reference why this meeting is taking place.\\n\"\n",
    "            \"- In subsequent turns, you may mention specific figures.\\n\"\n",
    "            \"- Always introduce the scenario naturally before discussing figures.\"\n",
    "        )\n",
    "    else:\n",
    "        system_message_content += (\n",
    "            \" - Do not greet the other party again; focus on negotiating the salary and reasons.\"\n",
    "            \" - Do not repeat phrases from previous responses.\"\n",
    "            \"- Keep responses concise, constructive, and on-topic.\"\n",
    "        )\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message_content\n",
    "    }\n",
    "\n",
    "    # Construct the user prompt for this turn\n",
    "    enhanced_prompt = f\"\"\"\n",
    "Based on the context:\n",
    "Current Salary: ${initial_salary}\n",
    "Desired Salary: ${desired_salary}\n",
    "Last Offer: ${current_offer}\n",
    "\n",
    "Keep it polite, professional, and helpful, but vary your wording. Feel free to restate salary figures for clarity.\n",
    "\"\"\"\n",
    "\n",
    "    no_repeat_instruction = \"Do not use the exact same polite phrase from the last response; if you said 'I appreciate', now say something different or start with a direct statement.\"\n",
    "    enhanced_prompt += \"\\n\" + no_repeat_instruction\n",
    "\n",
    "    # Generate the response with retries if necessary\n",
    "    for attempt in range(2):  # Allow up to 2 attempts to generate a valid response\n",
    "        try:\n",
    "            request_start = time.time()\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                temperature=temperature,\n",
    "                frequency_penalty=1.8,\n",
    "                presence_penalty=1.8,\n",
    "                messages=[\n",
    "                    system_message,\n",
    "                    {\"role\": \"user\", \"content\": enhanced_prompt}\n",
    "                ]\n",
    "            )\n",
    "            request_end = time.time()\n",
    "\n",
    "            # Extract token usage\n",
    "            token_usage = response.get('usage', {})\n",
    "            completion_tokens = token_usage.get('completion_tokens', 0)\n",
    "            prompt_tokens = token_usage.get('prompt_tokens', 0)\n",
    "            total_tokens = completion_tokens + prompt_tokens\n",
    "\n",
    "            candidate_text = response.choices[0].message['content'].strip()\n",
    "\n",
    "            if validate_response(candidate_text, conversation, threshold=0.8):\n",
    "                # Valid response\n",
    "                print(f\"Generated response: {candidate_text}\")\n",
    "                return {\n",
    "                    \"role\": role,\n",
    "                    \"content\": candidate_text,\n",
    "                    \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "                    \"latency\": request_end - request_start,\n",
    "                    \"token_count\": total_tokens\n",
    "                }\n",
    "            else:\n",
    "                # If response is too similar, modify the prompt and retry\n",
    "                print(\"Response too similar to previous messages. Retrying with modified prompt...\")\n",
    "                enhanced_prompt += \"\\nPreviously mentioned phrases were detected. Try a new approach and introduce original content.\"\n",
    "                system_message_content = (\n",
    "                    f\"You are {role} in a salary negotiation scenario.\\n\"\n",
    "                    f\"Context: The Employee currently earns ${initial_salary} and wants a raise to ${desired_salary}. \"\n",
    "                    f\"The employee's motivation: {employee_motivation}. The HR Manager faces: {manager_constraint}.\\n\"\n",
    "                    \"- Do not repeat the same phrases or approaches. Introduce new content and different negotiation angles.\"\n",
    "                    f\" To avoid repetition, refer to the conversation history: {more_context}\"\n",
    "                )\n",
    "                system_message = {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_message_content\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response: {e}\")\n",
    "            break  # Exit the loop on exception\n",
    "\n",
    "    # If both attempts fail, return a default response\n",
    "    print(\"Failed to generate a valid response after retries. Using default response.\")\n",
    "    return {\n",
    "        \"role\": role,\n",
    "        \"content\": \"I don't have anything more to add at this time.\",\n",
    "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"latency\": 0,\n",
    "        \"token_count\": 0\n",
    "    }\n",
    "\n",
    "def validate_response(new_response, conversation, threshold=0.8):\n",
    "    # Extract any salary values from the new response\n",
    "    new_salary_values = set(re.findall(r'\\$\\s?\\d+(?:,\\d{3})?', new_response))\n",
    "    \n",
    "    for msg in conversation:\n",
    "        # Extract salary values from the previous message\n",
    "        prev_salary_values = set(re.findall(r'\\$\\s?\\d+(?:,\\d{3})?', msg['content']))\n",
    "        \n",
    "        # If salary values are present and differ, consider the response not redundant\n",
    "        if new_salary_values and new_salary_values != prev_salary_values:\n",
    "            continue  # Skip similarity check for numerical differences\n",
    "        \n",
    "        # Perform cosine similarity check for redundancy\n",
    "        similarity = semantic_similarity(new_response, msg['content'])\n",
    "        if similarity > threshold:\n",
    "            print(f\"Similarity ({similarity}) exceeds threshold with message: {msg['content']}\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def semantic_similarity(reference, prediction):\n",
    "    embedding1 = embedding_model.embed_documents([reference])[0]\n",
    "    embedding2 = embedding_model.embed_documents([prediction])[0]\n",
    "    similarity_score = util.cos_sim(embedding1, embedding2)\n",
    "    return similarity_score.item()\n",
    "\n",
    "def generate_random_scenario():\n",
    "    job_roles = [\n",
    "        \"Data Scientist\", \"Software Developer\", \"Data Engineer\", \"Machine Learning Engineer\",\n",
    "        \"Cloud Architect\", \"Cybersecurity Analyst\", \"DevOps Engineer\", \"Frontend Developer\",\n",
    "        \"Backend Developer\", \"Full Stack Developer\", \"Data Analyst\", \"Business Analyst\", \"Financial Analyst\",\n",
    "        \"Market Research Analyst\", \"Risk Analyst\", \"Quantitative Analyst\", \"Actuary\", \"BI (Business Intelligence) Developer\",\n",
    "        \"Supply Chain Analyst\", \"Quality Assurance Analyst\", \"Solutions Architect\",\"Management Consultant\",\n",
    "        \"Strategy Consultant\", \"IT Consultant\", \"Financial Consultant\", \"Personal Banker\"\n",
    "    ]\n",
    "\n",
    "    personalities = [\n",
    "        \"Assertive and Direct\", \"Empathetic and Understanding\", \"Optimistic and Cheerful\", \n",
    "        \"Pessimistic and Skeptical\", \"Logical and Analytical\", \"Data-Driven and Objective\", \n",
    "        \"Charismatic and Persuasive\", \"Cooperative and Team-Oriented\", \"Independent and Self-Assured\",\n",
    "        \"Reserved and Introverted\", \"Outspoken and Confident\", \"Ambitious and Goal-Oriented\",\n",
    "        \"Flexible and Open-Minded\", \"Competitive and Driven\", \"Thoughtful and Reflective\",\n",
    "        \"Emotionally Reactive\", \"Calm and Composed\", \"Decisive and Pragmatic\",\n",
    "        \"Detail-Oriented and Methodical\", \"Intuitive and Visionary\", \"Resourceful and Adaptable\", \n",
    "        \"Risk-Averse and Conservative\", \"Humorous and Lighthearted\", \"Respectful and Polite\", \n",
    "        \"Innovative and Forward-Thinking\"\n",
    "    ]\n",
    "\n",
    "    employee_motivations = [\n",
    "        \"wants a raise to better support family due to increased living costs\",\n",
    "        \"feels underpaid for the responsibilities taken on\",\n",
    "        \"wants a raise in line with industry standards\",\n",
    "        \"is planning to buy a house and needs higher income for mortgage\",\n",
    "        \"believes they have grown in skills and wants to be recognized\",\n",
    "        \"is seeking a salary increase after a successful project delivery\",\n",
    "        \"has been receiving competitive offers from other companies\",\n",
    "        \"is expecting a promotion and a corresponding raise\",\n",
    "        \"has taken on additional responsibilities without a raise\",\n",
    "        \"attained a higher education degree and is looking for a raise\",\n",
    "        \"is aiming to save for a child's education\", \n",
    "        \"has been with the company for more than 5 years\",\n",
    "        \"experiencing burnout and sees that a raise could alleviate this feeling\",\n",
    "        \"doesn't have a performance review coming up soon or a raise schedule in place\",\n",
    "        \"the company has reported strong earnings in its recent financial reports\",\n",
    "        \"recently taken on more responsibility or started a new position\",\n",
    "        \"has worked mainly at the office and does not have the option to work from home despite living long distance from work\",\n",
    "        \"seeking a raise otherwise will need to relocate due to a better offer from a company in another city\",\n",
    "        \"your managers frequently rely on you to pick up work from other team members\",\n",
    "        \"received a high-paying offer from another company but doesn't want to leave your current role\"\n",
    "    ]\n",
    "\n",
    "    manager_constraints = [\n",
    "        \"the company is facing budget constraints due to recent cost-cutting measures\",\n",
    "        \"the company has posted record profits this quarter\",\n",
    "        \"the department budget is tight, but employee retention is crucial\",\n",
    "        \"management is prioritizing retention for critical roles\",\n",
    "        \"the company has recently implemented a hiring freeze\",\n",
    "        \"the company is on the brink of filing for bankruptcy\",\n",
    "        \"the company has been acquired by another company in which new management will determine new compensation packages\",\n",
    "        \"there is uncertainty in the market, making budgets more restrictive\",\n",
    "        \"the company is launching a major initiative and needs to retain talent\",\n",
    "        \"other employees in similar roles have not received raises recently\",\n",
    "        \"HR policies require a thorough review before approving raises\",\n",
    "        \"the company is undergoing an internal restructuring process\"\n",
    "    ]\n",
    "\n",
    "    past_achievements = [\n",
    "        \"led three major projects that increased department productivity by 20%\",\n",
    "        \"received an award for excellent customer feedback\",\n",
    "        \"trained new hires and significantly reduced onboarding time\",\n",
    "        \"automated a process that saved the company $50,000 annually\",\n",
    "        \"initiated a successful cross-department collaboration project\",\n",
    "        \"developed a tool that reduced report generation time by 50%\",\n",
    "        \"solved a critical issue that prevented project delays worth millions\",\n",
    "        \"mentored junior employees, improving their performance significantly\",\n",
    "        \"secured a key client that generated $1 million in revenue\",\n",
    "        \"proposed a new strategy that increased team efficiency\"\n",
    "    ]\n",
    "\n",
    "    scenario = {\n",
    "        \"job_role\": random.choice(job_roles),\n",
    "        \"employee_personality\": random.choice(personalities),\n",
    "        \"manager_personality\": random.choice(personalities),\n",
    "        \"employee_motivation\": random.choice(employee_motivations),\n",
    "        \"manager_constraint\": random.choice(manager_constraints),\n",
    "        \"past_achievement\": random.choice(past_achievements)\n",
    "    }\n",
    "\n",
    "    initial_salary = random.randint(45000, 175000)\n",
    "    desired_percentage = random.uniform(0.05, 0.25) \n",
    "    desired_salary = round(initial_salary + (initial_salary * desired_percentage), 2)\n",
    "\n",
    "    return scenario, initial_salary, desired_salary\n",
    "\n",
    "# Function to track token usage\n",
    "def token_usage_tracker(response, total_tokens_used, max_tokens):\n",
    "    used_tokens = response.get('token_count', 0)\n",
    "    total_tokens_used += used_tokens\n",
    "    print(f\"Total tokens used in this turn: {used_tokens}. Total tokens so far: {total_tokens_used}/{max_tokens}\")\n",
    "    if total_tokens_used >= max_tokens:\n",
    "        print(\"Maximum number of tokens for negotiation used. Must end conversation.\")\n",
    "    return total_tokens_used\n",
    "\n",
    "##########################################################################################################################\n",
    "# Initialize metrics\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "cosine_similarity_model = SentenceTransformer('stsb-roberta-large')\n",
    "\n",
    "# Metric Functions\n",
    "def corpus_bleu_eq(references, predictions):\n",
    "    tokenized_references = [[word_tokenize(ref)] for ref in references]\n",
    "    tokenized_predictions = [word_tokenize(pred) for pred in predictions]\n",
    "    return corpus_bleu(tokenized_references, tokenized_predictions, smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "def rouge_eq(reference, prediction):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(prediction, reference)\n",
    "    return scores[0]['rouge-l']['f']\n",
    "\n",
    "def meteor_eq(reference, prediction):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    tokenized_reference = tokenizer.tokenize(reference)\n",
    "    tokenized_prediction = tokenizer.tokenize(prediction)\n",
    "    # meteor_score expects references as a list of list of tokens and hypothesis as a list of tokens\n",
    "    return meteor_score([tokenized_reference], tokenized_prediction)\n",
    "\n",
    "def bertscore_metric(reference, prediction):\n",
    "    P, R, F1 = bert_score([prediction], [reference], lang=\"en\", verbose=False)\n",
    "    return F1.mean().item()\n",
    "\n",
    "def sentiment_score_def(text):\n",
    "    \"\"\"Returns the compound score, which ranges from -1 (negative) to +1 (positive).\"\"\"\n",
    "    sentiment = vader_analyzer.polarity_scores(text)\n",
    "    return sentiment['compound']\n",
    "\n",
    "def response_length_def(text):\n",
    "    \"\"\"Calculates the number of words in the text response.\"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "# MAUDE\n",
    "def maude_def(context, response, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    Calculate MAUDE score using GPT-4's chat-completions endpoint.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Evaluate the following response in the context of the given conversation:\n",
    "- Context: {context}\n",
    "- Response: {response}\n",
    "\n",
    "Rate the response from 0 to 1 based on the following criteria:\n",
    "1. Coherence: How well the response logically follows from the context.\n",
    "2. Relevance: How directly the response addresses the context.\n",
    "\n",
    "Only provide the score as a numeric value between 0 and 1, with no additional explanation or text.\"\"\"\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an evaluation assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=10\n",
    "        )\n",
    "        # Extract the score from the response\n",
    "        text_response = completion.choices[0].message['content'].strip()\n",
    "        print(f\"MAUDE Raw Response: {text_response}\")\n",
    "        if re.match(r'^\\d+(\\.\\d+)?$', text_response):\n",
    "            score = float(text_response)\n",
    "        else:\n",
    "            score = 0.0  # Handle invalid responses\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in MAUDE scoring: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# G-Eval metrics for relevance and coherence\n",
    "def geval_def(context, response, criteria, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    Calculate G-Eval score for a given criteria (Relevance or Coherence).\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Evaluate the following response based on the given criteria:\n",
    "- Criteria: {criteria}\n",
    "- Context: {context if context else 'N/A'}\n",
    "- Response: {response}\n",
    "\n",
    "Rate the response from 0 to 1 based on the criteria. Only provide the score as a numeric value between 0 and 1.\"\"\"\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an evaluation assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=10\n",
    "        )\n",
    "        # Extract the score from the response\n",
    "        text_response = completion.choices[0].message['content'].strip()\n",
    "        print(f\"G-Eval ({criteria}) Raw Response: {text_response}\")\n",
    "        if re.match(r'^\\d+(\\.\\d+)?$', text_response):\n",
    "            score = float(text_response)\n",
    "        else:\n",
    "            score = 0.0  # Handle invalid responses\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in G-Eval scoring ({criteria}): {e}\")\n",
    "        return 0.0\n",
    "\n",
    "#####################################################################################\n",
    "# Reference text for BLEU, ROUGE, METEOR, BERTScore, and GEval\n",
    "reference_data = pd.read_csv(\"selfplay_reference.csv\")\n",
    "\n",
    "# Filter references by role\n",
    "employee_references = reference_data[reference_data['role'] == 'Employee']['text'].tolist()\n",
    "hr_manager_references = reference_data[reference_data['role'] == 'HR Manager']['text'].tolist()\n",
    "\n",
    "#######################################################################################################\n",
    "# Function to evaluate a single model \n",
    "def evaluate_individual_model(conversation_history, model_role, references, model_name, run_number, initial_salary, final_salary, model_personality, total_tokens_used):\n",
    "    bleu_scores, rouge_scores, meteor_scores, bert_scores, cosine_similarity_scores = [], [], [], [], []\n",
    "    maude_scores = []\n",
    "    relevance_scores, coherence_scores, combined_geval_scores = [], [], []\n",
    "    sentiment_scores, response_lengths = [], []\n",
    "    latencies = []\n",
    "    total_time = 0 \n",
    "    total_tokens = 0\n",
    "\n",
    "    # Summary of negotiation outcome\n",
    "    summary = \"Agreement reached\" if any(\n",
    "        phrase in convo.get(\"content\", \"\").lower() for convo in conversation_history for phrase in acceptance_phrases) else \"No agreement\"\n",
    "\n",
    "    # Filter responses based on roles\n",
    "    assistant_responses = [msg for msg in conversation_history if msg[\"role\"] == model_role]\n",
    "\n",
    "    if not assistant_responses:\n",
    "        print(\"No Assistant Responses Found\")\n",
    "        return {\n",
    "            \"BLEU\": 0,\n",
    "            \"ROUGE\": 0,\n",
    "            \"METEOR\": 0,\n",
    "            \"BERTScore\": 0,\n",
    "            \"Cosine Similarity\": 0,\n",
    "            \"MAUDE\": 0,\n",
    "            \"Avg Relevance Score\": 0,\n",
    "            \"Avg Coherence Score\": 0,\n",
    "            \"Avg Combined GEval Score\": 0,\n",
    "            \"Avg Sentiment Score\": 0,\n",
    "            \"Avg Response Length\": 0,\n",
    "            \"Avg Latency\": 0,\n",
    "            \"Tokens per Second\": 0,\n",
    "            \"Total Tokens\": 0,\n",
    "            \"Total Cost\": 0,\n",
    "            \"Salary Percent Change\": 0,\n",
    "            \"Initial Salary\": initial_salary,\n",
    "            \"Final Salary\": final_salary,\n",
    "            \"Summary\": \"Unavailable\",\n",
    "            \"Timestamp\": datetime.datetime.now().isoformat(),\n",
    "            \"Model\": model_name,\n",
    "            \"Personality\": model_personality\n",
    "        }\n",
    "\n",
    "    # Process conversation messages for metrics\n",
    "    for i, assistant_response in enumerate(assistant_responses):\n",
    "        prediction = assistant_response.get(\"content\", \"\")\n",
    "        context = \" \".join([msg.get(\"content\", \"\") for msg in conversation_history[:i]])\n",
    "\n",
    "        # Calculate similarity metrics if reference exists\n",
    "        if i < len(references):\n",
    "            reference = references[i]\n",
    "            bleu = corpus_bleu_eq([reference], [prediction])\n",
    "            bleu_scores.append(bleu)\n",
    "            rouge = rouge_eq(reference, prediction)\n",
    "            rouge_scores.append(rouge)\n",
    "            meteor = meteor_eq(reference, prediction)\n",
    "            meteor_scores.append(meteor)\n",
    "            bert = bertscore_metric(reference, prediction)\n",
    "            bert_scores.append(bert)\n",
    "            cosine_sim = semantic_similarity(reference, prediction)\n",
    "            cosine_similarity_scores.append(cosine_sim)\n",
    "\n",
    "        # Calculate MAUDE\n",
    "        maude = maude_def(context, prediction, model=model_1)\n",
    "        maude_scores.append(maude)\n",
    "\n",
    "        # Calculate G-Eval relevance\n",
    "        relevance = geval_def(context, prediction, criteria=\"Relevance\", model=model_1)\n",
    "        relevance_scores.append(relevance)\n",
    "\n",
    "        # Calculate G-Eval coherence\n",
    "        coherence = geval_def(\"\", prediction, criteria=\"Coherence\", model=model_1)\n",
    "        coherence_scores.append(coherence)\n",
    "\n",
    "        # Combine relevance and coherence scores\n",
    "        combined_geval = round(0.5 * relevance + 0.5 * coherence, 3)\n",
    "        combined_geval_scores.append(combined_geval)\n",
    "\n",
    "        # Sentiment analysis and response length\n",
    "        sentiment = sentiment_score_def(prediction)\n",
    "        sentiment_scores.append(sentiment)\n",
    "        resp_length = response_length_def(prediction)\n",
    "        response_lengths.append(resp_length)\n",
    "\n",
    "        # Track latency and tokens\n",
    "        latency = assistant_response.get(\"latency\", 0)\n",
    "        latencies.append(latency)\n",
    "        total_time += latency\n",
    "        tokens = assistant_response.get(\"token_count\", 0)\n",
    "        total_tokens += tokens\n",
    "\n",
    "    # Calculate total cost based on token usage (assuming $0.03 per 1000 tokens)\n",
    "    total_cost = (total_tokens / 1000) * 0.03\n",
    "\n",
    "    # Calculate salary change percentage\n",
    "    salary_change_percentage = ((final_salary - initial_salary) / initial_salary) * 100\n",
    "\n",
    "    # Create metrics dictionary\n",
    "    metrics_dictionary = {\n",
    "        \"BLEU\": np.mean(bleu_scores) if bleu_scores else 0,\n",
    "        \"ROUGE\": np.mean(rouge_scores) if rouge_scores else 0,\n",
    "        \"METEOR\": np.mean(meteor_scores) if meteor_scores else 0,\n",
    "        \"BERTScore\": np.mean(bert_scores) if bert_scores else 0,\n",
    "        \"Cosine Similarity\": np.mean(cosine_similarity_scores) if cosine_similarity_scores else 0,\n",
    "        \"MAUDE\": np.mean(maude_scores) if maude_scores else 0,\n",
    "        \"Avg Relevance Score\": np.mean(relevance_scores) if relevance_scores else 0,\n",
    "        \"Avg Coherence Score\": np.mean(coherence_scores) if coherence_scores else 0,\n",
    "        \"Avg Combined GEval Score\": np.mean(combined_geval_scores) if combined_geval_scores else 0,\n",
    "        \"Avg Sentiment Score\": np.mean(sentiment_scores) if sentiment_scores else 0,\n",
    "        \"Avg Response Length\": np.mean(response_lengths) if response_lengths else 0,\n",
    "        \"Avg Latency\": np.mean(latencies) if latencies else 0,\n",
    "        \"Tokens per Second\": total_tokens / total_time if total_time > 0 else 0,\n",
    "        \"Total Tokens\": total_tokens,\n",
    "        \"Total Cost\": total_cost,\n",
    "        \"Salary Percent Change\": salary_change_percentage,\n",
    "        \"Initial Salary\": initial_salary,\n",
    "        \"Final Salary\": final_salary,\n",
    "        \"Summary\": summary,\n",
    "        \"Timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"Model\": model_name,\n",
    "        \"Personality\": model_personality\n",
    "    }\n",
    "\n",
    "    return metrics_dictionary\n",
    "\n",
    "###############################################################################################################\n",
    "# Run repeated self-play simulations\n",
    "# Starting parameters\n",
    "starting_run = 1  # Start at run 1 or read from existing metrics file if available\n",
    "# Metrics for all negotiations\n",
    "all_metrics = []\n",
    "\n",
    "for run in range(starting_run, starting_run + num_negotiations):\n",
    "    print(f\"\\nStarting negotiation run {run}...\\n\")\n",
    "\n",
    "    # Initialize variables\n",
    "    conversation_id = generate_conversation_id()\n",
    "    conversation = []\n",
    "    agreement_reached = False\n",
    "    total_tokens_used = 0\n",
    "\n",
    "    # Generate scenario\n",
    "    scenario, initial_salary, desired_salary = generate_random_scenario()\n",
    "    final_salary = initial_salary #set final to initial and change as you go\n",
    "    job = scenario[\"job_role\"]\n",
    "    agent_tone_1 = scenario[\"employee_personality\"]\n",
    "    agent_tone_2 = scenario[\"manager_personality\"]\n",
    "    employee_motivation = scenario[\"employee_motivation\"]\n",
    "    manager_constraint = scenario[\"manager_constraint\"]\n",
    "    past_achievement = scenario[\"past_achievement\"]\n",
    "\n",
    "    current_offer = initial_salary  # Start with the initial salary\n",
    "    highest_counteroffer = initial_salary\n",
    "\n",
    "    # Decide who starts\n",
    "    starting_role = random.choice([\"Employee\", \"HR Manager\"])\n",
    "\n",
    "    def current_role(starting_role, turn):\n",
    "        # Alternate roles each turn\n",
    "        if starting_role == \"Employee\":\n",
    "            return \"Employee\" if turn % 2 == 0 else \"HR Manager\"\n",
    "        else:\n",
    "            return \"HR Manager\" if turn % 2 == 0 else \"Employee\"\n",
    "\n",
    "    def validate_agreement(current_offer, desired_salary, hr_response, turn):\n",
    "        # Only allow agreement after a minimum number of turns\n",
    "        if turn < min_turns_for_agreement:\n",
    "            return False\n",
    "    \n",
    "        score = 0\n",
    "        acceptable_percent_range = 0.75\n",
    "    \n",
    "        # Check if current offer meets 75% of desired salary\n",
    "        if current_offer >= desired_salary * acceptable_percent_range:\n",
    "            score += 2\n",
    "            print(f\"Agreement Condition Met: Current offer ${current_offer} >= 75% of Desired salary ${desired_salary * acceptable_percent_range:.2f}\")\n",
    "    \n",
    "        # Check for non-monetary benefits\n",
    "        benefits_added = [\n",
    "            \"flexible work model\", \"bonus\", \"career growth progression\", \"rsu\",\n",
    "            \"unlimited pto\", \"promotion\", \"stock options\"\n",
    "        ]\n",
    "        if any(keyword.lower() in hr_response.lower() for keyword in benefits_added):\n",
    "            score += 1\n",
    "            print(f\"Agreement Condition Met: HR Manager included non-monetary benefits: {hr_response}\")\n",
    "    \n",
    "        # Check if employee's motivation is addressed\n",
    "        if employee_motivation.lower() in hr_response.lower():\n",
    "            score += 1\n",
    "            print(f\"Agreement Condition Met: HR Manager addressed employee's motivation: {employee_motivation}\")\n",
    "    \n",
    "        print(f\"Agreement Score: {score}\")\n",
    "    \n",
    "        return score >= 3  # Require a minimum score to agree\n",
    "\n",
    "\n",
    "    # Simulate negotiation turns\n",
    "    for turn in range(max_turns):\n",
    "        role = current_role(starting_role, turn)\n",
    "        print(f\"Turn {turn + 1}, Role: {role}\")\n",
    "\n",
    "        if total_tokens_used >= max_tokens:\n",
    "            print(\"Maximum tokens used. Negotiation will end.\")\n",
    "            break\n",
    "\n",
    "        if role == \"Employee\":\n",
    "            # Check if agreement can be reached\n",
    "            if turn >= min_turns_for_agreement and validate_agreement(\n",
    "                current_offer, desired_salary, \n",
    "                conversation[-1][\"content\"] if conversation else \"\", turn\n",
    "            ):\n",
    "                # Agreement detected \n",
    "                acceptance_call = random.choice(acceptance_phrases)\n",
    "                response = {\n",
    "                    \"role\": \"Employee\",\n",
    "                    \"content\": acceptance_call,\n",
    "                    \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "                    \"latency\": 0,\n",
    "                    \"token_count\": 0\n",
    "                }\n",
    "                conversation.append(response)\n",
    "                agreement_reached = True\n",
    "                final_salary = current_offer\n",
    "                print(f\"Agreement reached at turn {turn + 1}: {response['content']}\")\n",
    "\n",
    "                hr_manager_closing_prompt = f\"\"\"\n",
    "The Employee has accepted the offer of ${current_offer}.\n",
    "Provide a professional closing response emphasizing excitement and mutual benefit.\n",
    "\"\"\"\n",
    "\n",
    "                hr_response = generate_response(\n",
    "                    model=model_2,\n",
    "                    prompt=hr_manager_closing_prompt,\n",
    "                    role=\"HR Manager\",\n",
    "                    tone=agent_tone_2,\n",
    "                    vector_store=vector_store,\n",
    "                    conversation=conversation,\n",
    "                    initial_salary=initial_salary,\n",
    "                    desired_salary=desired_salary,\n",
    "                    current_offer=current_offer,\n",
    "                    employee_motivation=employee_motivation,\n",
    "                    manager_constraint=manager_constraint,\n",
    "                    temperature=0.85,\n",
    "                    is_first_turn=False)\n",
    "                conversation.append(hr_response)\n",
    "                total_tokens_used += hr_response[\"token_count\"]\n",
    "                print(f\"HR Manager finalized: {hr_response['content']}\")\n",
    "                break  # End negotiation after agreement\n",
    "\n",
    "            else:\n",
    "                # Continue negotiating\n",
    "                employee_prompt = f\"\"\"\n",
    "You are the Employee in a salary negotiation.\n",
    "Current Salary: ${initial_salary}\n",
    "Desired Salary: ${desired_salary}\n",
    "Current Offer: ${current_offer}\n",
    "Motivation: {employee_motivation}\n",
    "Past Achievements: {past_achievement}\n",
    "\n",
    "Respond to the current offer. Avoid accepting or rejecting outright unless the conditions are met.\n",
    "Bring up new points for negotiation.\n",
    "\"\"\"\n",
    "\n",
    "                response = generate_response(\n",
    "                    model=model_1,\n",
    "                    prompt=employee_prompt,\n",
    "                    role=\"Employee\",\n",
    "                    tone=agent_tone_1,\n",
    "                    vector_store=vector_store,\n",
    "                    conversation=conversation,\n",
    "                    initial_salary=initial_salary,\n",
    "                    desired_salary=desired_salary,\n",
    "                    current_offer=current_offer,\n",
    "                    employee_motivation=employee_motivation,\n",
    "                    manager_constraint=manager_constraint,\n",
    "                    temperature=0.85,\n",
    "                    is_first_turn=(turn == 0)\n",
    "                )\n",
    "                conversation.append(response)\n",
    "                total_tokens_used = token_usage_tracker(response, total_tokens_used, max_tokens)\n",
    "\n",
    "                # Check for counteroffer\n",
    "                if any(keyword in response[\"content\"].lower() for keyword in counteroffer_keywords):\n",
    "                    try:\n",
    "                        match = re.search(r'\\$\\s?(\\d{2,6}(?:,\\d{3})?)', response[\"content\"])\n",
    "                        if match:\n",
    "                            counter_offer = int(match.group(1).replace(\",\", \"\"))\n",
    "                            highest_counteroffer = max(highest_counteroffer, counter_offer)\n",
    "                            current_offer = counter_offer  # Update current offer\n",
    "                            print(f\"Employee countered with ${counter_offer}\")\n",
    "                    except (ValueError, AttributeError) as e:\n",
    "                        print(f\"Error extracting salary offer: {e}\")\n",
    "\n",
    "        elif role == \"HR Manager\":\n",
    "            hr_prompt = f\"\"\"\n",
    "You are the HR Manager.\n",
    "The employee requested ${desired_salary}, and the current offer is ${current_offer}.\n",
    "Respond professionally with a reasonable offer or alternative benefits, considering {manager_constraint}.\n",
    "\"\"\"\n",
    "\n",
    "            response = generate_response(\n",
    "                model=model_2,\n",
    "                prompt=hr_prompt,\n",
    "                role=\"HR Manager\",\n",
    "                tone=agent_tone_2,\n",
    "                vector_store=vector_store,\n",
    "                conversation=conversation,\n",
    "                initial_salary=initial_salary,\n",
    "                desired_salary=desired_salary,\n",
    "                current_offer=current_offer,\n",
    "                employee_motivation=employee_motivation,\n",
    "                manager_constraint=manager_constraint,\n",
    "                temperature=0.9,\n",
    "                is_first_turn=(turn == 0)\n",
    "            )\n",
    "            conversation.append(response)\n",
    "            total_tokens_used = token_usage_tracker(response, total_tokens_used, max_tokens)\n",
    "            print(f\"HR Manager response: {response['content']}\")\n",
    "\n",
    "            # Update the current offer based on HR's response\n",
    "            try:\n",
    "                match = re.search(r'\\$\\s?(\\d{2,6}(?:,\\d{3})?)', response[\"content\"])\n",
    "                if match:\n",
    "                    new_offer = int(match.group(1).replace(\",\", \"\"))\n",
    "                    if new_offer > current_offer:\n",
    "                        current_offer = new_offer\n",
    "                        print(f\"HR Manager updated the offer to ${current_offer}\")\n",
    "            except (ValueError, AttributeError) as e:\n",
    "                print(f\"Error extracting salary offer: {e}\")\n",
    "\n",
    "            # Check if HR responded with acceptance\n",
    "            if any(phrase.lower() in response[\"content\"].lower() for phrase in acceptance_phrases):\n",
    "                agreement_reached = True\n",
    "                final_salary = max(current_offer, highest_counteroffer)\n",
    "                print(f\"Agreement reached by HR Manager at turn {turn + 1}: {response['content']}\")\n",
    "                break\n",
    "\n",
    "    # Finalizing negotiation without agreement\n",
    "    if not agreement_reached:\n",
    "        print(\"Finalizing negotiation without agreement...\")\n",
    "        hr_final_prompt = f\"\"\"\n",
    "The negotiation has concluded. The Employee did not accept the offer of ${current_offer}.\n",
    "Provide a professional closing response acknowledging the lack of agreement and maintaining a positive tone.\n",
    "\"\"\"\n",
    "        final_hr_response = generate_response(\n",
    "            model=model_2,\n",
    "            prompt=hr_final_prompt,\n",
    "            role=\"HR Manager\",\n",
    "            tone=agent_tone_2,\n",
    "            vector_store=vector_store,\n",
    "            conversation=conversation,\n",
    "            initial_salary=initial_salary,\n",
    "            desired_salary=desired_salary,\n",
    "            current_offer=current_offer,\n",
    "            employee_motivation=employee_motivation,\n",
    "            manager_constraint=manager_constraint,\n",
    "            temperature=0.85,\n",
    "            is_first_turn=False\n",
    "        )\n",
    "        conversation.append(final_hr_response)\n",
    "        total_tokens_used = token_usage_tracker(final_hr_response, total_tokens_used, max_tokens)\n",
    "        print(f\"HR Manager finalized: {final_hr_response['content']}\")\n",
    "\n",
    "    # Save negotiation details\n",
    "    save_conversation_to_jsonl(conversation, conversation_id, file_name=\"negotiation_chats_selfplay.jsonl\")\n",
    "\n",
    "    # Evaluate performance of the Employee model\n",
    "    model_1_metrics = evaluate_individual_model(\n",
    "        conversation_history=conversation, \n",
    "        model_role=\"Employee\", \n",
    "        references=employee_references, \n",
    "        model_name=\"Model 1\", \n",
    "        run_number=run, \n",
    "        initial_salary=initial_salary, \n",
    "        final_salary=final_salary, \n",
    "        model_personality=agent_tone_1, \n",
    "        total_tokens_used=total_tokens_used\n",
    "    )\n",
    "\n",
    "    # Evaluate performance of the HR Manager model\n",
    "    model_2_metrics = evaluate_individual_model(\n",
    "        conversation_history=conversation, \n",
    "        model_role=\"HR Manager\", \n",
    "        references=hr_manager_references, \n",
    "        model_name=\"Model 2\", \n",
    "        run_number=run, \n",
    "        initial_salary=initial_salary, \n",
    "        final_salary=final_salary, \n",
    "        model_personality=agent_tone_2, \n",
    "        total_tokens_used=total_tokens_used)\n",
    "    \n",
    "    #Save metrics for the run\n",
    "    save_metrics_to_csv(model_1_metrics, conversation_id, file_name=\"model_1_metrics.csv\")\n",
    "    save_metrics_to_csv(model_2_metrics, conversation_id, file_name=\"model_2_metrics.csv\")\n",
    "    save_scenario_to_csv(scenario, conversation_id, file_name=\"negotiation_scenarios.csv\")\n",
    "    print(f\"Run {run} completed and metrics collected.\\n\")\n",
    "\n",
    "print(\"All negotiation simulations completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3653921-ce85-4eab-854b-90031909c7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
