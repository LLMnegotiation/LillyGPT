{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7137efff-4b6a-42da-b3dd-4272a72bddb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Claire Personal\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Claire Personal\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Claire\n",
      "[nltk_data]     Personal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Claire\n",
      "[nltk_data]     Personal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import uuid # for conversation id\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datetime import datetime\n",
    "import openai\n",
    "import random\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "#RAG \n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "#Incorporating langchain for easier integration and embedding document chunks into FAISS vector\n",
    "#Rationale More Efficiency \n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "#Metrics\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from rouge import Rouge \n",
    "from bert_score import score as bert_score\n",
    "from nltk.translate.meteor_score import meteor_score \n",
    "from nltk.tokenize import word_tokenize  #Import for tokenizing\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from rouge_score import rouge_scorer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from transformers import pipeline\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df257c6-9de2-41ab-8936-a3dc51935ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: 62 Business English Negotiation Phrases _ FluentU.pdf with 23 chunks.\n",
      "Processed file: business-english-negotiations-jigsaw-dialogues-and-useful-phrases.pdf with 6 chunks.\n",
      "Processed file: main_negotiations.pdf with 93 chunks.\n",
      "Processed file: Transcript Example.pdf with 9 chunks.\n",
      "Turn 1 (HR Manager):\n",
      "While aligning compensation with market standards is important, our current offer of $126,200 is competitive based on our internal benchmarks and budget constraints. However, I’m open to exploring other forms of recognition. How about a performancebased bonus or additional nonmonetary benefits like professional development opportunities?\n",
      "Extracted Matches: ['$126,200']\n",
      "No keywords matched. Using first extracted match as fallback: $126,200\n",
      "Turn 2 (Employee):\n",
      "These are valuable, but I still believe aligning my salary closer to $145,400 would better reflect my contributions and market standards. Could we consider a phased approach to reach this salary over time? This could balance both our interests and align with the company's budget constraints\n",
      "Extracted Matches: ['$145,400']\n",
      "No keywords matched. Using first extracted match as fallback: $145,400\n",
      "Turn 3 (HR Manager):\n",
      "Let's explore a phased approach towards your desired salary. We can adjust your salary to $140,400 now, with a clear path to $145,400 over the next year, contingent on meeting specific performance milestones. This plan aligns with our budget while recognizing your contributions. Additionally, we can enhance your benefits with professional development opportunities to support your growth. How does this sound?\n",
      "Extracted Matches: ['$140,400', '$145,400']\n",
      "No keywords matched. Using first extracted match as fallback: $140,400\n",
      "Turn 4 (Employee):\n",
      "This shows a commitment to recognizing my contributions. However, to better align with my current needs and market standards, could we consider adjusting the initial offer slightly closer to $145,400, perhaps meeting at $144,000? This would demonstrate a more immediate recognition of my value while still allowing us to work towards the full desired salary over the next year. Additionally, I am open to discussing performancebased bonuses and professional development opportunities as part of this package. How does this sound to you?\n",
      "Extracted Matches: ['$145,400', '$144,000']\n",
      "No keywords matched. Using first extracted match as fallback: $145,400\n",
      "Turn 5 (HR Manager):\n",
      "Meeting at $144,000 is indeed closer to your desired salary and demonstrates our recognition of your contributions. Let's proceed with this adjustment, and we'll work towards the full $145,400 over the next year, contingent on performance milestones. Additionally, I'll ensure we include a performancebased bonus structure and professional development opportunities to further enhance your growth. How does this sound?\n",
      "Extracted Matches: ['$144,000', '$145,400']\n",
      "No keywords matched. Using first extracted match as fallback: $144,000\n",
      "Turn 6 (Employee):\n",
      "That sounds like a promising path forward and shows the company's commitment to recognizing my contributions. However, I'm still feeling a bit of a gap between this offer and the market standards for my role. Would it be possible to consider an initial adjustment closer to $145,400, perhaps meeting at $144,500? This would provide a more immediate reflection of my value while maintaining the phased approach towards the full desired salary. Additionally, Could we also explore options for flexible working arrangements or additional vacation days? These would further enhance my job satisfaction and align with my personal values. How does this sound to you?\n",
      "Extracted Matches: ['$145,400', '$144,500']\n",
      "No keywords matched. Using first extracted match as fallback: $145,400\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 7 (HR Manager):\n",
      "I understand your perspective on aligning with market standards. Let's adjust the initial salary to $144,500 as a reflection of your value. This aligns with our phased approach towards $145,400. Regarding flexible working arrangements, we can offer a hybrid model, allowing you to work remotely two days a week. Additionally, we can provide an extra week of vacation to enhance your worklife balance. These adjustments aim to recognize your contributions and support your personal values. How does this sound to you?\n",
      "Extracted Matches: ['$144,500', '$145,400']\n",
      "No keywords matched. Using first extracted match as fallback: $144,500\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Final HR Manager Turn:\n",
      "If Agreement: I'm thrilled that we've reached an agreement! Your skills and experience are a perfect fit for our team, and I'm confident you'll make a significant impact. Let's finalize the details and get started on this exciting journey together. If No Agreement: I completely understand your decision, and I want to Your skills and experience are impressive, and while it didn't work out this time, I hope we can keep the door open for future opportunities\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Successfully saved conversation with ConversationID 4f72b9de-df84-42d8-a190-7b58b3cc69e2 to negotiation_chats_selfplay_FT.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "Salary change: 14.50079239302694%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.9\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "Salary change: 14.50079239302694%\n",
      "Metrics saved to model_1_metrics_FT.csv for ConversationID 4f72b9de-df84-42d8-a190-7b58b3cc69e2\n",
      "Metrics saved to model_2_metrics_FT.csv for ConversationID 4f72b9de-df84-42d8-a190-7b58b3cc69e2\n",
      "Successfully saved scenario for ConversationID 4f72b9de-df84-42d8-a190-7b58b3cc69e2 to negotiation_scenarios_FT.csv\n",
      "Run 0 Summary:\n",
      "Initial Salary: $126200\n",
      "Desired Salary: $145400.0\n",
      "Final Offer: $144500.0\n",
      "Turn 1 (HR Manager):\n",
      "While your current salary is $128,400, and we recognize your desire for an increase to $135,900, we're currently at our offer of $128,400. However, we're open to finding a middle ground. How about we explore a performancebased bonus that could bring your total compensation closer to what you're aiming for? Alternatively, we could discuss nonmonetary benefits that might enhance your role. What are your thoughts on these options?\n",
      "Extracted Matches: ['$128,400', '$135,900', '$128,400']\n",
      "No keywords matched. Using first extracted match as fallback: $128,400\n",
      "Turn 2 (Employee):\n",
      "While the performancebased bonus is an intriguing idea, I'd love to explore the possibility of a phased raise. Perhaps we could start with an increase to $133,400, which is closer to the highest counteroffer we've discussed, and then revisit the salary in a few months based on my performance. This way, we align our goals and keep the motivation high. What do you think about that approach?\n",
      "Extracted Matches: ['$133,400']\n",
      "No keywords matched. Using first extracted match as fallback: $133,400\n",
      "Turn 3 (HR Manager):\n",
      "It's a thoughtful approach that aligns with both your aspirations and the company's current position. Let's consider this: we can start with an increase to $133,400, as you suggested. This would bring your salary closer to your desired figure. Additionally, we could set up a performance review in six months to assess the possibility of further adjustment based on your contributions. To complement this, we could also explore enhancing your role with nonmonetary benefits, such as professional development opportunities or flexible work arrangements. How does this sound to you?\n",
      "Extracted Matches: ['$133,400']\n",
      "No keywords matched. Using first extracted match as fallback: $133,400\n",
      "Turn 4 (Employee):\n",
      "The idea of a performance review in six months is motivating, and I’m excited about the potential for further adjustments based on my contributions. As for nonmonetary benefits, professional development opportunities really resonate with me. Perhaps we could explore some courses or workshops that align with my role? Flexible work arrangements also sound appealing, especially with the evolving work landscape. Overall, this plan feels like a winwin, aligning my aspirations with the company's goals. What are your thoughts on these suggestions?\n",
      "Turn 5 (HR Manager):\n",
      "I'm glad to hear that the performance review and professional development opportunities align with your aspirations. Let's move forward with the increase to $133,400, as discussed. We'll plan the performance review for six months from now to explore further adjustments based on your contributions. Regarding professional development, we can look into courses or workshops that align with your role and support your growth. As for flexible work arrangements, we can certainly explore options that fit the evolving work landscape. This approach not only aligns with your goals but also strengthens our commitment to your development within the company. How does this plan sound to you?\n",
      "Extracted Matches: ['$133,400']\n",
      "No keywords matched. Using first extracted match as fallback: $133,400\n",
      "Turn 6 (Employee):\n",
      "I'm thrilled about the path we're taking! The increase to $133,400 is a solid step forward, and the performance review in six months adds a layer of motivation. I'm excited about exploring professional development opportunities—perhaps we could look into specific courses that align with my role? As for flexible work arrangements, I'm open to discussing options that fit both our needs. This plan feels like a great alignment of my goals with the company's vision. Let's make it happen!\n",
      "Extracted Matches: ['$133,400']\n",
      "No keywords matched. Using first extracted match as fallback: $133,400\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Final HR Manager Turn:\n",
      "It seems we've reached an agreement on the terms discussed. We're thrilled to have you join our team and are confident that your contributions will be invaluable to our continued success. Your enthusiasm and expertise align perfectly with our goals. Let's move forward together and make great things happen!\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Successfully saved conversation with ConversationID b8be503b-92b1-4141-912a-e052eddebcf2 to negotiation_chats_selfplay_FT.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "Salary change: 3.894080996884735%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.70\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.2\n",
      "GEval (Relevance) Raw Response: 0.30\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "Salary change: 3.894080996884735%\n",
      "Metrics saved to model_1_metrics_FT.csv for ConversationID b8be503b-92b1-4141-912a-e052eddebcf2\n",
      "Metrics saved to model_2_metrics_FT.csv for ConversationID b8be503b-92b1-4141-912a-e052eddebcf2\n",
      "Successfully saved scenario for ConversationID b8be503b-92b1-4141-912a-e052eddebcf2 to negotiation_scenarios_FT.csv\n",
      "Run 1 Summary:\n",
      "Initial Salary: $128400\n",
      "Desired Salary: $135900.0\n",
      "Final Offer: $133400.0\n",
      "Turn 1 (HR Manager):\n",
      "The company has already offered $95,900, which aligns with your current salary. Considering the budget constraints and market standards, a jump to $118,500 seems quite ambitious. However, let's explore some creative solutions. How about a onetime performance bonus to recognize your contributions? Alternatively, we could discuss a phased raise over the next year, contingent on specific performance targets. Nonmonetary benefits like additional vacation days or flexible working arrangements could also be on the table. What are your thoughts?\n",
      "Extracted Matches: ['$95,900', '$118,500']\n",
      "No keywords matched. Using first extracted match as fallback: $95,900\n",
      "Turn 2 (Employee):\n",
      "Both are creative solutions that could work well. How about we consider a phased raise that brings me closer to my desired salary over the next year, with clear performance targets? This way, it aligns with the company's budget constraints while also motivating me to achieve specific goals. Additionally, extra vacation days or flexible working arrangements would be valuable to me. These nonmonetary benefits could enhance my worklife balance and overall job satisfaction. What do you think about this approach?\n",
      "Turn 3 (HR Manager):\n",
      "While Jumping to $118,500 seems like a stretch right now. However, a modest phased raise with clear performance targets could be something we could explore, although it would need to be carefully aligned with our financial planning. As for nonmonetary benefits, while extra vacation days or flexible working arrangements might sound appealing, we need to ensure they align with company policy and don't set a precedent we can't maintain. That said, a onetime performance bonus could be a feasible way to recognize your contributions without overextending our budget. Let's focus on realistic solutions that satisfy both parties\n",
      "Extracted Matches: ['$118,500']\n",
      "No keywords matched. Using first extracted match as fallback: $118,500\n",
      "Turn 4 (Employee):\n",
      "Given the budget constraints, perhaps we could consider a phased raise that starts with a midpoint between my current salary and the desired $118,500. This way, we gradually move towards the target while aligning with financial planning. Regarding nonmonetary benefits, I understand the need for consistency in company policy. However, even a small increase in vacation days or occasional remote work days could significantly enhance my worklife balance. Lastly, a onetime performance bonus sounds like a promising way to recognize my contributions without straining the budget. Could we explore a combination of these options to find a balanced solution that satisfies both parties?\n",
      "Extracted Matches: ['$118,500']\n",
      "No keywords matched. Using first extracted match as fallback: $118,500\n",
      "Turn 5 (HR Manager):\n",
      "Given the current budget constraints and market standards, jumping to $118,500 is not feasible. However, a phased raise starting with a midpoint could be explored, but it would need to be carefully aligned with our financial planning. As for nonmonetary benefits, while extra vacation days or remote work might seem appealing, we must ensure they align with company policy and don't set a precedent we can't maintain. A onetime performance bonus could be a feasible way to recognize your contributions without overextending our budget. Let's focus on realistic solutions that satisfy both parties\n",
      "Extracted Matches: ['$118,500']\n",
      "No keywords matched. Using first extracted match as fallback: $118,500\n",
      "Turn 6 (Employee):\n",
      "I understand the challenges with budget constraints and policy consistency. How about we start with a phased raise that aligns with your financial planning, perhaps moving closer to $118,500 over a set period? This way, we can work towards my desired salary while meeting the company's needs. Additionally, a onetime performance bonus could be a great way to acknowledge my contributions without straining the budget. As for nonmonetary benefits, even a slight increase in vacation days or occasional remote work could make a big difference in my worklife balance. Let's explore a combination of these options to find a balanced solution that works for both of us\n",
      "Extracted Matches: ['$118,500']\n",
      "No keywords matched. Using first extracted match as fallback: $118,500\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 7 (HR Manager):\n",
      "However, given the current financial climate, even a phased raise towards $118,500 seems overly ambitious. We could consider a smaller increase to bridge the gap, but it must be aligned with our strict financial planning. Regarding nonmonetary benefits, while I see the appeal, any deviation from our current policy could set a precedent we're not equipped to handle. A slight increase in vacation days or occasional remote work might be feasible, but it would require careful consideration. A onetime performance bonus sounds like a more realistic option to acknowledge your contributions without straining our budget. Let's explore how we can integrate these elements into a balanced solution that aligns with both your aspirations and our constraints\n",
      "Extracted Matches: ['$118,500']\n",
      "No keywords matched. Using first extracted match as fallback: $118,500\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 8 (Employee):\n",
      "How about we consider a phased raise that begins with a modest increase closer to the midpoint between my current salary and $118,500, gradually working towards the target over time? This approach could align well with financial planning. Additionally, a onetime performance bonus would be a fantastic way to recognize my contributions and motivate continued excellence without impacting the budget significantly. Regarding nonmonetary benefits, perhaps we could explore the possibility of a flexible work arrangement, such as occasional remote work days. This could enhance my worklife balance without setting a difficult precedent. Let's work together to find a balanced solution that meets both our needs\n",
      "Extracted Matches: ['$118,500']\n",
      "No keywords matched. Using first extracted match as fallback: $118,500\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 9 (HR Manager):\n",
      "I understand the desire to move towards your target salary, but given our financial constraints, a phased raise even to a midpoint is stretching it. We might consider a very modest increase, but it’s crucial to remain aligned with our budgetary limits. As for a onetime performance bonus, that’s a possibility, but it would need to reflect our current fiscal reality. Regarding nonmonetary benefits, occasional remote work could be considered, but it must be carefully evaluated to ensure it doesn’t disrupt our operational consistency. Increasing vacation days is unlikely, as it could set a precedent we’re not prepared to handle. Let’s focus on a realistic combination of a modest salary adjustment, a potential bonus, and perhaps limited remote work, keeping both our aspirations and constraints in mind\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 10 (Employee):\n",
      "How about we consider a modest salary increase that reflects a step forward, even if it's not to the midpoint? This could be a gesture towards my desired salary over time. Regarding the performance bonus, perhaps we could link it to specific achievements or milestones, ensuring it aligns with our current fiscal reality. For nonmonetary benefits, occasional remote work seems like a feasible option. We could even start with a trial period to assess its impact on operational consistency. This combination could strike a balance between meeting company constraints and acknowledging my contributions. What are your thoughts?\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Final HR Manager Turn:\n",
      "If Agreement: I'm thrilled to hear that we've reached an agreement! Your enthusiasm and vision for your role are Let's confirm the terms we've agreed upon:. We're excited to have you join our team and contribute to our shared goals. Welcome aboard! If No Agreement: I completely understand your decision, and I want to express our gratitude for considering a role with us. Your insights have been invaluable, and while we won't be moving forward together at this time, the door is always open for future discussions. We wish you all the best in your endeavors and hope our paths cross again\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Successfully saved conversation with ConversationID c9a03cb0-b1f7-4467-8c6a-b5f6cc8da74e to negotiation_chats_selfplay_FT.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "No change in salary: Initial = 95900, Final = 95900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.9\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.9\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.9\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.70\n",
      "GEval (Coherence) Raw Response: 0.70\n",
      "No change in salary: Initial = 95900, Final = 95900\n",
      "Metrics saved to model_1_metrics_FT.csv for ConversationID c9a03cb0-b1f7-4467-8c6a-b5f6cc8da74e\n",
      "Metrics saved to model_2_metrics_FT.csv for ConversationID c9a03cb0-b1f7-4467-8c6a-b5f6cc8da74e\n",
      "Successfully saved scenario for ConversationID c9a03cb0-b1f7-4467-8c6a-b5f6cc8da74e to negotiation_scenarios_FT.csv\n",
      "Run 2 Summary:\n",
      "Initial Salary: $95900\n",
      "Desired Salary: $118500.0\n",
      "Final Offer: $118500.0\n",
      "Turn 1 (Employee):\n",
      "While my desired salary is $113,300, I understand we're currently at $97,200. To bridge this gap, I'm open to creative solutions. How about a phased raise to $113,300 over the next year, starting with an immediate increase to $105,000? Alternatively, a onetime performance bonus could help recognize my contributions while aligning with budget constraints. Nonmonetary benefits like additional vacation days or professional development opportunities could also be valuable. I'm confident we can find a solution that reflects my value to the company\n",
      "Extracted Matches: ['$113,300', '$97,200', '$113,300', '$105,000']\n",
      "No keywords matched. Using first extracted match as fallback: $113,300\n",
      "Turn 2 (HR Manager):\n",
      "We hear your proposal for a phased raise and appreciate your openness to creative solutions. Currently, we can offer an immediate increase to $108,300, which aligns with our budget constraints. Additionally, we could explore a onetime performance bonus or additional vacation days to recognize your contributions. This approach allows us to acknowledge your value while staying within our financial limits. How does this sound to you?\n",
      "Extracted Matches: ['$108,300']\n",
      "No keywords matched. Using first extracted match as fallback: $108,300\n",
      "Turn 3 (Employee):\n",
      "While it's close to my desired salary, I believe we can find a solution that reflects my contributions even more. How about we consider a phased raise to $113,300 over six months? This approach aligns with my longterm goals while respecting the company's budget constraints. Alternatively, a onetime performance bonus could be an excellent way to bridge the gap and recognize my achievements. I'm also open to discussing additional vacation days or professional development opportunities, which would enhance my engagement and productivity. Let's explore these options to find a mutually beneficial agreement\n",
      "Extracted Matches: ['$113,300']\n",
      "No keywords matched. Using first extracted match as fallback: $113,300\n",
      "Turn 4 (HR Manager):\n",
      "We appreciate your commitment to finding a solution that reflects your value. While our current offer of $108,300 aligns with our budget constraints, we're open to creative solutions to acknowledge your contributions further. Instead of a phased raise, which might stretch our budget thin, we can offer a onetime performance bonus that brings you closer to your desired salary. This allows us to recognize your achievements while staying within our financial limits. Additionally, we're open to discussing nonmonetary benefits like additional vacation days or professional development opportunities. These could enhance your engagement and align with your longterm goals. Let's explore these options to find a mutually beneficial agreement\n",
      "Extracted Matches: ['$108,300']\n",
      "No keywords matched. Using first extracted match as fallback: $108,300\n",
      "Turn 5 (Employee):\n",
      "However, to bridge the gap toward my desired salary, I propose a onetime performance bonus of $5,000. This bonus would bring us closer to my goal while respecting the company's budget constraints. Additionally, I'd like to discuss the possibility of an extra week of vacation, which would enhance my worklife balance and productivity. These adjustments would reflect my contributions and align with the company's financial considerations. How does this sound to you?\n",
      "Extracted Matches: ['$5,000']\n",
      "No keywords matched. Using first extracted match as fallback: $5,000\n",
      "Turn 6 (HR Manager):\n",
      "We appreciate your proposal of a $5,000 performance bonus and an extra week of vacation. However, given our current budget constraints, we're unable to accommodate both requests fully. We can offer a onetime performance bonus of $3,000. This bonus, combined with our current salary offer of $108,300, brings us closer to recognizing your contributions while respecting our financial limits. Additionally, we can offer an additional three days of vacation, which aligns with our commitment to support your worklife balance. These adjustments reflect your value to the company and maintain our financial integrity. How does this revised offer align with your goals?\n",
      "Extracted Matches: ['$5,000', '$3,000', '$108,300']\n",
      "No keywords matched. Using first extracted match as fallback: $5,000\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 7 (Employee):\n",
      "However, I'm still aiming to achieve a compensation package that better reflects my contributions. How about we meet halfway with a $4,000 performance bonus? This would bring us closer to my desired salary while staying within the company's budget constraints. Additionally, I'm willing to accept the three extra vacation days as a gesture of goodwill. These adjustments would not only recognize my achievements but also support my longterm engagement with the company. How does this sound to you?\n",
      "Extracted Matches: ['$4,000']\n",
      "No keywords matched. Using first extracted match as fallback: $4,000\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 8 (HR Manager):\n",
      "We understand your desire for a compensation package that reflects your contributions. While we appreciate your proposal for a $4,000 bonus, our budget constraints only allow us to offer a $3,000 bonus at this time. This, along with the three extra vacation days, demonstrates our commitment to recognizing your achievements within our financial limits. We believe this offer balances your goals with our current constraints. Let's focus on moving forward with this package, which reflects both your value and our commitment to supporting your longterm engagement with the company\n",
      "Extracted Matches: ['$4,000', '$3,000']\n",
      "No keywords matched. Using first extracted match as fallback: $4,000\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 9 (Employee):\n",
      "However, I'm keen on a package that more closely aligns with my contributions. How about we consider a phased approach? We could start with the current offer and review my salary in six months based on performance metrics we agree on. This allows us to align my compensation with my achievements while considering the company's budget constraints. This approach reflects my commitment to the company and ensures my contributions are recognized. How does this sound to you?\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 10 (HR Manager):\n",
      "However, our current financial constraints make it challenging to commit to a salary review in six months. Here's what I propose: we maintain the current offer of $108,300 with a $3,000 performance bonus and three additional vacation days. This package acknowledges your achievements and supports your worklife balance while keeping within our budget. Let's focus on moving forward with this offer, which reflects both your value to the company and our commitment to supporting your longterm engagement\n",
      "Extracted Matches: ['$108,300', '$3,000']\n",
      "No keywords matched. Using first extracted match as fallback: $108,300\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Final HR Manager Turn:\n",
      "Conclusion If Agreement: I'm thrilled we've reached an agreement! Your skills and experience are a perfect fit for our team. We're excited about the contributions you'll bring and look forward to your journey with us. Let's make this a great experience together! If No Agreement: I understand and respect your decision. We're grateful for the time and effort you've invested in our discussions. Should circumstances change, we'd be delighted to explore future opportunities with you\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Successfully saved conversation with ConversationID ce9c547f-a3a9-4353-b8f1-fb2b94f3ec93 to negotiation_chats_selfplay_FT.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "No change in salary: Initial = 97200, Final = 97200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.9\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.8\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.9\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.9\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "No change in salary: Initial = 97200, Final = 97200\n",
      "Metrics saved to model_1_metrics_FT.csv for ConversationID ce9c547f-a3a9-4353-b8f1-fb2b94f3ec93\n",
      "Metrics saved to model_2_metrics_FT.csv for ConversationID ce9c547f-a3a9-4353-b8f1-fb2b94f3ec93\n",
      "Successfully saved scenario for ConversationID ce9c547f-a3a9-4353-b8f1-fb2b94f3ec93 to negotiation_scenarios_FT.csv\n",
      "Run 3 Summary:\n",
      "Initial Salary: $97200\n",
      "Desired Salary: $113300.0\n",
      "Final Offer: $108300.0\n",
      "Turn 1 (HR Manager):\n",
      "We appreciate your dedication and the contributions you’ve made to the company. While we value your request to align your salary more closely with the market standards, we are currently at the $62,700 mark. Given this situation, I'd like to explore some creative solutions that could bridge the gap between your current compensation and your desired salary of $74,900. One possibility is to consider a performancebased bonus that recognizes your achievements and contributions. This could provide you with additional financial recognition while we continue to assess our salary structure. Alternatively, we could discuss a phased raise approach, where we implement incremental increases over time as we work towards aligning closer with your desired salary. Additionally, we could explore enhancing your benefits package with nonmonetary perks such as flexible working hours, additional vacation days, or professional development opportunities. These could add significant value to your overall compensation. Let's discuss which of these options might resonate with you, or if there are other ideas you might have. Our goal is to find\n",
      "Extracted Matches: ['$62,700', '$74,900']\n",
      "No keywords matched. Using first extracted match as fallback: $62,700\n",
      "Turn 2 (Employee):\n",
      "While the performancebased bonus is intriguing, my focus remains on achieving a salary that A phased raise approach could be a step in the right direction, but I’d like to see a more aggressive timeline to reach closer to my desired $74,900. Additionally, enhancing the benefits package with flexible working hours or additional vacation days could certainly add value. However, I believe a more immediate adjustment in my base salary would better align with my career goals and the value I bring to the company. How can we make that happen?\n",
      "Extracted Matches: ['$74,900']\n",
      "No keywords matched. Using first extracted match as fallback: $74,900\n",
      "Turn 3 (HR Manager):\n",
      "While we recognize the importance of this alignment, our current offer of $69,900 reflects our commitment to moving in that direction, even as we navigate budget constraints. Given these constraints, I’d like to explore some creative solutions that could bridge the gap between our current offer and your desired salary of $74,900. One possibility is to consider a performancebased bonus that recognizes your achievements and contributions. This could provide you with additional financial recognition while we continue to assess our salary structure. Alternatively, we could discuss a phased raise approach, where we implement incremental increases over time as we work towards aligning closer with your desired salary. Additionally, we could explore enhancing your benefits package with nonmonetary perks such as flexible working hours, additional vacation days, or professional development opportunities. These could add significant value to your overall compensation. Our goal is to find a solution that reflects your value to the company while being mindful of\n",
      "Extracted Matches: ['$69,900', '$74,900']\n",
      "No keywords matched. Using first extracted match as fallback: $69,900\n",
      "Turn 4 (Employee):\n",
      "My contributions have consistently driven results, and a salary closer to $74,900 would reflect that value. A phased raise with a clear, aggressive timeline could be a viable path. Additionally, enhancing the benefits package with flexible working hours and additional vacation days would add immediate value. How can we structure this to meet both our goals effectively?\n",
      "Extracted Matches: ['$74,900']\n",
      "No keywords matched. Using first extracted match as fallback: $74,900\n",
      "Turn 5 (HR Manager):\n",
      "I understand your focus on achieving a salary that reflects your contributions and aligns with your career goals. While our current offer of $69,900 is a step in that direction, I recognize the importance of bridging the gap to your desired $74,900. To address this, we could consider a phased raise approach with a more aggressive timeline. This could involve an initial salary increase to $69,900, followed by a structured plan to reach closer to your target within a specified timeframe. This approach would allow us to align more closely with your goals while managing our budget constraints. Additionally, enhancing your benefits package with flexible working hours and additional vacation days could provide immediate value. These nonmonetary perks would support your worklife balance and contribute to your overall satisfaction. Let's discuss how we can structure this plan to effectively meet both our goals. Your contributions are highly valued, and we are committed to finding a solution that reflects that\n",
      "Extracted Matches: ['$69,900', '$74,900', '$69,900']\n",
      "No keywords matched. Using first extracted match as fallback: $69,900\n",
      "Turn 6 (Employee):\n",
      "To move forward, I propose an immediate increase to $69,900, followed by a clear, aggressive plan to reach $74,900 within the next year. This phased approach aligns with my career aspirations and demonstrates the company’s commitment to valuing my contributions. Additionally, enhancing the benefits package with flexible working hours and additional vacation days would provide immediate value and support my worklife balance. Let's discuss how we can structure this plan to effectively meet both our goals\n",
      "Extracted Matches: ['$69,900', '$74,900']\n",
      "No keywords matched. Using first extracted match as fallback: $69,900\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Final HR Manager Turn:\n",
      "Of course! Could you let me know if an agreement was reached?\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Successfully saved conversation with ConversationID 88a92cc5-116d-45a2-9a5d-8232c0b31bbc to negotiation_chats_selfplay_FT.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.0\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.9\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.9\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "Salary change: 11.483253588516746%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.2\n",
      "GEval (Relevance) Raw Response: 0.20\n",
      "GEval (Coherence) Raw Response: 0.90\n",
      "Salary change: 11.483253588516746%\n",
      "Metrics saved to model_1_metrics_FT.csv for ConversationID 88a92cc5-116d-45a2-9a5d-8232c0b31bbc\n",
      "Metrics saved to model_2_metrics_FT.csv for ConversationID 88a92cc5-116d-45a2-9a5d-8232c0b31bbc\n",
      "Successfully saved scenario for ConversationID 88a92cc5-116d-45a2-9a5d-8232c0b31bbc to negotiation_scenarios_FT.csv\n",
      "Run 4 Summary:\n",
      "Initial Salary: $62700\n",
      "Desired Salary: $74900.0\n",
      "Final Offer: $69900.0\n",
      "Turn 1 (Employee):\n",
      "To bridge this gap, how about a phased raise? We could start with $165,000 and plan to reach my desired salary over time. Alternatively, a performancebased bonus or additional stock options could be a creative way to align our interests. What are your thoughts?\n",
      "Extracted Matches: ['$165,000']\n",
      "No keywords matched. Using first extracted match as fallback: $165,000\n",
      "Turn 2 (HR Manager):\n",
      "It seems a bit speculative given our current budget constraints. While a performancebased bonus could be an option, I’m wary of overcommitting. Stock options might align interests, but they also add complexity and risk. We could consider a modest bonus tied to specific performance metrics as a more immediate and measurable compromise. How does that sound to you?\n",
      "Turn 3 (Employee):\n",
      "I understand the need for caution, but let's look at this creatively. How about we start with the $165,000, as a commitment from both sides? Alongside, we could introduce a modest performancebased bonus, tied to specific metrics. This way, we align our goals and keep things measurable. Additionally, why not explore nonmonetary benefits like professional development opportunities? These could add value without straining the budget. What do you think?\n",
      "Extracted Matches: ['$165,000']\n",
      "No keywords matched. Using first extracted match as fallback: $165,000\n",
      "Turn 4 (HR Manager):\n",
      "I understand your perspective, but starting with $165,000 seems a stretch given our budget constraints. A modest performancebased bonus is feasible, but let's be realistic about its potential impact. Regarding nonmonetary benefits, while professional development is appealing, it's important to ensure it aligns with our strategic goals and doesn't divert resources. How about we explore a smaller increase to $160,000, combined with a performance bonus tied to specific metrics? This approach maintains alignment without overextending\n",
      "Extracted Matches: ['$165,000', '$160,000']\n",
      "No keywords matched. Using first extracted match as fallback: $165,000\n",
      "Turn 5 (Employee):\n",
      "How about we meet at $170,000? This shows a stronger commitment to my role and aligns with our shared goals. We can still include the performance bonus and explore professional development opportunities that directly support our strategic objectives. This way, we maintain budget alignment while investing in growth. How does that sound?\n",
      "Extracted Matches: ['$170,000']\n",
      "No keywords matched. Using first extracted match as fallback: $170,000\n",
      "Turn 6 (HR Manager):\n",
      "I see where you're coming from with the $170,000 proposal, but it's quite a leap from our current constraints. While How about this: we stick with the $165,000 but introduce a structured performancebased bonus. This way, you can earn more based on specific achievements, aligning with our goals without overcommitting. As for professional development, we can certainly explore options that directly support our strategic objectives, ensuring they add value without straining resources. Let's focus on a solution that balances ambition with realism. What do you think?\n",
      "Extracted Matches: ['$170,000', '$165,000']\n",
      "No keywords matched. Using first extracted match as fallback: $170,000\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 7 (Employee):\n",
      "I understand your position, but let's revisit the numbers. The $170,000 isn't just a figure; it's a reflection of my commitment and the value I bring. It's not a leap; it's a logical step forward. Now, regarding your structured performance bonus, I'm open to it, but it should complement a base salary that How about we consider a phased approach? We start at $170,000 with clearly defined performance milestones that could lead to further increases. For professional development, let's ensure the opportunities align with both our goals. This isn't about diverting resources; it's about investing in growth that benefits us both. Let's aim for a solution that recognizes my value and aligns with our shared ambitions. What do you think?\n",
      "Extracted Matches: ['$170,000', '$170,000']\n",
      "No keywords matched. Using first extracted match as fallback: $170,000\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 8 (HR Manager):\n",
      "I understand the importance you place on the $170,000 figure, but let's be realistic about our constraints. Jumping to $170,000 isn't just a matter of acknowledging your value; it's a significant stretch for us. A phased approach, as you suggested, could be a middle ground, but we need to ensure it's sustainable. How about this: we start at $165,000 with a clear roadmap for performancebased increases. This way, we align your growth with our capabilities. As for professional development, we can focus on initiatives that are directly beneficial without overextending. This isn't about limiting your potential; it's about finding a path that respects both your ambitions and our realities. What do you think?\n",
      "Extracted Matches: ['$170,000', '$170,000', '$165,000']\n",
      "No keywords matched. Using first extracted match as fallback: $170,000\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 9 (Employee):\n",
      "I understand the constraints, but let's aim for $170,000. It's not just a number; it's a recognition of my commitment and potential. We can introduce a performancebased bonus structure to align with our shared goals, which would allow me to earn more as I meet specific milestones. This way, we balance ambition and realism. Additionally, let's consider professional development opportunities that directly support our strategic objectives. By investing in growth that aligns with our goals, we ensure mutual benefit without straining resources. Let's aim for a solution that acknowledges my value and aligns with our shared ambitions. What do you think?\n",
      "Extracted Matches: ['$170,000']\n",
      "No keywords matched. Using first extracted match as fallback: $170,000\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Turn 10 (HR Manager):\n",
      "I hear your point about $170,000 being a recognition of your commitment, but let's be candid—it's a stretch. Jumping to that number isn't just a matter of acknowledging your value; it's a significant leap for us. Now, regarding the performancebased bonus, it's a decent idea, but let's not kid ourselves—bonuses aren't guaranteed income. They depend on factors that might be beyond your control. As for professional development, while it's important, we need to be strategic. We can't just throw resources at it without a clear return on investment. Here's a thought: How about we stick with $165,000 and introduce a modest signon bonus? This way, you get an immediate boost, and we keep things sustainable. Let's focus on a solution that respects both your ambitions and our realities\n",
      "Extracted Matches: ['$170,000', '$165,000']\n",
      "No keywords matched. Using first extracted match as fallback: $170,000\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Final HR Manager Turn:\n",
      "After careful consideration and discussions regarding the offer, we have reached a decision. We are thrilled to have you join our team. Your enthusiasm and expertise align perfectly with our vision, and we are confident that your contributions will be invaluable. The terms we've agreed upon reflect our mutual commitment to a successful partnership. If you have any questions or need further assistance, please feel free to reach out. We look forward to welcoming you aboard and embarking on this exciting journey together. Warm regards, HR Manager\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Successfully saved conversation with ConversationID 8f5a6dd5-a99a-4a77-bc52-85468b84f763 to negotiation_chats_selfplay_FT.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.8\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "No change in salary: Initial = 156300, Final = 156300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.7\n",
      "GEval (Relevance) Raw Response: 0.80\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.8\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.7\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "No change in salary: Initial = 156300, Final = 156300\n",
      "Metrics saved to model_1_metrics_FT.csv for ConversationID 8f5a6dd5-a99a-4a77-bc52-85468b84f763\n",
      "Metrics saved to model_2_metrics_FT.csv for ConversationID 8f5a6dd5-a99a-4a77-bc52-85468b84f763\n",
      "Successfully saved scenario for ConversationID 8f5a6dd5-a99a-4a77-bc52-85468b84f763 to negotiation_scenarios_FT.csv\n",
      "Run 5 Summary:\n",
      "Initial Salary: $156300\n",
      "Desired Salary: $187000.0\n",
      "Final Offer: $170000.0\n",
      "Turn 1 (HR Manager):\n",
      "We value your contributions and want to ensure you're fairly compensated. While our current offer is $118,400, I understand you're looking for $139,800. Let's explore some creative solutions. How about we discuss a performancebased bonus structure that could bring you closer to your desired salary? Additionally, we could look into nonmonetary benefits like professional development opportunities or increased flexibility that might align with your goals. What are your thoughts on these options?\n",
      "Extracted Matches: ['$118,400', '$139,800']\n",
      "No keywords matched. Using first extracted match as fallback: $118,400\n",
      "Turn 2 (Employee):\n",
      "A performancebased bonus structure could be an exciting way to align my compensation with my contributions. How about we consider a phased salary increase that starts at $123,400 and review my progress towards $139,800 over the next year? This approach, combined with a bonus structure, could provide a clear path forward. Additionally, I'm intrigued by the idea of professional development opportunities. Access to industryleading courses or conferences could enhance my skills and benefit the company. Increased flexibility is also appealing, as it could boost my productivity and worklife balance. How do these ideas resonate with you?\n",
      "Extracted Matches: ['$123,400', '$139,800']\n",
      "No keywords matched. Using first extracted match as fallback: $123,400\n",
      "Turn 3 (HR Manager):\n",
      "Your idea of a phased salary increase starting at $123,400, combined with a performancebased bonus structure, is a promising approach. This could indeed align your compensation with your contributions and provide a clear path toward your desired salary. In terms of professional development, we can certainly support access to industryleading courses or conferences. This investment in your growth can benefit both you and the company. Regarding increased flexibility, we can explore options that enhance your worklife balance and productivity. Perhaps we can discuss specific arrangements that would work best for you. How does this sound as a way forward?\n",
      "Extracted Matches: ['$123,400']\n",
      "No keywords matched. Using first extracted match as fallback: $123,400\n",
      "Turn 4 (Employee):\n",
      "I'm excited about the direction this conversation is taking. The phased salary increase starting at $123,400, combined with a performancebased bonus structure, really aligns with my goals. To add a creative twist, what if we explore a bonus tied to specific project milestones or innovations I could bring to the table? This could provide immediate rewards for impactful contributions. For professional development, how about a mentorship program or a leadership workshop? These could further enhance my skills while aligning with the company's growth. As for flexibility, perhaps a hybrid work model could be a winwin, boosting my productivity and maintaining team collaboration. How do these ideas resonate with you?\n",
      "Extracted Matches: ['$123,400']\n",
      "No keywords matched. Using first extracted match as fallback: $123,400\n",
      "Turn 5 (HR Manager):\n",
      "Tying a bonus to specific project milestones or innovations is a fantastic way to align your contributions with immediate rewards, and I’m excited to explore this with you. Regarding professional development, a mentorship program or leadership workshop aligns perfectly with our goals, and I believe it could be mutually beneficial. Let’s look into options that could enhance your skills and support your growth within the company. As for flexibility, a hybrid work model sounds like a great way to boost productivity while maintaining team collaboration. We can discuss a structure that suits both your needs and the company’s objectives. How do these ideas sound to you?\n",
      "Turn 6 (Employee):\n",
      "I'm thrilled by the potential of tying bonuses to specific project milestones or innovations. This approach not only rewards impactful contributions but also fuels my drive to think creatively and deliver tangible results. For professional development, exploring a mentorship program or leadership workshop is inspiring. It aligns perfectly with my aspirations and the company's growth trajectory. Let's delve into options that can enhance both my skills and our collective success. Regarding the hybrid work model, I envision it as a catalyst for boosting productivity while maintaining team synergy. We could tailor a structure that balances flexibility with collaboration, ensuring we meet both my needs and the company's objectives. Additionally, what if we consider a phased salary increase that aligns with key achievements? This could provide a clear path to my desired salary while allowing us to celebrate milestones along the way. How do these ideas resonate with you?\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Final HR Manager Turn:\n",
      "If Agreement: I'm thrilled that we've reached an agreement! We're excited about the contributions you'll bring to our team. Let's confirm the terms we've discussed:. Your future here is promising, and we're eager to support your growth and success. If No Agreement: I understand your decision, and I want to express our gratitude for considering this opportunity with us. While we won't be moving forward together at this time, we Please know that the door remains open for future discussions, and we wish you all the best in your endeavors\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Successfully saved conversation with ConversationID f5971208-da9c-43c7-8377-dfb8722309a9 to negotiation_chats_selfplay_FT.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: Relevance: 1.00\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.90\n",
      "No change in salary: Initial = 118400, Final = 118400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.70\n",
      "GEval (Coherence) Raw Response: 0.70\n",
      "No change in salary: Initial = 118400, Final = 118400\n",
      "Metrics saved to model_1_metrics_FT.csv for ConversationID f5971208-da9c-43c7-8377-dfb8722309a9\n",
      "Metrics saved to model_2_metrics_FT.csv for ConversationID f5971208-da9c-43c7-8377-dfb8722309a9\n",
      "Successfully saved scenario for ConversationID f5971208-da9c-43c7-8377-dfb8722309a9 to negotiation_scenarios_FT.csv\n",
      "Run 6 Summary:\n",
      "Initial Salary: $118400\n",
      "Desired Salary: $139800.0\n",
      "Final Offer: $123400.0\n",
      "Turn 1 (HR Manager):\n",
      "We appreciate your commitment and contributions to the company. While our current offer is $104,900, we recognize your desire for alignment with market standards. Given our budget constraints, we can explore creative solutions. How about considering a performancebased bonus or phased salary raise? Additionally, we can discuss enhancing nonmonetary benefits like professional development opportunities. Let's find a way to acknowledge your contributions while aligning with our financial framework\n",
      "Extracted Matches: ['$104,900']\n",
      "No keywords matched. Using first extracted match as fallback: $104,900\n",
      "Turn 2 (Employee):\n",
      "Given the budget constraints, how about considering a phased salary raise that brings me closer to my desired salary over the next year? This could be coupled with a performancebased bonus to acknowledge my contributions. Additionally, enhancing professional development opportunities would be valuable for my growth and align with the company's longterm goals. How does this sound?\n",
      "Turn 3 (HR Manager):\n",
      "We appreciate your flexibility and your contributions to the company. Given our budget constraints, a phased salary raise over the next year, coupled with a performancebased bonus, aligns well with our financial framework. This approach allows us to gradually move towards your desired salary while recognizing your achievements. Additionally, we are committed to enhancing your professional development opportunities, which will support your growth and align with our longterm goals. Let's work together to implement these solutions effectively\n",
      "Turn 4 (Employee):\n",
      "To further align with our goals, how about setting clear milestones for these adjustments? This way, we can track progress and ensure the raise reflects my growing contributions. Additionally, while I value professional development, perhaps we could also explore opportunities for leadership training. This would not only enhance my skills but also prepare me for future roles within the company. How does this sound?\n",
      "Turn 5 (HR Manager):\n",
      "We appreciate your proactive approach and focus on aligning with our goals. Setting clear milestones for the phased salary raise is an excellent idea, ensuring transparency and tracking progress effectively. We'll work with you to define these milestones, reflecting your growing contributions. Regarding leadership training, we see this as a valuable investment in both your personal growth and the company's future. We can explore tailored leadership programs that align with your career aspirations and our organizational needs. Additionally, to further recognize your contributions, we can offer a performancebased bonus structure. This will provide immediate recognition for your achievements while we work towards the phased salary adjustment. Let's collaborate to implement these solutions, ensuring they align with both your growth and our financial framework\n",
      "Turn 6 (Employee):\n",
      "I'm pleased with the focus on leadership training and the structured approach to the phased salary raise. To further align our interests, how about incorporating a mentorship component into the leadership program? This could provide immediate value and prepare me for future roles. Additionally, while we work towards the phased salary adjustment, perhaps we could explore a onetime performance bonus to acknowledge my current contributions. How does this sound?\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Final HR Manager Turn:\n",
      "Agreement Reached: I'm thrilled that we've reached an agreement today! Your enthusiasm and vision align perfectly with our goals at. We're excited about the contributions you'll bring to our team and are confident that this will be a rewarding journey for both you and the company. Let's move forward with the onboarding process and get you started on this exciting new chapter! No Agreement Reached: I understand your decision, and I want to express my gratitude for the time and thought you've invested in these discussions. Your insights have been valuable, and while we're not moving forward together at this moment, I believe there's always potential for future collaboration. Please know that the door remains open, and I hope our paths cross again\n",
      "Evaluation Bot Outcome: No Agreement\n",
      "Successfully saved conversation with ConversationID 5c2ff321-fc00-4337-b498-af07bdb8c2d5 to negotiation_chats_selfplay_FT.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.0\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "No change in salary: Initial = 104900, Final = 104900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.2\n",
      "GEval (Relevance) Raw Response: 0.60\n",
      "GEval (Coherence) Raw Response: 0.90\n",
      "No change in salary: Initial = 104900, Final = 104900\n",
      "Metrics saved to model_1_metrics_FT.csv for ConversationID 5c2ff321-fc00-4337-b498-af07bdb8c2d5\n",
      "Metrics saved to model_2_metrics_FT.csv for ConversationID 5c2ff321-fc00-4337-b498-af07bdb8c2d5\n",
      "Successfully saved scenario for ConversationID 5c2ff321-fc00-4337-b498-af07bdb8c2d5 to negotiation_scenarios_FT.csv\n",
      "Run 7 Summary:\n",
      "Initial Salary: $104900\n",
      "Desired Salary: $126400.0\n",
      "Final Offer: $104900\n",
      "Turn 1 (Employee):\n",
      "I understand our current offer is $66,000, and I'm hoping we can find a path toward my desired salary of $77,100. Given our current difference, perhaps we could explore a phased approach to reach this target. For instance, an immediate adjustment to $70,000, with a review in six months based on performance. Alternatively, we could consider a onetime performance bonus or additional nonmonetary benefits, such as extra vacation days or professional development opportunities, to bridge the gap. I believe these options could align our interests and ensure we move forward positively\n",
      "Extracted Matches: ['$66,000', '$77,100', '$70,000']\n",
      "No keywords matched. Using first extracted match as fallback: $66,000\n",
      "Turn 2 (HR Manager):\n",
      "Given our current position, I propose we consider a performance bonus to recognize your contributions immediately. This could be accompanied by a phased salary adjustment plan, where we aim to reach closer to your desired salary over time, contingent on performance metrics. Additionally, we could explore enhancing your benefits package with extra vacation days or professional development opportunities. This approach allows us to align more closely with your expectations while maintaining our current budgetary constraints. How does this sound to you?\n",
      "Turn 3 (Employee):\n",
      "The idea of a performance bonus alongside a phased salary adjustment is certainly a step in the right direction. I believe it could be motivating and align our goals effectively. However, to ensure we are moving toward my desired salary of $77,100, I propose we establish clear performance metrics that would trigger the salary adjustments. This way, we both have a transparent path forward. Additionally, while the extra vacation days and professional development opportunities are appealing, I wonder if there's room to discuss a more immediate adjustment to $70,000, as it would bring us closer to my goal and provide a stronger financial foundation as we work toward the full target. What are your thoughts on incorporating these elements into our plan?\n",
      "Extracted Matches: ['$77,100', '$70,000']\n",
      "No keywords matched. Using first extracted match as fallback: $77,100\n",
      "Turn 4 (HR Manager):\n",
      "This aligns well with our goal of a transparent and motivating path forward. Given your desire for an immediate adjustment to $70,000, I propose we implement this increase, contingent on meeting specific performance goals within the next six months. This would provide a solid foundation as we work toward your target salary of $77,100. Additionally, we could enhance your benefits package with extra vacation days and professional development opportunities, which would further support your growth and satisfaction. How does this proposal resonate with you?\n",
      "Extracted Matches: ['$70,000', '$77,100']\n",
      "No keywords matched. Using first extracted match as fallback: $70,000\n",
      "Turn 5 (Employee):\n",
      "Your proposal to move to $70,000 with performancebased adjustments over six months is indeed a compelling step. However, considering the difference between the current offer of $72,100 and my desired salary of $77,100, I wonder if there's room to adjust the immediate salary to $72,000. This would bring us even closer to my target and provide a more substantial foundation as I strive to meet the performance goals. Additionally, perhaps we could explore a onetime performance bonus tied to these metrics, adding an extra layer of motivation. How does this sound to you?\n",
      "Extracted Matches: ['$70,000', '$72,100', '$77,100', '$72,000']\n",
      "No keywords matched. Using first extracted match as fallback: $70,000\n",
      "Turn 6 (HR Manager):\n",
      "Your suggestion to adjust the immediate salary to $72,000 is indeed closer to your target and aligns well with our mutual goal of motivating progress through performance metrics. Here's a proposal that might resonate with both of us: 1. Immediate Salary Adjustment: We can move your salary to $72,000 as you suggested. This acknowledges your contributions and aligns with your goals. 2. PerformanceBased Bonus: To further incentivize meeting the performance goals, let's introduce a onetime bonus upon achieving these metrics within the next six months. This adds an exciting layer of motivation. 3. Expanded Benefits: We can enhance your benefits package with additional vacation days and professional development opportunities. This supports your growth and aligns with our commitment to your longterm success. How does this comprehensive approach sound to you?\n",
      "Extracted Matches: ['$72,000', '$72,000']\n",
      "No keywords matched. Using first extracted match as fallback: $72,000\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Final HR Manager Turn:\n",
      "It seems we've reached an agreement. I'm thrilled about the path ahead and confident in the contributions you'll bring to our team. Let's move forward together and make great things happen! If there's anything else you'd like to discuss or if you have any questions, feel free to reach out\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Successfully saved conversation with ConversationID 09d6cc14-ea06-4aad-aafc-9357dfb6a22c to negotiation_chats_selfplay_FT.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.7\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "Salary change: 9.242424242424242%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "Salary change: 9.242424242424242%\n",
      "Metrics saved to model_1_metrics_FT.csv for ConversationID 09d6cc14-ea06-4aad-aafc-9357dfb6a22c\n",
      "Metrics saved to model_2_metrics_FT.csv for ConversationID 09d6cc14-ea06-4aad-aafc-9357dfb6a22c\n",
      "Successfully saved scenario for ConversationID 09d6cc14-ea06-4aad-aafc-9357dfb6a22c to negotiation_scenarios_FT.csv\n",
      "Run 8 Summary:\n",
      "Initial Salary: $66000\n",
      "Desired Salary: $77100.0\n",
      "Final Offer: $72100.0\n",
      "Turn 1 (Employee):\n",
      "Given my contributions and the current market trends, I believe a salary closer to $142,000 would better reflect my value to the company. However, I'm open to creative solutions. Perhaps we could consider a phased raise, starting with an increase to $130,000, with a performance review in six months to discuss further adjustments. Alternatively, a onetime bonus could bridge the gap while we work towards my desired salary. I'm confident we can find a solution that acknowledges my contributions and aligns with the company's goals\n",
      "Extracted Matches: ['$142,000', '$130,000']\n",
      "No keywords matched. Using first extracted match as fallback: $142,000\n",
      "Turn 2 (HR Manager):\n",
      "Your suggestion of a phased raise with a performance review aligns well with our focus on growth and development. Let's consider starting with an increase to $130,000, as you proposed, with a performance review in six months. This approach allows us to acknowledge your current contributions and align with our company's goals. Additionally, to bridge the gap towards your desired salary, we could explore a onetime bonus or even nonmonetary benefits that align with your professional goals. This could include professional development opportunities or enhanced health and wellness benefits. Let's find a solution that recognizes your contributions and supports both your ambitions and the company's objectives. What are your thoughts on this approach?\n",
      "Extracted Matches: ['$130,000']\n",
      "No keywords matched. Using first extracted match as fallback: $130,000\n",
      "Turn 3 (Employee):\n",
      "Starting at $130,000 with a performance review in six months aligns well with my career goals and the company's growth focus. To bridge the gap to my desired salary of $142,000, I suggest a onetime bonus. This would acknowledge my current contributions while we work towards the raise. Additionally, I'm open to exploring nonmonetary benefits like professional development opportunities, which would enhance my skills and align with the company's objectives. Let's find a solution that recognizes my contributions and supports both my ambitions and the company's goals. What are your thoughts on this approach?\n",
      "Extracted Matches: ['$130,000', '$142,000']\n",
      "No keywords matched. Using first extracted match as fallback: $130,000\n",
      "Turn 4 (HR Manager):\n",
      "Your proposal to start at $130,000 with a performance review in six months is a strategic move that aligns with both your career goals and our company's growth focus. To bridge the gap to your desired salary of $142,000, I see the onetime bonus as a viable option to acknowledge your current contributions. Additionally, let's explore nonmonetary benefits like professional development opportunities. These could include leadership training or courses that enhance your skills, supporting both your ambitions and the company's objectives. How does this comprehensive approach resonate with you?\n",
      "Extracted Matches: ['$130,000', '$142,000']\n",
      "No keywords matched. Using first extracted match as fallback: $130,000\n",
      "Turn 5 (Employee):\n",
      "Your comprehensive approach is wellaligned with my goals. Starting at $130,000 with a performance review in six months is a strategic step forward. To bridge the gap to $142,000, a onetime bonus would be ideal. Nonmonetary benefits like leadership training also appeal to me, as they support both my growth and the company's objectives. Let's solidify this plan and move forward together\n",
      "Extracted Matches: ['$130,000', '$142,000']\n",
      "No keywords matched. Using first extracted match as fallback: $130,000\n",
      "Turn 6 (HR Manager):\n",
      "Starting at $130,000 with a performance review in six months is indeed a promising path forward. To bridge the gap to your desired $142,000, we can offer a onetime bonus, which acknowledges your current contributions. Additionally, let's enhance your professional growth with leadership training opportunities. This approach not only supports your development but also aligns with our company's objectives. Let's solidify this plan and move forward together. How does this sound to you?\n",
      "Extracted Matches: ['$130,000', '$142,000']\n",
      "No keywords matched. Using first extracted match as fallback: $130,000\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Final HR Manager Turn:\n",
      "Absolutely, let's conclude the negotiation: Agreement Reached: I'm thrilled that we've reached an agreement! We're genuinely excited about the contributions you'll bring to our team. Let's move forward with the terms we've discussed. Welcome aboard! No Agreement Reached: I understand your decision, and I want to express our gratitude for considering us. Your insights have been invaluable. Please know that the door is always open for future discussions. Wishing you all the best in your endeavors!\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Successfully saved conversation with ConversationID b21048bd-641c-41f0-ab48-c903bfd82e7b to negotiation_chats_selfplay_FT.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "Salary change: 13.316790736145576%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.0\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "Salary change: 13.316790736145576%\n",
      "Metrics saved to model_1_metrics_FT.csv for ConversationID b21048bd-641c-41f0-ab48-c903bfd82e7b\n",
      "Metrics saved to model_2_metrics_FT.csv for ConversationID b21048bd-641c-41f0-ab48-c903bfd82e7b\n",
      "Successfully saved scenario for ConversationID b21048bd-641c-41f0-ab48-c903bfd82e7b to negotiation_scenarios_FT.csv\n",
      "Run 9 Summary:\n",
      "Initial Salary: $120900\n",
      "Desired Salary: $142000.0\n",
      "Final Offer: $137000.0\n"
     ]
    }
   ],
   "source": [
    "#Prompt to enter OpenAI API key\n",
    "openai.api_key = #############################\n",
    "#Set Up Configuration\n",
    "#######################################################################################################################\n",
    "#Model settings\n",
    "model_employee = # \n",
    "model_manager = #\n",
    "\n",
    "#Negotiation settings\n",
    "num_negotiations = 10\n",
    "max_turns = 10   #Maximum turns per negotiation\n",
    "sim_token_limit = 5000     #Total token limit for a single negotiation\n",
    "\n",
    "#######################################################################################################################\n",
    "#Scenario generator to help generate different scenarios\n",
    "def generate_random_scenario():\n",
    "    job_roles = [\n",
    "        \"Data Scientist\", \"Software Developer\", \"Data Engineer\", \"Machine Learning Engineer\",\n",
    "        \"Cloud Architect\", \"Cybersecurity Analyst\", \"DevOps Engineer\", \"Frontend Developer\",\n",
    "        \"Backend Developer\", \"Full Stack Developer\", \"Data Analyst\", \"Business Analyst\", \"Financial Analyst\",\n",
    "        \"Market Research Analyst\", \"Risk Analyst\", \"Quantitative Analyst\", \"Actuary\", \"BI (Business Intelligence) Developer\",\n",
    "        \"Supply Chain Analyst\", \"Quality Assurance Analyst\", \"Solutions Architect\",\"Management Consultant\",\n",
    "        \"Strategy Consultant\", \"IT Consultant\", \"Financial Consultant\", \"Personal Banker\"\n",
    "    ]\n",
    "\n",
    "    personalities = [\n",
    "        \"Assertive and Direct\", \"Empathetic and Understanding\", \"Optimistic and Cheerful\", \n",
    "        \"Pessimistic and Skeptical\", \"Logical and Analytical\", \"Data-Driven and Objective\", \n",
    "        \"Charismatic and Persuasive\", \"Cooperative and Team-Oriented\", \"Independent and Self-Assured\",\n",
    "        \"Reserved and Introverted\", \"Outspoken and Confident\", \"Ambitious and Goal-Oriented\",\n",
    "        \"Flexible and Open-Minded\", \"Competitive and Driven\", \"Thoughtful and Reflective\",\n",
    "        \"Emotionally Reactive\", \"Calm and Composed\", \"Decisive and Pragmatic\",\n",
    "        \"Detail-Oriented and Methodical\", \"Intuitive and Visionary\", \"Resourceful and Adaptable\", \n",
    "        \"Risk-Averse and Conservative\", \"Humorous and Lighthearted\", \"Respectful and Polite\", \n",
    "        \"Innovative and Forward-Thinking\"\n",
    "    ]\n",
    "\n",
    "    employee_motivations = [\n",
    "        \"wants a raise to better support family due to increased living costs\",\n",
    "        \"feels underpaid for the responsibilities taken on\",\n",
    "        \"wants a raise in line with industry standards\",\n",
    "        \"is planning to buy a house and needs higher income for mortgage\",\n",
    "        \"believes they have grown in skills and wants to be recognized\",\n",
    "        \"is seeking a salary increase after a successful project delivery\",\n",
    "        \"has been receiving competitive offers from other companies\",\n",
    "        \"is expecting a promotion and a corresponding raise\",\n",
    "        \"has taken on additional responsibilities without a raise\",\n",
    "        \"attained a higher education degree and is looking for a raise\",\n",
    "        \"is aiming to save for a child's education\", \n",
    "        \"has been with the company for more than 5 years\",\n",
    "        \"experiencing burnout and sees that a raise could alleviate this feeling\",\n",
    "        \"doesn't have a performance review coming up soon or a raise schedule in place\",\n",
    "        \"the company has reported strong earnings in its recent financial reports\",\n",
    "        \"recently taken on more responsibility or started a new position\",\n",
    "        \"has worked mainly at the office and does not have the option to work from home despite living long distance from work\",\n",
    "        \"seeking a raise otherwise will need to relocate due to a better offer from a company in another city\",\n",
    "        \"your managers frequently rely on you to pick up work from other team members\",\n",
    "        \"received a high-paying offer from another company but doesn't want to leave your current role\"\n",
    "    ]\n",
    "\n",
    "    manager_constraints = [\n",
    "        \"the company is facing budget constraints due to recent cost-cutting measures\",\n",
    "        \"the company has posted record profits this quarter\",\n",
    "        \"the department budget is tight, but employee retention is crucial\",\n",
    "        \"management is prioritizing retention for critical roles\",\n",
    "        \"the company has recently implemented a hiring freeze\",\n",
    "        \"the company is on the brink of filing for bankruptcy\",\n",
    "        \"the company has been acquired by another company in which new management will determine new compensation packages\",\n",
    "        \"there is uncertainty in the market, making budgets more restrictive\",\n",
    "        \"the company is launching a major initiative and needs to retain talent\",\n",
    "        \"other employees in similar roles have not received raises recently\",\n",
    "        \"HR policies require a thorough review before approving raises\",\n",
    "        \"the company is undergoing an internal restructuring process\"\n",
    "    ]\n",
    "\n",
    "    past_achievements = [\n",
    "        \"led three major projects that increased department productivity by 20%\",\n",
    "        \"received an award for excellent customer feedback\",\n",
    "        \"trained new hires and significantly reduced onboarding time\",\n",
    "        \"automated a process that saved the company $50,000 annually\",\n",
    "        \"initiated a successful cross-department collaboration project\",\n",
    "        \"developed a tool that reduced report generation time by 50%\",\n",
    "        \"solved a critical issue that prevented project delays worth millions\",\n",
    "        \"mentored junior employees, improving their performance significantly\",\n",
    "        \"secured a key client that generated $1 million in revenue\",\n",
    "        \"proposed a new strategy that increased team efficiency\"\n",
    "    ]\n",
    "\n",
    "    scenario = {\n",
    "        \"job_role\": random.choice(job_roles),\n",
    "        \"employee_personality\": random.choice(personalities),\n",
    "        \"hr_manager_personality\": random.choice(personalities),\n",
    "        \"employee_motivation\": random.choice(employee_motivations),\n",
    "        \"manager_constraint\": random.choice(manager_constraints),\n",
    "        \"past_achievement\": random.choice(past_achievements)}\n",
    "\n",
    "    current_salary = round(random.randint(45000, 175000),-2)\n",
    "    desired_percentage = random.uniform(0.05, 0.25) \n",
    "    desired_salary = round(current_salary + (current_salary * desired_percentage), -2)\n",
    "    adjusted_desired_salary = desired_salary \n",
    "\n",
    "    return scenario, current_salary, desired_salary\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "#Function to track token usage\n",
    "def token_usage_tracker(response, total_tokens_used, max_tokens):\n",
    "    print(f\"Response structure: {response}\")\n",
    "    #retrieve token usage\n",
    "    used_tokens = response.get('usage', {}).get('total_tokens', 0)\n",
    "    total_tokens_used += used_tokens\n",
    "\n",
    "    print(f\"Total tokens used in this turn: {used_tokens}. Total tokens so far: {total_tokens_used}/{max_tokens}\")\n",
    "\n",
    "    if total_tokens_used >= max_tokens:\n",
    "        print(\"Maximum number of tokens for negotiation used. Must end conversation.\")\n",
    "    \n",
    "    return total_tokens_used\n",
    "\n",
    "\n",
    "#Conversation history\n",
    "def generate_conversation_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "#RAG Section\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name='all-MiniLM-L6-v2') \n",
    "rag_document_location = \"RAG\"\n",
    "\n",
    "#Used to process PDFs, split into chunks\n",
    "def lang_chain_pdf_puller(rag_document_location):\n",
    "    all_chunks = []\n",
    "    file_list = []\n",
    "\n",
    "    #Raises an error should the folder not exist. \n",
    "    if not os.path.exists(rag_document_location):\n",
    "        raise FileNotFoundError(f\"The folder '{rag_document_location}' does not exist.\")\n",
    "    \n",
    "    #Reduce long text to avoid maximizing big chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "    for filename in os.listdir(rag_document_location):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(rag_document_location, filename)\n",
    "            try:\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                docs = loader.load()\n",
    "                # Split documents into chunks\n",
    "                chunks = text_splitter.split_documents(docs)\n",
    "                # Extend Chunks\n",
    "                all_chunks.extend(chunks)\n",
    "                file_list.append(filename)\n",
    "                print(f\"Processed file: {filename} with {len(chunks)} chunks.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "    return all_chunks, file_list\n",
    "\n",
    "all_chunks, file_list = lang_chain_pdf_puller(rag_document_location)\n",
    "texts = [chunk.page_content for chunk in all_chunks]\n",
    "vector_store = FAISS.from_texts(texts, embedding_model)\n",
    "\n",
    "#Sifted through folder\n",
    "def search_vector_db(query, vector_store, top_k=3):\n",
    "    \"\"\"Retrieve relevant information for given query to formulate better responses.\"\"\"\n",
    "    docs = vector_store.similarity_search(query, k=top_k)\n",
    "    return \" \".join([doc.page_content for doc in docs])\n",
    "\n",
    "##########################################################################################################################\n",
    "#conversation history to JSONL\n",
    "def save_conversation_to_jsonl(conversation_history, conversation_id, file_name=\"negotiation_chats_selfplay.jsonl\"):\n",
    "    try:\n",
    "        # Filter the conversation history to include only Employee and HR Manager roles\n",
    "        filtered_conversation = [\n",
    "            {\"role\": entry.get(\"role\"), \"content\": entry.get(\"content\")}\n",
    "            for entry in conversation_history\n",
    "            if entry.get(\"role\") != \"system\"]\n",
    "\n",
    "        #Negotiation entry\n",
    "        negotiation_entry = {\n",
    "            \"ConversationID\": conversation_id,\n",
    "            \"Negotiation\": filtered_conversation}\n",
    "        \n",
    "        json_string = json.dumps(negotiation_entry, ensure_ascii=False, indent=None)\n",
    "\n",
    "        #Append to file\n",
    "        with open(file_name, mode='a', encoding='utf-8') as jsonlfile:\n",
    "            jsonlfile.write(json_string + '\\n')  # Ensure newline after each JSON object\n",
    "\n",
    "        print(f\"Successfully saved conversation with ConversationID {conversation_id} to {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving conversation with ConversationID {conversation_id}: {e}\")\n",
    "\n",
    "\n",
    "def save_metrics_to_csv(metrics, conversation_id, file_name=\"self_play_metrics.csv\"):\n",
    "    metric_fieldnames = [\n",
    "        \"ConversationID\", \n",
    "        \"Timestamp\", \n",
    "        \"Model\",  \n",
    "        \"Personality\",  \n",
    "        \"Initial Salary\",  \n",
    "        \"Final Salary\",  \n",
    "        \"Salary Percent Change\",  \n",
    "        \"BLEU\",  \n",
    "        \"ROUGE\", \n",
    "        \"BERTScore\",  \n",
    "        \"Cosine Similarity\",  \n",
    "        \"METEOR\",\n",
    "        \"Avg Sentiment Score\", \n",
    "        \"Avg Response Length\",  \n",
    "        \"Avg Relevance Score\",  \n",
    "        \"Avg Coherence Score\",  \n",
    "        \"Avg Combined GEval Score\", \n",
    "        \"MAUDE\",  \n",
    "        \"Total Tokens\",  \n",
    "        \"Avg Latency\", \n",
    "        \"Tokens per Second\", \n",
    "        \"Total Cost\",  \n",
    "        \"Summary\"] \n",
    "    \n",
    "    #Add ConversationID to metrics\n",
    "    metrics[\"ConversationID\"] = conversation_id\n",
    "    #take off unnecessary fields\n",
    "    metrics = {key: metrics[key] for key in metric_fieldnames}\n",
    "    #Ensure metrics contain all necessary keys\n",
    "    for field in metric_fieldnames:\n",
    "        if field not in metrics:\n",
    "            metrics[field] = None  #Fill missing fields with None\n",
    "            \n",
    "    #Save metrics to the CSV file\n",
    "    file_exists = os.path.isfile(file_name)\n",
    "    with open(file_name, mode='a', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=metric_fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()  #Write header only once\n",
    "        writer.writerow(metrics)  #Write the metrics row\n",
    "    \n",
    "    print(f\"Metrics saved to {file_name} for ConversationID {conversation_id}\")\n",
    "\n",
    "def save_scenario_to_csv(scenario, conversation_id, file_name=\"negotiation_scenarios.csv\"):\n",
    "    #CSV columns\n",
    "    scenario_fieldnames = [\"ConversationID\", \"job_role\", \"employee_personality\", \"hr_manager_personality\", \"employee_motivation\", \"manager_constraint\", \"past_achievement\"]\n",
    "    #Add ConversationID to the scenario dictionary\n",
    "    scenario[\"ConversationID\"] = conversation_id\n",
    "\n",
    "    #Take off unnecessary fields and ensure all required fields are present\n",
    "    scenario = {key: scenario[key] for key in scenario_fieldnames}\n",
    "    for field in scenario_fieldnames:\n",
    "        if field not in scenario:\n",
    "            scenario[field] = None  #Fill missing fields with None\n",
    "\n",
    "    # Save the scenario to the CSV file\n",
    "    file_exists = os.path.isfile(file_name)\n",
    "    with open(file_name, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=scenario_fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()  #Write header only once\n",
    "        writer.writerow(scenario)  #Write the scenario row\n",
    "    \n",
    "    print(f\"Successfully saved scenario for ConversationID {conversation_id} to {file_name}\")\n",
    "\n",
    "##########################################################################################################################\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "cosine_similarity_model = SentenceTransformer('stsb-roberta-large')\n",
    "\n",
    "def cosine_similarity(reference, prediction):\n",
    "    embedding1 = cosine_similarity_model.encode(reference, convert_to_tensor=True)\n",
    "    embedding2 = cosine_similarity_model.encode(prediction, convert_to_tensor=True)\n",
    "    similarity_score = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    return similarity_score.item()\n",
    "    \n",
    "def corpus_bleu_eq(references, predictions):\n",
    "    tokenized_references = [[word_tokenize(ref)] for ref in references]\n",
    "    tokenized_predictions = [word_tokenize(pred) for pred in predictions]\n",
    "    return corpus_bleu(tokenized_references, tokenized_predictions, smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "def rouge_eq(reference, prediction):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(prediction, reference)\n",
    "    return scores[0]['rouge-l']['f']\n",
    "\n",
    "def meteor_eq(reference, prediction):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    tokenized_reference = tokenizer.tokenize(reference)\n",
    "    tokenized_prediction = tokenizer.tokenize(prediction)\n",
    "    return meteor_score([tokenized_reference], tokenized_prediction)\n",
    "\n",
    "def bertscore_metric(reference, prediction):\n",
    "    P, R, F1 = bert_score([prediction], [reference], lang=\"en\", verbose=False)\n",
    "    return F1.mean().item()\n",
    "\n",
    "def sentiment_score_def(text):\n",
    "    \"\"\"compound score: which ranges from -1 (negative) to +1 (positive).\"\"\"\n",
    "    sentiment = vader_analyzer.polarity_scores(text)\n",
    "    return sentiment['compound']\n",
    "\n",
    "def response_length_def(text):\n",
    "    \"\"\"calc number of words in the text response.\"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "#MAUDE\n",
    "def maude_def(context, response, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    MAUDE score using GPT-4's chat-completions endpoint.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Evaluate the following response in the context of the given conversation:\n",
    "- Context: {context}\n",
    "- Response: {response}\n",
    "\n",
    "Rate the response from 0 to 1 based on the following criteria:\n",
    "1. Coherence: How well the response logically follows from the context.\n",
    "2. Relevance: How directly the response addresses the context.\n",
    "\n",
    "Only provide the score as a numeric value between 0 and 1, with no additional explanation or text.\"\"\"\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an evaluation assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=10)\n",
    "        #Extract the score from the response\n",
    "        text_response = completion.choices[0].message['content'].strip()\n",
    "        print(f\"MAUDE Raw Response: {text_response}\")\n",
    "        if re.match(r'^\\d+(\\.\\d+)?$', text_response):\n",
    "            score = float(text_response)\n",
    "        else:\n",
    "            score = 0.0  #Handle invalid responses\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in MAUDE scoring: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "#GEval metrics for relevance and coherence\n",
    "def geval_def(context, response, criteria, model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    GE-val score for a given criteria (relevance or coherence).\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an evaluation assistant tasked with scoring a response based on the given criteria.\n",
    "    \n",
    "    Evaluation Task:\n",
    "    - Criteria: {criteria}\n",
    "    - Context: {context if context else 'N/A'}\n",
    "    - Response: {response}\n",
    "    \n",
    "    Scoring Instructions:\n",
    "    - Relevance: Score based on how directly the response addresses the context and aligns with a salary negotiation\n",
    "        - A score of 0.9–1.0: The response directly addresses the main points in the context and is highly relevant\n",
    "        - A score of 0.6–0.8: The response is partially relevant but may include unrelated or tangential content\n",
    "        - A score of 0.0–0.5: The response does not address the context or is entirely irrelevant\n",
    "    \n",
    "    - Coherence: Score based on how logically structured and clear the response is for a salary negotiation\n",
    "        - A score of 0.9–1.0: The response is well-structured, logical, and easy to understand.\n",
    "        - A score of 0.6–0.8: The response is somewhat clear but may contain minor logical inconsistencies\n",
    "        - A score of 0.0–0.5: The response is poorly structured, lacks logic, or is difficult to understand\n",
    "    \n",
    "    **Instructions**:\n",
    "    1. Provide a numeric score between 0.0 and 1.0 based on the criteria\n",
    "    2. Use only two decimal place in your score (e.g., 0.80, 0.90)\n",
    "    3. Do not include any explanation or additional text in your response; provide only the score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an evaluation assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.0,\n",
    "            max_tokens=10)\n",
    "        #Extract the score from the response\n",
    "        text_response = completion.choices[0].message['content'].strip()\n",
    "        print(f\"GEval ({criteria}) Raw Response: {text_response}\")\n",
    "        if re.match(r'^\\d+(\\.\\d+)?$', text_response):\n",
    "            score = float(text_response)\n",
    "        else:\n",
    "            score = 0.0  #Handle invalid responses\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in GEval scoring ({criteria}): {e}\")\n",
    "        return 0.0\n",
    "\n",
    "#####################################################################################\n",
    "#Reference text for BLEU, ROUGE, METEOR, BERTScore\n",
    "reference_data = pd.read_csv(\"negotiation_references_combined.csv\")\n",
    "\n",
    "#Filter references by role\n",
    "employee_references = reference_data[reference_data['role'] == 'Employee']['text'].tolist()\n",
    "hr_manager_references = reference_data[reference_data['role'] == 'HR Manager']['text'].tolist()\n",
    "\n",
    "#######################################################################################################\n",
    "#Function to evaluate a single model \n",
    "def evaluate_individual_model(\n",
    "    conversation_history, model_role, references, model_name, run_number, \n",
    "    current_salary, final_salary, model_personality, total_tokens_used, prompt_tokens,  \n",
    "        completion_tokens, agreement_status):\n",
    "    #Initialize metric containers\n",
    "    bleu_scores, rouge_scores, meteor_scores, bert_scores, cosine_similarity_scores = [], [], [], [], []\n",
    "    maude_scores = []\n",
    "    relevance_scores, coherence_scores, combined_geval_scores = [], [], []\n",
    "    sentiment_scores, response_lengths = [], []\n",
    "    latencies = []\n",
    "    total_time = 0  #Initialize total_time here\n",
    "    total_tokens = 0\n",
    "\n",
    "    #Summary of negotiation outcome\n",
    "    summary = agreement_status\n",
    "\n",
    "    #Filter responses for the given model role\n",
    "    assistant_responses = [msg for msg in conversation_history if msg[\"role\"] == model_role]\n",
    "\n",
    "    #Process each response for metrics\n",
    "    for i, assistant_response in enumerate(assistant_responses):\n",
    "        prediction = assistant_response.get(\"content\", \"\")\n",
    "        context = \" \".join([msg.get(\"content\", \"\") for msg in conversation_history[:i]])\n",
    "\n",
    "        #Calculate similarity metrics if reference exists\n",
    "        if i < len(references):\n",
    "            reference = references[i]\n",
    "            bleu_scores.append(corpus_bleu_eq([reference], [prediction]))\n",
    "            rouge_scores.append(rouge_eq(reference, prediction))\n",
    "            meteor_scores.append(meteor_eq(reference, prediction))\n",
    "            bert_scores.append(bertscore_metric(reference, prediction))\n",
    "            cosine_similarity_scores.append(cosine_similarity(reference, prediction))\n",
    "\n",
    "        #Calculate MAUDE score\n",
    "        maude_scores.append(maude_def(context, prediction, model=\"gpt-4o\"))\n",
    "\n",
    "        #Calculate GEval metrics\n",
    "        relevance_scores.append(geval_def(context, prediction, criteria=\"Relevance\", model=\"gpt-4o\"))\n",
    "        coherence_scores.append(geval_def(\"\", prediction, criteria=\"Coherence\", model=\"gpt-4o\"))\n",
    "        combined_geval_scores.append(round(0.5 * relevance_scores[-1] + 0.5 * coherence_scores[-1], 3))\n",
    "\n",
    "        #Sentiment and response length\n",
    "        sentiment_scores.append(sentiment_score_def(prediction))\n",
    "        response_lengths.append(response_length_def(prediction))\n",
    "\n",
    "        #Track latency and token usage\n",
    "        latency = assistant_response.get(\"latency\", 0)\n",
    "        latencies.append(latency)\n",
    "        total_tokens += assistant_response.get(\"token_count\", 0)\n",
    "        total_time += latency\n",
    "        usage = assistant_response.get('usage', {})\n",
    "        prompt_tokens += usage.get('prompt_tokens', 0)\n",
    "        completion_tokens += usage.get('completion_tokens', 0)\n",
    "\n",
    "    #Ensure tokens per second is calculated after processing all responses\n",
    "    tokens_per_second = total_tokens / total_time if total_time > 0 else 0\n",
    "\n",
    "    #Calculate total cost based on token usage \n",
    "    input_cost = (prompt_tokens / 1000000) * 12.00  #$12 per 1M input tokens\n",
    "    output_cost = (completion_tokens / 1000000) * 16.00  #$16 per 1M output tokens\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    #Calculate salary percent change\n",
    "    salary_percent_change = ((final_salary - current_salary) / current_salary) * 100\n",
    "    if salary_percent_change == 0:\n",
    "        print(f\"No change in salary: Initial = {current_salary}, Final = {final_salary}\")\n",
    "    else:\n",
    "        print(f\"Salary change: {salary_percent_change}%\")\n",
    "\n",
    "    #Create metrics dictionary\n",
    "    metrics_dictionary = {\n",
    "        \"BLEU\": np.mean(bleu_scores) if bleu_scores else 0,\n",
    "        \"ROUGE\": np.mean(rouge_scores) if rouge_scores else 0,\n",
    "        \"METEOR\": np.mean(meteor_scores) if meteor_scores else 0,\n",
    "        \"BERTScore\": np.mean(bert_scores) if bert_scores else 0,\n",
    "        \"Cosine Similarity\": np.mean(cosine_similarity_scores) if cosine_similarity_scores else 0,\n",
    "        \"MAUDE\": np.mean(maude_scores) if maude_scores else 0,\n",
    "        \"Avg Relevance Score\": np.mean(relevance_scores) if relevance_scores else 0,\n",
    "        \"Avg Coherence Score\": np.mean(coherence_scores) if coherence_scores else 0,\n",
    "        \"Avg Combined GEval Score\": np.mean(combined_geval_scores) if combined_geval_scores else 0,\n",
    "        \"Avg Sentiment Score\": np.mean(sentiment_scores) if sentiment_scores else 0,\n",
    "        \"Avg Response Length\": np.mean(response_lengths) if response_lengths else 0,\n",
    "        \"Avg Latency\": np.mean(latencies) if latencies else 0,\n",
    "        \"Tokens per Second\": tokens_per_second,\n",
    "        \"Total Tokens\": total_tokens,\n",
    "        \"Total Cost\": total_cost,\n",
    "        \"Salary Percent Change\": salary_percent_change,\n",
    "        \"Initial Salary\": current_salary,\n",
    "        \"Final Salary\": final_salary,\n",
    "        \"Summary\": summary,\n",
    "        \"Timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"Model\": model_name,\n",
    "        \"Personality\": model_personality}\n",
    "\n",
    "    return metrics_dictionary\n",
    "\n",
    "###########################################################################################################################\n",
    "def extract_salary(response):\n",
    "    \"\"\"\n",
    "    Extract the salary from a response with enhanced fallback strategies.\n",
    "    \"\"\"\n",
    "    #Keywords that indicate salary\n",
    "    salary_keywords = [\n",
    "        \"propose\", \"offer\", \"current salary\", \"desired salary\",\n",
    "        \"counteroffer\", \"final offer\", \"salary of\", \"adjustment to\",\n",
    "        \"compensation\", \"increase to\", \"base salary\", \"package\"]\n",
    "\n",
    "    #Match dollar amounts in various formats\n",
    "    matches = re.findall(r'\\$\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', response)  #Match \"$123,456.78\"\n",
    "    print(f\"Extracted Matches: {matches}\")  #Debugging statement for matches\n",
    "\n",
    "    #If matches found, proceed to validate proximity to keywords\n",
    "    if matches:\n",
    "        for match in matches:\n",
    "            #Clean and convert the matched dollar amount\n",
    "            salary_amount = float(match.replace(\",\", \"\").replace(\"$\", \"\"))\n",
    "\n",
    "            #Check if the matched salary is near a keyword\n",
    "            for keyword in salary_keywords:\n",
    "                pattern = rf\"{keyword}.*?{match}|{match}.*?{keyword}\"  #Check proximity\n",
    "                if re.search(pattern, response, re.IGNORECASE):\n",
    "                    print(f\"Extracted salary: {salary_amount} with keyword '{keyword}'\")\n",
    "                    return salary_amount  # Return the first valid match\n",
    "\n",
    "        #Fallback: If no keywords are matched, assume the first dollar amount is a salary\n",
    "        print(f\"No keywords matched. Using first extracted match as fallback: {matches[0]}\")\n",
    "        return float(matches[0].replace(\",\", \"\").replace(\"$\", \"\"))\n",
    "\n",
    "    #Final fallback: If no matches, log and return None\n",
    "    print(f\"No valid salary found in response: {response}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "#Function intended to remove extraneous words and phrases that may be inadvertently printed \n",
    "#this helps remove gernated text issues we have seen constantly\n",
    "def clean_response(response):\n",
    "    #Remove or limit \"Thank you\" or similar phrases\n",
    "    response = re.sub(r\"(Thank you|I appreciate|truly).+?\\.\", \"\", response, flags=re.IGNORECASE).strip()\n",
    "    #Remove placeholders like \"[Employee's Name]\"\n",
    "    response = re.sub(r\"\\[.*?\\]\", \"\", response).strip()\n",
    "    #Remove leading role identifiers like \"HR Manager:\" or \"Employee:\" or \"Dear ...\"\n",
    "    response = re.sub(r\"^(HR Manager:|Employee:|Dear\\s.+?,)\", \"\", response, flags=re.IGNORECASE).strip()\n",
    "    #Remove excessive whitespace\n",
    "    response = re.sub(r\"\\s+\", \" \", response).strip()\n",
    "    #Remove bullet points, markdown-like formatting, and excessive symbols\n",
    "    response = re.sub(r\"(\\*\\*|--|\\s*-)\", \"\", response).strip()\n",
    "    #Remove numbers or irrelevant prefixes (e.g., \"94.\")\n",
    "    response = re.sub(r\"^\\d+\\.?\", \"\", response).strip()\n",
    "    #Split into sentences and remove duplicates while preserving order\n",
    "    sentences = [s.strip() for s in response.split(\".\") if s.strip()]\n",
    "    seen = set()\n",
    "    unique_sentences = []\n",
    "    for s in sentences:\n",
    "        if s not in seen and s != \"\":\n",
    "            unique_sentences.append(s)\n",
    "            seen.add(s)\n",
    "\n",
    "    #Rejoin sentences\n",
    "    response = \". \".join(unique_sentences).strip()\n",
    "\n",
    "    #Remove repeated leading \"We\" or \"I\" (rare edge case)\n",
    "    response = re.sub(r\"^(We\\s+We|I\\s+I)\\s+\", \"\", response, flags=re.IGNORECASE)\n",
    "\n",
    "    #Ensure proper capitalization of the first letter\n",
    "    if response and not response[0].isupper():\n",
    "        response = response[0].upper() + response[1:]\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_negotiation_outcome(conversation_history, model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Determines whether the negotiation ended in an agreement or no agreement\n",
    "    based on the last four turns of the conversation using GPT-4o.\n",
    "    \"\"\"\n",
    "    #Extract the last four turns\n",
    "    last_turns = conversation_history[-4:]\n",
    "    last_turns_text = \"\\n\".join(\n",
    "        f\"{entry['role']}: {entry['content']}\" for entry in last_turns)\n",
    "\n",
    "    #Create the evaluation prompt\n",
    "    evaluation_prompt = f\"\"\"\n",
    "    Below is the conversation history of a salary negotiation. \n",
    "    Review the final four turns and determine whether the negotiation ended in an agreement or no agreement. \n",
    "    Your response must include one of the following:\n",
    "    - \"Agreement\" if both parties agreed on a salary or terms.\n",
    "    - \"No Agreement\" if the negotiation ended without mutual consent.\n",
    "\n",
    "    Final Four Turns:\n",
    "    {last_turns_text}\n",
    "\n",
    "    Outcome:\n",
    "    \"\"\"\n",
    "\n",
    "    #Call the GPT-4o model to evaluate the outcome\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an evaluation assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": evaluation_prompt.strip()}\n",
    "            ],\n",
    "            max_tokens=50,\n",
    "            temperature=0.0)\n",
    "        outcome = response.choices[0].message['content'].strip()\n",
    "        print(f\"Evaluation Bot Outcome: {outcome}\")\n",
    "        return outcome\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating negotiation outcome: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################################################################\n",
    "\n",
    "def run_negotiation(\n",
    "    model_employee,\n",
    "    model_manager,\n",
    "    scenario,\n",
    "    current_salary,\n",
    "    desired_salary,\n",
    "    max_turns,\n",
    "    sim_token_limit):\n",
    "    \"\"\"\n",
    "    Simulates a salary negotiation where HR Manager always concludes the conversation.\n",
    "    Ensures strict role alternation and avoids double turns.\n",
    "    \"\"\"\n",
    "    conversation_history = []\n",
    "    total_tokens_used = 0\n",
    "    current_offer = current_salary\n",
    "    highest_counteroffer = current_salary\n",
    "    total_time = 0\n",
    "    prompt_tokens = 0\n",
    "    completion_tokens = 0\n",
    "\n",
    "    starting_role = random.choice([\"Employee\", \"HR Manager\"])\n",
    "    current_role = starting_role\n",
    "    roles = {\"Employee\": model_employee, \"HR Manager\": model_manager}\n",
    "\n",
    "    # Introductory message\n",
    "    if starting_role == \"Employee\":\n",
    "        intro_message = f\"\"\"\n",
    "        Thank you for taking the time to meet today. I wanted to discuss my compensation and explore how we can align \n",
    "        it more closely with my contributions and the market standards. My current salary is ${current_salary}, and \n",
    "        I believe there is room for adjustment to better reflect my role.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        intro_message = f\"\"\"\n",
    "        Thank you for meeting with us today to discuss your compensation. \n",
    "        We value your work at the company and aim to have a discussion.\n",
    "        Currently, your salary is ${current_salary}, and we are open to discussing an adjustment.\n",
    "        \"\"\"\n",
    "\n",
    "    conversation_history.append({\n",
    "        \"role\": starting_role,\n",
    "        \"content\": intro_message.strip(),\n",
    "        \"latency\": 0,\n",
    "        \"token_count\": 0})\n",
    "\n",
    "    agreement_status = \"No Agreement\"\n",
    "    minimum_turns = max_turns // 2\n",
    "\n",
    "    #Negotiation loop\n",
    "    for turn in range(max_turns):\n",
    "        #Ensure role alternation\n",
    "        current_role = \"HR Manager\" if current_role == \"Employee\" else \"Employee\"\n",
    "        model = roles[current_role]\n",
    "        tone = scenario[\"employee_personality\"] if current_role == \"Employee\" else scenario[\"hr_manager_personality\"]\n",
    "\n",
    "        memory_context = \"\\n\".join(f\"{entry['role']}: {entry['content']}\" for entry in conversation_history[-4:])\n",
    "        prompt = f\"\"\"\n",
    "        The employee's current salary is ${current_salary}.\n",
    "        The company's current offer is ${current_offer}.\n",
    "        The employee's desired salary is ${desired_salary}.\n",
    "        The highest counteroffer so far is ${highest_counteroffer}.\n",
    "        \n",
    "        Context:\n",
    "        {memory_context}\n",
    "\n",
    "        Instructions:\n",
    "        - Respond as the {current_role} in a {tone} tone.\n",
    "        - Avoid repeating points; introduce new arguments or compromises.\n",
    "        - Suggest creative solutions (e.g., bonuses, phased raises, non-monetary benefits).\n",
    "        - Be concise and professional.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": f\"You are the {current_role} in this negotiation.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "                max_tokens=200,\n",
    "                temperature=0.7)\n",
    "            latency = time.time() - start_time\n",
    "            total_time += latency\n",
    "\n",
    "            response_content = response.choices[0].message['content'].strip()\n",
    "            response_tokens = response['usage']['total_tokens']\n",
    "            total_tokens_used += response_tokens\n",
    "\n",
    "            response_content = clean_response(response_content)\n",
    "            conversation_history.append({\n",
    "                \"role\": current_role,\n",
    "                \"content\": response_content,\n",
    "                \"latency\": latency,\n",
    "                \"token_count\": response_tokens})\n",
    "\n",
    "            print(f\"Turn {turn + 1} ({current_role}):\\n{response_content}\")\n",
    "\n",
    "            #Update offers dynamically\n",
    "            if current_role == \"Employee\" and \"$\" in response_content:\n",
    "                extracted_salary = extract_salary(response_content)\n",
    "                if extracted_salary:\n",
    "                    highest_counteroffer = max(highest_counteroffer, extracted_salary)\n",
    "                    current_offer = max(current_offer, highest_counteroffer - 5000)\n",
    "            elif current_role == \"HR Manager\" and \"$\" in response_content:\n",
    "                extracted_salary = extract_salary(response_content)\n",
    "                if extracted_salary:\n",
    "                    current_offer = max(current_offer, extracted_salary)\n",
    "                    highest_counteroffer = max(highest_counteroffer, current_offer + 5000)\n",
    "\n",
    "            #Early agreement check after minimum turns\n",
    "            if turn >= minimum_turns:\n",
    "                current_outcome = evaluate_negotiation_outcome(conversation_history)\n",
    "                if current_outcome == \"Agreement\":\n",
    "                    agreement_status = \"Agreement\"\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response for {current_role}: {e}\")\n",
    "            break\n",
    "\n",
    "    #HR Manager Final Turn to Conclude the Negotiation\n",
    "    closing_prompt = \"\"\"\n",
    "    Conclude the negotiation as the HR Manager:\n",
    "    - If Agreement: Express enthusiasm, confirm the agreed terms, and highlight the employee's future contributions.\n",
    "    - If No Agreement: Respectfully acknowledge the decision, express gratitude, and leave the door open for future discussions.\n",
    "    \"\"\"\n",
    "    hr_manager_response = openai.ChatCompletion.create(\n",
    "        model=model_manager,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are the HR Manager concluding the negotiation.\"},\n",
    "            {\"role\": \"user\", \"content\": closing_prompt.strip()}],\n",
    "        max_tokens=150,\n",
    "        temperature=0.5)\n",
    "    hr_manager_content = clean_response(hr_manager_response.choices[0].message['content'].strip())\n",
    "    #Append only HR Manager's final response\n",
    "    if conversation_history[-1]['role'] != \"HR Manager\":  #Prevent consecutive HR Manager turns\n",
    "        conversation_history.append({\n",
    "            \"role\": \"HR Manager\",\n",
    "            \"content\": hr_manager_content,\n",
    "            \"latency\": 0,\n",
    "            \"token_count\": hr_manager_response['usage']['total_tokens']})\n",
    "\n",
    "    print(f\"Final HR Manager Turn:\\n{hr_manager_content}\")\n",
    "    #Final Evaluation\n",
    "    agreement_status = evaluate_negotiation_outcome(conversation_history)\n",
    "    return conversation_history, current_offer, total_tokens_used, prompt_tokens, completion_tokens, agreement_status\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Negotiation Loop\n",
    "for run in range(num_negotiations):\n",
    "    scenario, current_salary, desired_salary = generate_random_scenario()\n",
    "    conversation_id = generate_conversation_id()\n",
    "\n",
    "    #Updated to unpack all returned values\n",
    "    conversation, current_offer, total_tokens_used, prompt_tokens, completion_tokens, agreement_reached = run_negotiation(\n",
    "        model_employee=model_employee,\n",
    "        model_manager=model_manager,\n",
    "        scenario=scenario,\n",
    "        current_salary=current_salary,\n",
    "        desired_salary=desired_salary,\n",
    "        max_turns=max_turns,\n",
    "        sim_token_limit=sim_token_limit)\n",
    "\n",
    "\n",
    "    #Save negotiation details\n",
    "    save_conversation_to_jsonl(conversation, conversation_id, file_name=\"negotiation_chats_selfplay_FT.jsonl\")\n",
    "    final_salary = current_offer if agreement_reached == \"Agreement\" else current_salary\n",
    "    \n",
    "    model_1_metrics = evaluate_individual_model(\n",
    "        conversation_history=conversation,\n",
    "        model_role=\"Employee\",\n",
    "        references=employee_references,\n",
    "        model_name=\"Model 1\",\n",
    "        run_number=run,\n",
    "        current_salary=current_salary,\n",
    "        final_salary = current_offer if agreement_reached == \"Agreement\" else current_salary,\n",
    "        model_personality=scenario[\"employee_personality\"],\n",
    "        total_tokens_used=total_tokens_used,\n",
    "        prompt_tokens=prompt_tokens,  \n",
    "        completion_tokens=completion_tokens,  \n",
    "        agreement_status=agreement_reached)\n",
    "    \n",
    "    model_2_metrics = evaluate_individual_model(\n",
    "        conversation_history=conversation,\n",
    "        model_role=\"HR Manager\",\n",
    "        references=hr_manager_references,\n",
    "        model_name=\"Model 2\",\n",
    "        run_number=run,\n",
    "        current_salary=current_salary,\n",
    "        final_salary= current_offer if agreement_reached == \"Agreement\" else current_salary,  \n",
    "        model_personality=scenario[\"hr_manager_personality\"],\n",
    "        total_tokens_used=total_tokens_used,\n",
    "        prompt_tokens=prompt_tokens,  \n",
    "        completion_tokens=completion_tokens,  \n",
    "        agreement_status=agreement_reached)\n",
    "\n",
    "\n",
    "    #Save metrics for the run\n",
    "    save_metrics_to_csv(model_1_metrics, conversation_id, file_name=\"model_1_metrics_FT.csv\")\n",
    "    save_metrics_to_csv(model_2_metrics, conversation_id, file_name=\"model_2_metrics_FT.csv\")\n",
    "    save_scenario_to_csv(scenario, conversation_id, file_name=\"negotiation_scenarios_FT.csv\")\n",
    "\n",
    "    print(f\"Run {run} Summary:\")\n",
    "    print(f\"Initial Salary: ${current_salary}\")\n",
    "    print(f\"Desired Salary: ${desired_salary}\")\n",
    "    print(f\"Final Offer: ${current_offer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a01392-a56a-4e39-8342-84c1eb7a7979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
