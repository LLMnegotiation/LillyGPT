{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2208c336-369b-48f6-b6b3-a946ac2aa88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/chrisgallevo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/chrisgallevo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import uuid # for conversation id\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datetime import datetime\n",
    "import openai\n",
    "import random\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "#RAG \n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "#Incorporating langchain for easier integration and embedding document chunks into FAISS vector\n",
    "#Rationale More Efficiency \n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "#Metrics\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from rouge import Rouge \n",
    "from bert_score import score as bert_score\n",
    "from nltk.translate.meteor_score import meteor_score \n",
    "from nltk.tokenize import word_tokenize  #Import for tokenizing\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from rouge_score import rouge_scorer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from transformers import pipeline\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8a1cd2b-cf35-4ea4-8aec-8618a76b1a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: main_negotiations.pdf with 93 chunks.\n",
      "Processed file: business-english-negotiations-jigsaw-dialogues-and-useful-phrases.pdf with 6 chunks.\n",
      "Processed file: Transcript Example.pdf with 9 chunks.\n",
      "Processed file: 62 Business English Negotiation Phrases _ FluentU.pdf with 23 chunks.\n",
      "Turn 1 (Employee):\n",
      "I believe we can find a path forward that aligns with both our goals. While my desired salary is $121,900, I understand the need for flexibility. Perhaps we could explore a phased salary increase, starting with an initial adjustment and a review in six months based on performance metrics. Additionally, a performancebased bonus structure or enhanced professional development opportunities could bridge the gap. Let's work together to create a mutually beneficial arrangement\n",
      "Turn 2 (HR Manager):\n",
      "While the current budget limits us to maintaining the $105,100 salary, I am open to discussing a phased approach. We can consider an initial raise to $109,000, with a performance review in six months to assess further adjustments. Additionally, let's explore a performancebased bonus structure that rewards your contributions and a personalized professional development plan. This approach acknowledges your value and aligns with our financial framework\n",
      "Turn 3 (Employee):\n",
      "I'm encouraged by the proposal of an initial raise to $109,000 and the opportunity to review performance metrics in six months. To further align our goals, I'd like to suggest a more structured performancebased bonus system that directly reflects my contributions and achievements. Additionally, access to exclusive training programs or leadership workshops could enhance my skills and, in turn, benefit the company. Together, we can craft a growthoriented plan that respects both my aspirations and the company's budgetary considerations\n",
      "Turn 4 (HR Manager):\n",
      "Let's finalize the initial raise to $109,000, effective immediately, with a performance review set for six months. To strengthen our collaboration, we'll implement a structured bonus system directly tied to your achievements. Moreover, we'll provide access to exclusive training programs and leadership workshops to further develop your skills. This plan not only supports your growth but also aligns with our commitment to recognizing and rewarding your contributions. Let's proceed with these arrangements to ensure mutual success\n",
      "Turn 5 (Employee):\n",
      "The initial raise to $109,000, coupled with a structured bonus system and access to training programs, sets a positive trajectory for both my development and our shared success. To add a creative layer, perhaps we could explore mentorship opportunities within the company. This would not only enhance my leadership skills but also foster a culture of knowledge sharing. I'm confident this approach will drive mutual growth and innovation. Let's move forward with these initiatives\n",
      "Turn 6 (HR Manager):\n",
      "I'm pleased to see your enthusiasm for the plan we've outlined. Let's integrate mentorship opportunities as part of your development strategy. This initiative will not only enhance your leadership capabilities but also contribute to our culture of knowledge sharing. We believe this comprehensive approach—combining the immediate raise, performancebased bonuses, exclusive training, and mentorship—will drive our mutual growth and innovation. We'll proceed with these arrangements to solidify our commitment to your development and success\n",
      "Evaluation Bot Outcome: Agreement\n",
      "Agreement reached early. Ending negotiation.\n",
      "Successfully saved conversation with ConversationID c82a87c2-c68b-459b-833e-6f591b0e27c3 to negotiation_chats_selfplay_base.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.5\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0.9\n",
      "GEval (Relevance) Raw Response: 0.80\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "No change in salary: Initial = 105100, Final = 105100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 0\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.95\n",
      "GEval (Coherence) Raw Response: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAUDE Raw Response: 1\n",
      "GEval (Relevance) Raw Response: 0.90\n",
      "GEval (Coherence) Raw Response: 0.95\n",
      "No change in salary: Initial = 105100, Final = 105100\n",
      "Metrics saved to model_1_metrics_base.csv for ConversationID c82a87c2-c68b-459b-833e-6f591b0e27c3\n",
      "Metrics saved to model_2_metrics_base.csv for ConversationID c82a87c2-c68b-459b-833e-6f591b0e27c3\n",
      "Successfully saved scenario for ConversationID c82a87c2-c68b-459b-833e-6f591b0e27c3 to negotiation_scenarios_base.csv\n",
      "Run 0 Summary:\n",
      "Initial Salary: $105100\n",
      "Desired Salary: $121900.0\n",
      "Final Offer: $105100\n"
     ]
    }
   ],
   "source": [
    "#Prompt to enter OpenAI API key\n",
    "openai.api_key = #####################################INSERT API KEY HERE#########################################\n",
    "\n",
    "#Set Up Configuration\n",
    "#######################################################################################################################\n",
    "#Model settings\n",
    "model_employee = 'gpt-4o'  \n",
    "model_manager = 'gpt-4o' \n",
    "\n",
    "#Negotiation settings\n",
    "num_negotiations = 1\n",
    "max_turns = 10   #Maximum turns per negotiation\n",
    "sim_token_limit = 5000     #Total token limit for a single negotiation\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "#Scenario generator to help generate different scenarios\n",
    "def generate_random_scenario():\n",
    "    job_roles = [\n",
    "        \"Data Scientist\", \"Software Developer\", \"Data Engineer\", \"Machine Learning Engineer\",\n",
    "        \"Cloud Architect\", \"Cybersecurity Analyst\", \"DevOps Engineer\", \"Frontend Developer\",\n",
    "        \"Backend Developer\", \"Full Stack Developer\", \"Data Analyst\", \"Business Analyst\", \"Financial Analyst\",\n",
    "        \"Market Research Analyst\", \"Risk Analyst\", \"Quantitative Analyst\", \"Actuary\", \"BI (Business Intelligence) Developer\",\n",
    "        \"Supply Chain Analyst\", \"Quality Assurance Analyst\", \"Solutions Architect\",\"Management Consultant\",\n",
    "        \"Strategy Consultant\", \"IT Consultant\", \"Financial Consultant\", \"Personal Banker\"\n",
    "    ]\n",
    "\n",
    "    personalities = [\n",
    "        \"Assertive and Direct\", \"Empathetic and Understanding\", \"Optimistic and Cheerful\", \n",
    "        \"Pessimistic and Skeptical\", \"Logical and Analytical\", \"Data-Driven and Objective\", \n",
    "        \"Charismatic and Persuasive\", \"Cooperative and Team-Oriented\", \"Independent and Self-Assured\",\n",
    "        \"Reserved and Introverted\", \"Outspoken and Confident\", \"Ambitious and Goal-Oriented\",\n",
    "        \"Flexible and Open-Minded\", \"Competitive and Driven\", \"Thoughtful and Reflective\",\n",
    "        \"Emotionally Reactive\", \"Calm and Composed\", \"Decisive and Pragmatic\",\n",
    "        \"Detail-Oriented and Methodical\", \"Intuitive and Visionary\", \"Resourceful and Adaptable\", \n",
    "        \"Risk-Averse and Conservative\", \"Humorous and Lighthearted\", \"Respectful and Polite\", \n",
    "        \"Innovative and Forward-Thinking\"\n",
    "    ]\n",
    "\n",
    "    employee_motivations = [\n",
    "        \"wants a raise to better support family due to increased living costs\",\n",
    "        \"feels underpaid for the responsibilities taken on\",\n",
    "        \"wants a raise in line with industry standards\",\n",
    "        \"is planning to buy a house and needs higher income for mortgage\",\n",
    "        \"believes they have grown in skills and wants to be recognized\",\n",
    "        \"is seeking a salary increase after a successful project delivery\",\n",
    "        \"has been receiving competitive offers from other companies\",\n",
    "        \"is expecting a promotion and a corresponding raise\",\n",
    "        \"has taken on additional responsibilities without a raise\",\n",
    "        \"attained a higher education degree and is looking for a raise\",\n",
    "        \"is aiming to save for a child's education\", \n",
    "        \"has been with the company for more than 5 years\",\n",
    "        \"experiencing burnout and sees that a raise could alleviate this feeling\",\n",
    "        \"doesn't have a performance review coming up soon or a raise schedule in place\",\n",
    "        \"the company has reported strong earnings in its recent financial reports\",\n",
    "        \"recently taken on more responsibility or started a new position\",\n",
    "        \"has worked mainly at the office and does not have the option to work from home despite living long distance from work\",\n",
    "        \"seeking a raise otherwise will need to relocate due to a better offer from a company in another city\",\n",
    "        \"your managers frequently rely on you to pick up work from other team members\",\n",
    "        \"received a high-paying offer from another company but doesn't want to leave your current role\"\n",
    "    ]\n",
    "\n",
    "    manager_constraints = [\n",
    "        \"the company is facing budget constraints due to recent cost-cutting measures\",\n",
    "        \"the company has posted record profits this quarter\",\n",
    "        \"the department budget is tight, but employee retention is crucial\",\n",
    "        \"management is prioritizing retention for critical roles\",\n",
    "        \"the company has recently implemented a hiring freeze\",\n",
    "        \"the company is on the brink of filing for bankruptcy\",\n",
    "        \"the company has been acquired by another company in which new management will determine new compensation packages\",\n",
    "        \"there is uncertainty in the market, making budgets more restrictive\",\n",
    "        \"the company is launching a major initiative and needs to retain talent\",\n",
    "        \"other employees in similar roles have not received raises recently\",\n",
    "        \"HR policies require a thorough review before approving raises\",\n",
    "        \"the company is undergoing an internal restructuring process\"\n",
    "    ]\n",
    "\n",
    "    past_achievements = [\n",
    "        \"led three major projects that increased department productivity by 20%\",\n",
    "        \"received an award for excellent customer feedback\",\n",
    "        \"trained new hires and significantly reduced onboarding time\",\n",
    "        \"automated a process that saved the company $50,000 annually\",\n",
    "        \"initiated a successful cross-department collaboration project\",\n",
    "        \"developed a tool that reduced report generation time by 50%\",\n",
    "        \"solved a critical issue that prevented project delays worth millions\",\n",
    "        \"mentored junior employees, improving their performance significantly\",\n",
    "        \"secured a key client that generated $1 million in revenue\",\n",
    "        \"proposed a new strategy that increased team efficiency\"\n",
    "    ]\n",
    "\n",
    "    scenario = {\n",
    "        \"job_role\": random.choice(job_roles),\n",
    "        \"employee_personality\": random.choice(personalities),\n",
    "        \"hr_manager_personality\": random.choice(personalities),\n",
    "        \"employee_motivation\": random.choice(employee_motivations),\n",
    "        \"manager_constraint\": random.choice(manager_constraints),\n",
    "        \"past_achievement\": random.choice(past_achievements)}\n",
    "\n",
    "    current_salary = round(random.randint(45000, 175000),-2)\n",
    "    desired_percentage = random.uniform(0.05, 0.25) \n",
    "    desired_salary = round(current_salary + (current_salary * desired_percentage), -2)\n",
    "    adjusted_desired_salary = desired_salary \n",
    "\n",
    "    return scenario, current_salary, desired_salary\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "#Function to track token usage\n",
    "def token_usage_tracker(response, total_tokens_used, max_tokens):\n",
    "    print(f\"Response structure: {response}\")\n",
    "    #retrieve token usage\n",
    "    used_tokens = response.get('usage', {}).get('total_tokens', 0)\n",
    "    total_tokens_used += used_tokens\n",
    "\n",
    "    print(f\"Total tokens used in this turn: {used_tokens}. Total tokens so far: {total_tokens_used}/{max_tokens}\")\n",
    "\n",
    "    if total_tokens_used >= max_tokens:\n",
    "        print(\"Maximum number of tokens for negotiation used. Must end conversation.\")\n",
    "    \n",
    "    return total_tokens_used\n",
    "\n",
    "\n",
    "#Conversation history\n",
    "def generate_conversation_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "#RAG Section\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name='all-MiniLM-L6-v2') \n",
    "rag_document_location = \"RAG\"\n",
    "\n",
    "#Used to process PDFs, split into chunks\n",
    "def lang_chain_pdf_puller(rag_document_location):\n",
    "    all_chunks = []\n",
    "    file_list = []\n",
    "\n",
    "    #Raises an error should the folder not exist. \n",
    "    if not os.path.exists(rag_document_location):\n",
    "        raise FileNotFoundError(f\"The folder '{rag_document_location}' does not exist.\")\n",
    "    \n",
    "    #Reduce long text to avoid maximizing big chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "    for filename in os.listdir(rag_document_location):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(rag_document_location, filename)\n",
    "            try:\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                docs = loader.load()\n",
    "                # Split documents into chunks\n",
    "                chunks = text_splitter.split_documents(docs)\n",
    "                # Extend Chunks\n",
    "                all_chunks.extend(chunks)\n",
    "                file_list.append(filename)\n",
    "                print(f\"Processed file: {filename} with {len(chunks)} chunks.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "    return all_chunks, file_list\n",
    "\n",
    "all_chunks, file_list = lang_chain_pdf_puller(rag_document_location)\n",
    "texts = [chunk.page_content for chunk in all_chunks]\n",
    "vector_store = FAISS.from_texts(texts, embedding_model)\n",
    "\n",
    "#Sifted through folder\n",
    "def search_vector_db(query, vector_store, top_k=3):\n",
    "    \"\"\"Retrieve relevant information for given query to formulate better responses.\"\"\"\n",
    "    docs = vector_store.similarity_search(query, k=top_k)\n",
    "    return \" \".join([doc.page_content for doc in docs])\n",
    "\n",
    "##########################################################################################################################\n",
    "#conversation history to JSONL\n",
    "def save_conversation_to_jsonl(conversation_history, conversation_id, file_name=\"negotiation_chats_selfplay.jsonl\"):\n",
    "    try:\n",
    "        # Filter the conversation history to include only Employee and HR Manager roles\n",
    "        filtered_conversation = [\n",
    "            {\"role\": entry.get(\"role\"), \"content\": entry.get(\"content\")}\n",
    "            for entry in conversation_history\n",
    "            if entry.get(\"role\") != \"system\"]\n",
    "\n",
    "        #Negotiation entry\n",
    "        negotiation_entry = {\n",
    "            \"ConversationID\": conversation_id,\n",
    "            \"Negotiation\": filtered_conversation}\n",
    "        \n",
    "        json_string = json.dumps(negotiation_entry, ensure_ascii=False, indent=None)\n",
    "\n",
    "        #Append to file\n",
    "        with open(file_name, mode='a', encoding='utf-8') as jsonlfile:\n",
    "            jsonlfile.write(json_string + '\\n')  # Ensure newline after each JSON object\n",
    "\n",
    "        print(f\"Successfully saved conversation with ConversationID {conversation_id} to {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving conversation with ConversationID {conversation_id}: {e}\")\n",
    "\n",
    "\n",
    "def save_metrics_to_csv(metrics, conversation_id, file_name=\"self_play_metrics.csv\"):\n",
    "    metric_fieldnames = [\n",
    "        \"ConversationID\", \n",
    "        \"Timestamp\", \n",
    "        \"Model\",  \n",
    "        \"Personality\",  \n",
    "        \"Initial Salary\",  \n",
    "        \"Final Salary\",  \n",
    "        \"Salary Percent Change\",  \n",
    "        \"BLEU\",  \n",
    "        \"ROUGE\", \n",
    "        \"BERTScore\",  \n",
    "        \"Cosine Similarity\",  \n",
    "        \"METEOR\",\n",
    "        \"Avg Sentiment Score\", \n",
    "        \"Avg Response Length\",  \n",
    "        \"Avg Relevance Score\",  \n",
    "        \"Avg Coherence Score\",  \n",
    "        \"Avg Combined GEval Score\", \n",
    "        \"MAUDE\",  \n",
    "        \"Total Tokens\",  \n",
    "        \"Avg Latency\", \n",
    "        \"Tokens per Second\", \n",
    "        \"Total Cost\",  \n",
    "        \"Summary\"] \n",
    "    \n",
    "    #Add ConversationID to metrics\n",
    "    metrics[\"ConversationID\"] = conversation_id\n",
    "    #take off unnecessary fields\n",
    "    metrics = {key: metrics[key] for key in metric_fieldnames}\n",
    "    #Ensure metrics contain all necessary keys\n",
    "    for field in metric_fieldnames:\n",
    "        if field not in metrics:\n",
    "            metrics[field] = None  #Fill missing fields with None\n",
    "            \n",
    "    #Save metrics to the CSV file\n",
    "    file_exists = os.path.isfile(file_name)\n",
    "    with open(file_name, mode='a', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=metric_fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()  #Write header only once\n",
    "        writer.writerow(metrics)  #Write the metrics row\n",
    "    \n",
    "    print(f\"Metrics saved to {file_name} for ConversationID {conversation_id}\")\n",
    "\n",
    "def save_scenario_to_csv(scenario, conversation_id, file_name=\"negotiation_scenarios.csv\"):\n",
    "    #CSV columns\n",
    "    scenario_fieldnames = [\"ConversationID\", \"job_role\", \"employee_personality\", \"hr_manager_personality\", \"employee_motivation\", \"manager_constraint\", \"past_achievement\"]\n",
    "    #Add ConversationID to the scenario dictionary\n",
    "    scenario[\"ConversationID\"] = conversation_id\n",
    "\n",
    "    #Take off unnecessary fields and ensure all required fields are present\n",
    "    scenario = {key: scenario[key] for key in scenario_fieldnames}\n",
    "    for field in scenario_fieldnames:\n",
    "        if field not in scenario:\n",
    "            scenario[field] = None  #Fill missing fields with None\n",
    "\n",
    "    # Save the scenario to the CSV file\n",
    "    file_exists = os.path.isfile(file_name)\n",
    "    with open(file_name, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=scenario_fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()  #Write header only once\n",
    "        writer.writerow(scenario)  #Write the scenario row\n",
    "    \n",
    "    print(f\"Successfully saved scenario for ConversationID {conversation_id} to {file_name}\")\n",
    "\n",
    "##########################################################################################################################\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "cosine_similarity_model = SentenceTransformer('stsb-roberta-large')\n",
    "\n",
    "def cosine_similarity(reference, prediction):\n",
    "    embedding1 = cosine_similarity_model.encode(reference, convert_to_tensor=True)\n",
    "    embedding2 = cosine_similarity_model.encode(prediction, convert_to_tensor=True)\n",
    "    similarity_score = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    return similarity_score.item()\n",
    "    \n",
    "def corpus_bleu_eq(references, predictions):\n",
    "    tokenized_references = [[word_tokenize(ref)] for ref in references]\n",
    "    tokenized_predictions = [word_tokenize(pred) for pred in predictions]\n",
    "    return corpus_bleu(tokenized_references, tokenized_predictions, smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "def rouge_eq(reference, prediction):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(prediction, reference)\n",
    "    return scores[0]['rouge-l']['f']\n",
    "\n",
    "def meteor_eq(reference, prediction):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    tokenized_reference = tokenizer.tokenize(reference)\n",
    "    tokenized_prediction = tokenizer.tokenize(prediction)\n",
    "    return meteor_score([tokenized_reference], tokenized_prediction)\n",
    "\n",
    "def bertscore_metric(reference, prediction):\n",
    "    P, R, F1 = bert_score([prediction], [reference], lang=\"en\", verbose=False)\n",
    "    return F1.mean().item()\n",
    "\n",
    "def sentiment_score_def(text):\n",
    "    \"\"\"compound score: which ranges from -1 (negative) to +1 (positive).\"\"\"\n",
    "    sentiment = vader_analyzer.polarity_scores(text)\n",
    "    return sentiment['compound']\n",
    "\n",
    "def response_length_def(text):\n",
    "    \"\"\"calc number of words in the text response.\"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "#MAUDE\n",
    "def maude_def(context, response, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    MAUDE score using GPT-4's chat-completions endpoint.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Evaluate the following response in the context of the given conversation:\n",
    "- Context: {context}\n",
    "- Response: {response}\n",
    "\n",
    "Rate the response from 0 to 1 based on the following criteria:\n",
    "1. Coherence: How well the response logically follows from the context.\n",
    "2. Relevance: How directly the response addresses the context.\n",
    "\n",
    "Only provide the score as a numeric value between 0 and 1, with no additional explanation or text.\"\"\"\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an evaluation assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=10)\n",
    "        #Extract the score from the response\n",
    "        text_response = completion.choices[0].message['content'].strip()\n",
    "        print(f\"MAUDE Raw Response: {text_response}\")\n",
    "        if re.match(r'^\\d+(\\.\\d+)?$', text_response):\n",
    "            score = float(text_response)\n",
    "        else:\n",
    "            score = 0.0  #Handle invalid responses\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in MAUDE scoring: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "#GEval metrics for relevance and coherence\n",
    "def geval_def(context, response, criteria, model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    GE-val score for a given criteria (relevance or coherence).\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an evaluation assistant tasked with scoring a response based on the given criteria.\n",
    "    \n",
    "    Evaluation Task:\n",
    "    - Criteria: {criteria}\n",
    "    - Context: {context if context else 'N/A'}\n",
    "    - Response: {response}\n",
    "    \n",
    "    Scoring Instructions:\n",
    "    - Relevance: Score based on how directly the response addresses the context and aligns with a salary negotiation\n",
    "        - A score of 0.9–1.0: The response directly addresses the main points in the context and is highly relevant\n",
    "        - A score of 0.6–0.8: The response is partially relevant but may include unrelated or tangential content\n",
    "        - A score of 0.0–0.5: The response does not address the context or is entirely irrelevant\n",
    "    \n",
    "    - Coherence: Score based on how logically structured and clear the response is for a salary negotiation\n",
    "        - A score of 0.9–1.0: The response is well-structured, logical, and easy to understand.\n",
    "        - A score of 0.6–0.8: The response is somewhat clear but may contain minor logical inconsistencies\n",
    "        - A score of 0.0–0.5: The response is poorly structured, lacks logic, or is difficult to understand\n",
    "    \n",
    "    **Instructions**:\n",
    "    1. Provide a numeric score between 0.0 and 1.0 based on the criteria\n",
    "    2. Use only two decimal place in your score (e.g., 0.80, 0.90)\n",
    "    3. Do not include any explanation or additional text in your response; provide only the score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an evaluation assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.0,\n",
    "            max_tokens=10)\n",
    "        #Extract the score from the response\n",
    "        text_response = completion.choices[0].message['content'].strip()\n",
    "        print(f\"GEval ({criteria}) Raw Response: {text_response}\")\n",
    "        if re.match(r'^\\d+(\\.\\d+)?$', text_response):\n",
    "            score = float(text_response)\n",
    "        else:\n",
    "            score = 0.0  #Handle invalid responses\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in GEval scoring ({criteria}): {e}\")\n",
    "        return 0.0\n",
    "\n",
    "#####################################################################################\n",
    "#Reference text for BLEU, ROUGE, METEOR, BERTScore\n",
    "reference_data = pd.read_csv(\"negotiation_references_combined.csv\")\n",
    "\n",
    "#Filter references by role\n",
    "employee_references = reference_data[reference_data['role'] == 'Employee']['text'].tolist()\n",
    "hr_manager_references = reference_data[reference_data['role'] == 'HR Manager']['text'].tolist()\n",
    "\n",
    "#######################################################################################################\n",
    "#Function to evaluate a single model \n",
    "def evaluate_individual_model(\n",
    "    conversation_history, model_role, references, model_name, run_number, \n",
    "    current_salary, final_salary, model_personality, total_tokens_used, prompt_tokens,  \n",
    "        completion_tokens, agreement_status):\n",
    "    #Initialize metric containers\n",
    "    bleu_scores, rouge_scores, meteor_scores, bert_scores, cosine_similarity_scores = [], [], [], [], []\n",
    "    maude_scores = []\n",
    "    relevance_scores, coherence_scores, combined_geval_scores = [], [], []\n",
    "    sentiment_scores, response_lengths = [], []\n",
    "    latencies = []\n",
    "    total_time = 0  #Initialize total_time here\n",
    "    total_tokens = 0\n",
    "\n",
    "    #Summary of negotiation outcome\n",
    "    summary = agreement_status\n",
    "\n",
    "    #Filter responses for the given model role\n",
    "    assistant_responses = [msg for msg in conversation_history if msg[\"role\"] == model_role]\n",
    "\n",
    "    #Process each response for metrics\n",
    "    for i, assistant_response in enumerate(assistant_responses):\n",
    "        prediction = assistant_response.get(\"content\", \"\")\n",
    "        context = \" \".join([msg.get(\"content\", \"\") for msg in conversation_history[:i]])\n",
    "\n",
    "        #Calculate similarity metrics if reference exists\n",
    "        if i < len(references):\n",
    "            reference = references[i]\n",
    "            bleu_scores.append(corpus_bleu_eq([reference], [prediction]))\n",
    "            rouge_scores.append(rouge_eq(reference, prediction))\n",
    "            meteor_scores.append(meteor_eq(reference, prediction))\n",
    "            bert_scores.append(bertscore_metric(reference, prediction))\n",
    "            cosine_similarity_scores.append(cosine_similarity(reference, prediction))\n",
    "\n",
    "        #Calculate MAUDE score\n",
    "        maude_scores.append(maude_def(context, prediction, model=\"gpt-4o\"))\n",
    "\n",
    "        #Calculate GEval metrics\n",
    "        relevance_scores.append(geval_def(context, prediction, criteria=\"Relevance\", model=\"gpt-4o\"))\n",
    "        coherence_scores.append(geval_def(\"\", prediction, criteria=\"Coherence\", model=\"gpt-4o\"))\n",
    "        combined_geval_scores.append(round(0.5 * relevance_scores[-1] + 0.5 * coherence_scores[-1], 3))\n",
    "\n",
    "        #Sentiment and response length\n",
    "        sentiment_scores.append(sentiment_score_def(prediction))\n",
    "        response_lengths.append(response_length_def(prediction))\n",
    "\n",
    "        #Track latency and token usage\n",
    "        latency = assistant_response.get(\"latency\", 0)\n",
    "        latencies.append(latency)\n",
    "        total_tokens += assistant_response.get(\"token_count\", 0)\n",
    "        total_time += latency\n",
    "        usage = assistant_response.get('usage', {})\n",
    "        prompt_tokens += usage.get('prompt_tokens', 0)\n",
    "        completion_tokens += usage.get('completion_tokens', 0)\n",
    "\n",
    "    #Ensure tokens per second is calculated after processing all responses\n",
    "    tokens_per_second = total_tokens / total_time if total_time > 0 else 0\n",
    "\n",
    "    #Calculate total cost based on token usage \n",
    "    input_cost = (prompt_tokens / 1000000) * 2.50  #$2.50 per 1M input tokens\n",
    "    output_cost = (completion_tokens / 1000000) * 10.00  #$10.00 per 1M output tokens\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    #Calculate salary percent change\n",
    "    salary_percent_change = ((final_salary - current_salary) / current_salary) * 100\n",
    "    if salary_percent_change == 0:\n",
    "        print(f\"No change in salary: Initial = {current_salary}, Final = {final_salary}\")\n",
    "    else:\n",
    "        print(f\"Salary change: {salary_percent_change}%\")\n",
    "\n",
    "    #Create metrics dictionary\n",
    "    metrics_dictionary = {\n",
    "        \"BLEU\": np.mean(bleu_scores) if bleu_scores else 0,\n",
    "        \"ROUGE\": np.mean(rouge_scores) if rouge_scores else 0,\n",
    "        \"METEOR\": np.mean(meteor_scores) if meteor_scores else 0,\n",
    "        \"BERTScore\": np.mean(bert_scores) if bert_scores else 0,\n",
    "        \"Cosine Similarity\": np.mean(cosine_similarity_scores) if cosine_similarity_scores else 0,\n",
    "        \"MAUDE\": np.mean(maude_scores) if maude_scores else 0,\n",
    "        \"Avg Relevance Score\": np.mean(relevance_scores) if relevance_scores else 0,\n",
    "        \"Avg Coherence Score\": np.mean(coherence_scores) if coherence_scores else 0,\n",
    "        \"Avg Combined GEval Score\": np.mean(combined_geval_scores) if combined_geval_scores else 0,\n",
    "        \"Avg Sentiment Score\": np.mean(sentiment_scores) if sentiment_scores else 0,\n",
    "        \"Avg Response Length\": np.mean(response_lengths) if response_lengths else 0,\n",
    "        \"Avg Latency\": np.mean(latencies) if latencies else 0,\n",
    "        \"Tokens per Second\": tokens_per_second,\n",
    "        \"Total Tokens\": total_tokens,\n",
    "        \"Total Cost\": total_cost,\n",
    "        \"Salary Percent Change\": salary_percent_change,\n",
    "        \"Initial Salary\": current_salary,\n",
    "        \"Final Salary\": final_salary,\n",
    "        \"Summary\": summary,\n",
    "        \"Timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"Model\": model_name,\n",
    "        \"Personality\": model_personality}\n",
    "\n",
    "    return metrics_dictionary\n",
    "\n",
    "###########################################################################################################################\n",
    "# Function intended to pull salary from responses to log \n",
    "def extract_salary(response):\n",
    "    \"\"\"\n",
    "    Extract the salary from a response with enhanced fallback strategies.\n",
    "    \"\"\"\n",
    "    #Keywords that indicate salary\n",
    "    salary_keywords = [\n",
    "        \"propose\", \"offer\", \"current salary\", \"desired salary\",\n",
    "        \"counteroffer\", \"final offer\", \"salary of\", \"adjustment to\",\n",
    "        \"compensation\", \"increase to\", \"base salary\", \"package\"]\n",
    "\n",
    "    #Match dollar amounts in various formats\n",
    "    matches = re.findall(r'\\$\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', response)  #Match \"$123,456.78\"\n",
    "    print(f\"Extracted Matches: {matches}\")  #Debugging statement for matches\n",
    "\n",
    "    #If matches found, proceed to validate proximity to keywords\n",
    "    if matches:\n",
    "        for match in matches:\n",
    "            #Clean and convert the matched dollar amount\n",
    "            salary_amount = float(match.replace(\",\", \"\").replace(\"$\", \"\"))\n",
    "\n",
    "            #Check if the matched salary is near a keyword\n",
    "            for keyword in salary_keywords:\n",
    "                pattern = rf\"{keyword}.*?{match}|{match}.*?{keyword}\"  #Check proximity\n",
    "                if re.search(pattern, response, re.IGNORECASE):\n",
    "                    print(f\"Extracted salary: {salary_amount} with keyword '{keyword}'\")\n",
    "                    return salary_amount  # Return the first valid match\n",
    "\n",
    "        #Fallback: If no keywords are matched, assume the first dollar amount is a salary\n",
    "        print(f\"No keywords matched. Using first extracted match as fallback: {matches[0]}\")\n",
    "        return float(matches[0].replace(\",\", \"\").replace(\"$\", \"\"))\n",
    "\n",
    "    #Final fallback: If no matches, log and return None\n",
    "    print(f\"No valid salary found in response: {response}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "#Function intended to remove extraneous words and phrases that may be inadvertently printed \n",
    "#this helps remove generated text issues we have seen constantly\n",
    "def clean_response(response):\n",
    "    #Remove or limit \"Thank you\" or similar phrases\n",
    "    response = re.sub(r\"(Thank you|I appreciate|truly).+?\\.\", \"\", response, flags=re.IGNORECASE).strip()\n",
    "    #Remove placeholders like \"[Employee's Name]\"\n",
    "    response = re.sub(r\"\\[.*?\\]\", \"\", response).strip()\n",
    "    #Remove leading role identifiers like \"HR Manager:\" or \"Employee:\" or \"Dear ...\"\n",
    "    response = re.sub(r\"^(HR Manager:|Employee:|Dear\\s.+?,)\", \"\", response, flags=re.IGNORECASE).strip()\n",
    "    #Remove excessive whitespace\n",
    "    response = re.sub(r\"\\s+\", \" \", response).strip()\n",
    "    #Remove bullet points, markdown-like formatting, and excessive symbols\n",
    "    response = re.sub(r\"(\\*\\*|--|\\s*-)\", \"\", response).strip()\n",
    "    #Remove numbers or irrelevant prefixes (e.g., \"94.\")\n",
    "    response = re.sub(r\"^\\d+\\.?\", \"\", response).strip()\n",
    "    #Split into sentences and remove duplicates while preserving order\n",
    "    sentences = [s.strip() for s in response.split(\".\") if s.strip()]\n",
    "    seen = set()\n",
    "    unique_sentences = []\n",
    "    for s in sentences:\n",
    "        if s not in seen and s != \"\":\n",
    "            unique_sentences.append(s)\n",
    "            seen.add(s)\n",
    "\n",
    "    #Rejoin sentences\n",
    "    response = \". \".join(unique_sentences).strip()\n",
    "\n",
    "    #Remove repeated leading \"We\" or \"I\" (rare edge case)\n",
    "    response = re.sub(r\"^(We\\s+We|I\\s+I)\\s+\", \"\", response, flags=re.IGNORECASE)\n",
    "\n",
    "    #Ensure proper capitalization of the first letter\n",
    "    if response and not response[0].isupper():\n",
    "        response = response[0].upper() + response[1:]\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_negotiation_outcome(conversation_history, model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Determines whether the negotiation ended in an agreement or no agreement\n",
    "    based on the last four turns of the conversation using GPT-4o.\n",
    "    \"\"\"\n",
    "    #Extract the last four turns\n",
    "    last_turns = conversation_history[-4:]\n",
    "    last_turns_text = \"\\n\".join(\n",
    "        f\"{entry['role']}: {entry['content']}\" for entry in last_turns)\n",
    "\n",
    "    #Create the evaluation prompt\n",
    "    evaluation_prompt = f\"\"\"\n",
    "    Below is the conversation history of a salary negotiation. \n",
    "    Review the final four turns and determine whether the negotiation ended in an agreement or no agreement. \n",
    "    Your response must include one of the following:\n",
    "    - \"Agreement\" if both parties agreed on a salary or terms.\n",
    "    - \"No Agreement\" if the negotiation ended without mutual consent.\n",
    "\n",
    "    Final Four Turns:\n",
    "    {last_turns_text}\n",
    "\n",
    "    Outcome:\n",
    "    \"\"\"\n",
    "\n",
    "    #Call the GPT-4o model to evaluate the outcome\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an evaluation assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": evaluation_prompt.strip()}\n",
    "            ],\n",
    "            max_tokens=50,\n",
    "            temperature=0.0)\n",
    "        outcome = response.choices[0].message['content'].strip()\n",
    "        print(f\"Evaluation Bot Outcome: {outcome}\")\n",
    "        return outcome\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating negotiation outcome: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################################################################\n",
    "\n",
    "def run_negotiation(\n",
    "    model_employee,\n",
    "    model_manager,\n",
    "    scenario,\n",
    "    current_salary,\n",
    "    desired_salary,\n",
    "    max_turns,\n",
    "    sim_token_limit):\n",
    "    \"\"\"\n",
    "    In this function: we implement a salary negotiation enabling proper role alternation, enforcing a minimum number of turns,\n",
    "    and ensuring the HR Manager always delivers the closing statement.\n",
    "    \"\"\"\n",
    "    conversation_history = []\n",
    "    total_tokens_used = 0\n",
    "    current_offer = current_salary\n",
    "    highest_counteroffer = current_salary\n",
    "    total_time = 0\n",
    "    prompt_tokens = 0\n",
    "    completion_tokens = 0\n",
    "\n",
    "    starting_role = random.choice([\"Employee\", \"HR Manager\"])\n",
    "    current_role = starting_role\n",
    "    roles = {\"Employee\": model_employee, \"HR Manager\": model_manager}\n",
    "\n",
    "    # Introductory message\n",
    "    # IF-Else to write different starting messages for whoever begins negotiation talks \n",
    "    if starting_role == \"Employee\":\n",
    "        intro_message = f\"\"\"\n",
    "        Thank you for taking the time to meet today. I wanted to discuss my compensation and explore how we can align \n",
    "        it more closely with my contributions and the market standards. My current salary is ${current_salary}, and \n",
    "        I believe there is room for adjustment to better reflect my role.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        intro_message = f\"\"\"\n",
    "        Thank you for meeting with us today to discuss your compensation. \n",
    "        We value your work at the company and aim to have a discussion.\n",
    "        Currently, your salary is ${current_salary}, and we are open to discussing an adjustment.\n",
    "        \"\"\"\n",
    "\n",
    "    conversation_history.append({\n",
    "        \"role\": starting_role,\n",
    "        \"content\": clean_response(intro_message.strip()),\n",
    "        \"latency\": 0,\n",
    "        \"token_count\": 0\n",
    "    })\n",
    "    \n",
    "    # Set this variable as the checker to if there was an agreement made\n",
    "    # Should there be an agreement, this variable will change to \"Agreement\"\n",
    "    agreement_status = \"No Agreement\"\n",
    "    # To prevent premature terminations in negotiations \n",
    "    # Set a minimum of half the max turns in order for the negotiation to play out further\n",
    "    minimum_turns = max_turns // 2\n",
    "\n",
    "    # Triggers the negotiation loop to begin\n",
    "    for turn in range(max_turns):\n",
    "        current_role = \"HR Manager\" if current_role == \"Employee\" else \"Employee\"\n",
    "        model = roles[current_role]\n",
    "        tone = scenario[\"employee_personality\"] if current_role == \"Employee\" else scenario[\"hr_manager_personality\"]\n",
    "\n",
    "        memory_context = \"\\n\".join(f\"{entry['role']}: {entry['content']}\" for entry in conversation_history[-4:])\n",
    "        prompt = f\"\"\"\n",
    "        The employee's current salary is ${current_salary}.\n",
    "        The company's current offer is ${current_offer}.\n",
    "        The employee's desired salary is ${desired_salary}.\n",
    "        The highest counteroffer so far is ${highest_counteroffer}.\n",
    "        \n",
    "        Context:\n",
    "        {memory_context}\n",
    "\n",
    "        Instructions:\n",
    "        - Respond as the {current_role} in a {tone} tone.\n",
    "        - Avoid repeating points, emojis, or unnecessary text.\n",
    "        - Suggest creative solutions (e.g., bonuses, phased raises, non-monetary benefits).\n",
    "        - Be concise and professional.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": f\"You are the {current_role} in this negotiation.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt.strip()}\n",
    "                ],\n",
    "                max_tokens=200,\n",
    "                temperature=0.7)\n",
    "            latency = time.time() - start_time\n",
    "            response_content = clean_response(response.choices[0].message['content'].strip())\n",
    "\n",
    "            conversation_history.append({\n",
    "                \"role\": current_role,\n",
    "                \"content\": response_content,\n",
    "                \"latency\": latency,\n",
    "                \"token_count\": response['usage']['total_tokens']\n",
    "            })\n",
    "\n",
    "            print(f\"Turn {turn + 1} ({current_role}):\\n{response_content}\")\n",
    "\n",
    "            # Evaluate agreement status after half the turns\n",
    "            if turn >= minimum_turns:\n",
    "                current_outcome = evaluate_negotiation_outcome(conversation_history)\n",
    "                if current_outcome == \"Agreement\":\n",
    "                    print(\"Agreement reached early. Ending negotiation.\")\n",
    "                    agreement_status = \"Agreement\"\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response for {current_role}: {e}\")\n",
    "            break\n",
    "\n",
    "    # For Fine Tuning purposes, this if statement is needed to guarantee that the HR Manager gets the last word\n",
    "    # Closing message designed to for either situations of an agreement/no agreement. \n",
    "    if conversation_history[-1]['role'] != \"HR Manager\":\n",
    "        closing_message = (\n",
    "            \"We are pleased to finalize our agreement, reflecting both our appreciation for your contributions and our mutual goals. \"\n",
    "            \"We look forward to your continued success and growth with us.\" \n",
    "            if agreement_status == \"Agreement\" else \n",
    "            \"While we could not finalize an agreement today, we deeply value your contributions. Thank you for engaging thoughtfully, \"\n",
    "            \"and we look forward to reconnecting in the future.\"\n",
    "        )\n",
    "\n",
    "        hr_manager_response = openai.ChatCompletion.create(\n",
    "            model=model_manager,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are the HR Manager in this negotiation.\"},\n",
    "                {\"role\": \"user\", \"content\": closing_message.strip()}\n",
    "            ],\n",
    "            max_tokens=150,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        final_hr_manager_response = clean_response(hr_manager_response.choices[0].message['content'].strip())\n",
    "        conversation_history.append({\n",
    "            \"role\": \"HR Manager\",\n",
    "            \"content\": final_hr_manager_response,\n",
    "            \"latency\": 0,\n",
    "            \"token_count\": hr_manager_response['usage']['total_tokens']\n",
    "        })\n",
    "        print(f\"Final HR Manager Turn:\\n{final_hr_manager_response}\")\n",
    "\n",
    "    return conversation_history, current_offer, total_tokens_used, prompt_tokens, completion_tokens, agreement_status\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Negotiation Loop\n",
    "for run in range(num_negotiations):\n",
    "    scenario, current_salary, desired_salary = generate_random_scenario()\n",
    "    conversation_id = generate_conversation_id()\n",
    "\n",
    "    #Updated to unpack all returned values\n",
    "    conversation, current_offer, total_tokens_used, prompt_tokens, completion_tokens, agreement_reached = run_negotiation(\n",
    "        model_employee=model_employee,\n",
    "        model_manager=model_manager,\n",
    "        scenario=scenario,\n",
    "        current_salary=current_salary,\n",
    "        desired_salary=desired_salary,\n",
    "        max_turns=max_turns,\n",
    "        sim_token_limit=sim_token_limit)\n",
    "\n",
    "\n",
    "    #Save negotiation details\n",
    "    save_conversation_to_jsonl(conversation, conversation_id, file_name=\"negotiation_chats_selfplay_base.jsonl\")\n",
    "    final_salary = current_offer if agreement_reached == \"Agreement\" else current_salary\n",
    "    \n",
    "    model_1_metrics = evaluate_individual_model(\n",
    "        conversation_history=conversation,\n",
    "        model_role=\"Employee\",\n",
    "        references=employee_references,\n",
    "        model_name=\"Model 1\",\n",
    "        run_number=run,\n",
    "        current_salary=current_salary,\n",
    "        final_salary = current_offer if agreement_reached == \"Agreement\" else current_salary,\n",
    "        model_personality=scenario[\"employee_personality\"],\n",
    "        total_tokens_used=total_tokens_used,\n",
    "        prompt_tokens=prompt_tokens,  \n",
    "        completion_tokens=completion_tokens,  \n",
    "        agreement_status=agreement_reached)\n",
    "    \n",
    "    model_2_metrics = evaluate_individual_model(\n",
    "        conversation_history=conversation,\n",
    "        model_role=\"HR Manager\",\n",
    "        references=hr_manager_references,\n",
    "        model_name=\"Model 2\",\n",
    "        run_number=run,\n",
    "        current_salary=current_salary,\n",
    "        final_salary= current_offer if agreement_reached == \"Agreement\" else current_salary,  \n",
    "        model_personality=scenario[\"hr_manager_personality\"],\n",
    "        total_tokens_used=total_tokens_used,\n",
    "        prompt_tokens=prompt_tokens,  \n",
    "        completion_tokens=completion_tokens,  \n",
    "        agreement_status=agreement_reached)\n",
    "\n",
    "\n",
    "    #Save metrics for the run\n",
    "    save_metrics_to_csv(model_1_metrics, conversation_id, file_name=\"model_1_metrics_base.csv\")\n",
    "    save_metrics_to_csv(model_2_metrics, conversation_id, file_name=\"model_2_metrics_base.csv\")\n",
    "    save_scenario_to_csv(scenario, conversation_id, file_name=\"negotiation_scenarios_base.csv\")\n",
    "\n",
    "    print(f\"Run {run} Summary:\")\n",
    "    print(f\"Initial Salary: ${current_salary}\")\n",
    "    print(f\"Desired Salary: ${desired_salary}\")\n",
    "    print(f\"Final Offer: ${current_offer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a960d23-9c04-436e-ac1a-6b44fdac058f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
